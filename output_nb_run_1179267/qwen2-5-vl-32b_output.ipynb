{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6c6dcd",
   "metadata": {
    "papermill": {
     "duration": 0.005538,
     "end_time": "2025-05-26T14:00:56.451937",
     "exception": false,
     "start_time": "2025-05-26T14:00:56.446399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f1bfa5",
   "metadata": {
    "papermill": {
     "duration": 0.004392,
     "end_time": "2025-05-26T14:00:56.461074",
     "exception": false,
     "start_time": "2025-05-26T14:00:56.456682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da127903",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-26T14:00:56.470742Z",
     "iopub.status.busy": "2025-05-26T14:00:56.470466Z",
     "iopub.status.idle": "2025-05-26T14:00:56.474532Z",
     "shell.execute_reply": "2025-05-26T14:00:56.473888Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.010247,
     "end_time": "2025-05-26T14:00:56.475679",
     "exception": false,
     "start_time": "2025-05-26T14:00:56.465432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install transformers torch Pillow tqdm bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dd7674",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-26T14:00:56.485369Z",
     "iopub.status.busy": "2025-05-26T14:00:56.485044Z",
     "iopub.status.idle": "2025-05-26T14:00:58.206378Z",
     "shell.execute_reply": "2025-05-26T14:00:58.205431Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.727754,
     "end_time": "2025-05-26T14:00:58.207788",
     "exception": false,
     "start_time": "2025-05-26T14:00:56.480034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (0.0.11)\r\n",
      "Requirement already satisfied: flash-attn in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.7.4.post1)\r\n",
      "Requirement already satisfied: av in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (14.3.0)\r\n",
      "Requirement already satisfied: packaging in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (25.0)\r\n",
      "Requirement already satisfied: pillow in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (10.3.0)\r\n",
      "Requirement already satisfied: requests in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (2.32.3)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (2.2.1)\r\n",
      "Requirement already satisfied: einops in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (0.8.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2025.4.26)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.93)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch->flash-attn) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qwen-vl-utils flash-attn #--no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c79d0aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T14:00:58.220016Z",
     "iopub.status.busy": "2025-05-26T14:00:58.219742Z",
     "iopub.status.idle": "2025-05-26T14:01:04.432059Z",
     "shell.execute_reply": "2025-05-26T14:01:04.430913Z"
    },
    "papermill": {
     "duration": 6.219414,
     "end_time": "2025-05-26T14:01:04.433405",
     "exception": false,
     "start_time": "2025-05-26T14:00:58.213991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84751216",
   "metadata": {
    "papermill": {
     "duration": 0.004882,
     "end_time": "2025-05-26T14:01:04.444560",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.439678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8f5fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T14:01:04.456347Z",
     "iopub.status.busy": "2025-05-26T14:01:04.455795Z",
     "iopub.status.idle": "2025-05-26T14:01:04.480525Z",
     "shell.execute_reply": "2025-05-26T14:01:04.479825Z"
    },
    "papermill": {
     "duration": 0.032105,
     "end_time": "2025-05-26T14:01:04.481630",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.449525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "    \n",
    "    def format_question(self, question, model_name):\n",
    "        \"\"\"Format a question for the model.\"\"\"\n",
    "\n",
    "        if model_name==\"blip2\":\n",
    "            return f\"Question: {question['question']} Answer:\"\n",
    "        else:\n",
    "            return f\"Question: {question['question']} Answer with a number and list of objects. Answer:\"\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "        # Remove any text that's not a number\n",
    "        # import re\n",
    "        # numbers = re.findall(r'\\d+', answer)\n",
    "        # if numbers:\n",
    "        #     return numbers[0]  # Return the first number found\n",
    "        # return answer\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    def model_generation(self, model_name, model, inputs, processor):\n",
    "        \"\"\"Generate answer and decode.\"\"\"\n",
    "        outputs = None  # Initialize outputs to None\n",
    "        \n",
    "        if model_name==\"smolVLM2\":\n",
    "            outputs = model.generate(**inputs, do_sample=False, max_new_tokens=64)\n",
    "            answer = processor.batch_decode(\n",
    "                outputs,\n",
    "                skip_special_tokens=True,\n",
    "            )[0]\n",
    "        elif model_name==\"Qwen2.5-VL\":\n",
    "            outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "            outputs = [\n",
    "                out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, outputs)\n",
    "            ]\n",
    "            answer = processor.batch_decode(\n",
    "                outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "        else:\n",
    "            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "            answer = \"\"  # Return an empty string\n",
    "\n",
    "        return answer, outputs\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                try:\n",
    "                    print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        print(f\"Warning: Image not found at {image_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question in image_data['questions']:\n",
    "                        try:\n",
    "                            # prompt = self.format_question(question, model_name)\n",
    "                            print(f\"Question: {question['question']}\")\n",
    "\n",
    "                            messages = [\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [\n",
    "                                        {\"type\": \"image\", \"image\": image},\n",
    "                                        # {\"type\": \"text\", \"text\": f\"{question['question']} Answer format: total number(numerical) objects(within square brackets)\"},\n",
    "                                        # {\"type\": \"text\", \"text\": f\"{question['question']} Provide just the total count and the list of objects in the given format \\n Format: number [objects]\"},\n",
    "                                        {\"type\": \"text\", \"text\": f\"{question['question']} Answer Format: number [objects]\"}\n",
    "                                    ]\n",
    "                                },\n",
    "                            ]\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            # Process image and text\n",
    "                            # inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "                            if model_name==\"smolVLM2\":\n",
    "                                inputs = processor.apply_chat_template(\n",
    "                                    messages,\n",
    "                                    add_generation_prompt=True,\n",
    "                                    tokenize=True,\n",
    "                                    return_dict=True,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                ).to(model.device, dtype=torch.float16)\n",
    "                            else:\n",
    "                                \n",
    "                                text = processor.apply_chat_template(\n",
    "                                    messages, tokenize=False, add_generation_prompt=True\n",
    "                                )\n",
    "                                # image_inputs, video_inputs = process_vision_info(messages)\n",
    "                                inputs = processor(\n",
    "                                    text=text,\n",
    "                                    images=image,\n",
    "                                    videos=None,\n",
    "                                    padding=True,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                ).to(\"cuda\")\n",
    "                            \n",
    "                            # Generate answer with better settings\n",
    "                            with torch.no_grad():\n",
    "                                answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n",
    "        \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data[\"image_type\"],\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing question: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "            if results:\n",
    "                with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4742f78",
   "metadata": {
    "papermill": {
     "duration": 0.004802,
     "end_time": "2025-05-26T14:01:04.491355",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.486553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test SmolVLM Model\n",
    "\n",
    "Let's evaluate the SmolVLM2-2.2B-Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba98f2dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T14:01:04.502090Z",
     "iopub.status.busy": "2025-05-26T14:01:04.501852Z",
     "iopub.status.idle": "2025-05-26T14:01:04.506222Z",
     "shell.execute_reply": "2025-05-26T14:01:04.505478Z"
    },
    "papermill": {
     "duration": 0.011167,
     "end_time": "2025-05-26T14:01:04.507363",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.496196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_smolVLM2():\n",
    "#     from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "#     print(\"Loading smolVLM model...\")\n",
    "    \n",
    "#     model = AutoModelForImageTextToText.from_pretrained(\n",
    "#         \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\",\n",
    "#         torch_dtype=torch.float16,\n",
    "#         attn_implementation=\"flash_attention_2\",\n",
    "#         low_cpu_mem_usage=True,\n",
    "#         trust_remote_code=True\n",
    "#     ).to(\"cuda\")\n",
    "\n",
    "#     processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM2-2.2B-Instruct\")\n",
    "\n",
    "#     ## A bit slow without the flash_attention2 requires ampere gpu's. Better performance in some cases\n",
    "\n",
    "#     # Optional: Enable memory efficient attention\n",
    "#     if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "#         model.config.use_memory_efficient_attention = True\n",
    "\n",
    "#     tester = BenchmarkTester()\n",
    "#     smolVLM_results = tester.evaluate_model(\n",
    "#         \"smolVLM2\",\n",
    "#         model, \n",
    "#         processor, \n",
    "#         \"smolVLM2_results_1.json\", \n",
    "#         batch_size=25\n",
    "#     )\n",
    "\n",
    "#     # Clean up\n",
    "#     del model, processor\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7524743",
   "metadata": {
    "papermill": {
     "duration": 0.004777,
     "end_time": "2025-05-26T14:01:04.517005",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.512228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Qwen2.5-VL\n",
    "\n",
    "Lets evaluate the Qwen2.5-VL-7B-Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495307f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T14:01:04.527822Z",
     "iopub.status.busy": "2025-05-26T14:01:04.527327Z",
     "iopub.status.idle": "2025-05-26T14:01:04.533165Z",
     "shell.execute_reply": "2025-05-26T14:01:04.532426Z"
    },
    "papermill": {
     "duration": 0.012464,
     "end_time": "2025-05-26T14:01:04.534310",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.521846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_Qwen2_5VL():\n",
    "    from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "    \n",
    "    # default: Load the model on the available device(s)\n",
    "    # model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    #     \"Qwen/Qwen2.5-VL-3B-Instruct\", \n",
    "    #     load_in_8bit=True, # throws error when .to() is added\n",
    "    #     torch_dtype=torch.bfloat16, \n",
    "    #     device_map=\"auto\",\n",
    "    #     # attn_implementation=\"flash_attention_2\",\n",
    "    #     low_cpu_mem_usage=True\n",
    "    # )\n",
    "    \n",
    "    # We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/qwen2-5-vl-32b\",\n",
    "        torch_dtype=torch.float16,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # default processer\n",
    "    processor = AutoProcessor.from_pretrained(\"/var/scratch/ave303/models/qwen2-5-vl-32b\")\n",
    "\n",
    "    ### Qwen2.5-VL-7B-Instruct --> goes out of CUDA memory\n",
    "    ### Qwen2.5-VL-3B-Instruct --> can handle only 2 images before going out of memory but decent performance\n",
    "\n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "\n",
    "    tester = BenchmarkTester()\n",
    "    Qwen2_5VL_results = tester.evaluate_model(\n",
    "        \"Qwen2.5-VL\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"Qwen2.5-VL_32b_results.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "\n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d137da",
   "metadata": {
    "papermill": {
     "duration": 0.004724,
     "end_time": "2025-05-26T14:01:04.543963",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.539239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the SmolVLM2 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05855e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T14:01:04.554631Z",
     "iopub.status.busy": "2025-05-26T14:01:04.554377Z",
     "iopub.status.idle": "2025-05-26T14:01:04.557906Z",
     "shell.execute_reply": "2025-05-26T14:01:04.557248Z"
    },
    "papermill": {
     "duration": 0.010119,
     "end_time": "2025-05-26T14:01:04.559045",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.548926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_smolVLM2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f51978f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T14:01:04.569841Z",
     "iopub.status.busy": "2025-05-26T14:01:04.569518Z",
     "iopub.status.idle": "2025-05-26T21:04:28.646758Z",
     "shell.execute_reply": "2025-05-26T21:04:28.645908Z"
    },
    "papermill": {
     "duration": 25404.084223,
     "end_time": "2025-05-26T21:04:28.648131",
     "exception": false,
     "start_time": "2025-05-26T14:01:04.563908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   3%|▎         | 1/30 [00:02<01:18,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   7%|▋         | 2/30 [00:06<01:27,  3.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  10%|█         | 3/30 [00:09<01:25,  3.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  13%|█▎        | 4/30 [00:12<01:23,  3.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  17%|█▋        | 5/30 [00:15<01:18,  3.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  20%|██        | 6/30 [00:19<01:19,  3.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  23%|██▎       | 7/30 [00:22<01:17,  3.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  27%|██▋       | 8/30 [00:26<01:14,  3.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  30%|███       | 9/30 [00:29<01:10,  3.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  33%|███▎      | 10/30 [00:32<01:05,  3.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  37%|███▋      | 11/30 [00:35<01:02,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  40%|████      | 12/30 [00:39<00:59,  3.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  43%|████▎     | 13/30 [00:42<00:54,  3.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  47%|████▋     | 14/30 [00:45<00:51,  3.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  50%|█████     | 15/30 [00:48<00:49,  3.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  53%|█████▎    | 16/30 [00:51<00:45,  3.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  57%|█████▋    | 17/30 [00:55<00:42,  3.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  60%|██████    | 18/30 [00:58<00:39,  3.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  63%|██████▎   | 19/30 [01:01<00:35,  3.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  67%|██████▋   | 20/30 [01:04<00:32,  3.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  70%|███████   | 21/30 [01:07<00:28,  3.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  73%|███████▎  | 22/30 [01:10<00:23,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  77%|███████▋  | 23/30 [01:13<00:20,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  80%|████████  | 24/30 [01:16<00:17,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  83%|████████▎ | 25/30 [01:19<00:14,  2.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  87%|████████▋ | 26/30 [01:22<00:11,  2.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  90%|█████████ | 27/30 [01:25<00:08,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  93%|█████████▎| 28/30 [01:28<00:06,  3.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  97%|█████████▋| 29/30 [01:31<00:03,  3.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 30/30 [01:34<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 30/30 [01:34<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Qwen2.5-VL...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 1/50: image01\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of breakable items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the metal objects were replaced by a wooden object, how many wooden objects would be there in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   2%|▏         | 1/50 [06:52<5:36:57, 412.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 2/50: image02\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can store other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the zebra were replaced by a tree, how many mammals would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   4%|▍         | 2/50 [15:28<6:18:31, 473.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 3/50: image03\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects with the primary purpose of illumination can be seen?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the person riding one of the bicycles were replaced by a pedestrian, how many objects that have handles would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   6%|▌         | 3/50 [24:33<6:36:21, 505.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 4/50: image04\n",
      "Question: How many tools are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cutting tools are present in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the red handle were replaced by a wooden handle, how many colored artifacts would remain in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   8%|▊         | 4/50 [35:01<7:05:03, 554.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 5/50: image05\n",
      "Question: How many furniture items are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of containers that cannot hold hot liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the room were transformed into an open workspace instead of a meeting room, how many privacy features would need to be removed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  10%|█         | 5/50 [46:25<7:30:48, 601.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 6/50: image06\n",
      "Question: How many reptiles are visible in this enclosure?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many reptilian couples, at maximum, are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the small pebbles forming the mosaic floor were replaced with sand, how many natural elements would still be visible in the enclosure?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  12%|█▏        | 6/50 [55:27<7:05:59, 580.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 7/50: image07\n",
      "Question: How many birds are visible in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can comfortably seat a human?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the birds sitting together only on one railing were to fly away, how many birds would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  14%|█▍        | 7/50 [1:00:01<5:44:25, 480.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 8/50: image08\n",
      "Question: How many reptiles are visible in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one turtle slid off the log into the water, how many turtles would be in the water?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  16%|█▌        | 8/50 [1:04:16<4:46:10, 408.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 9/50: image09\n",
      "Question: How many different types of vegetables are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are used as containers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bag of limes were removed and replaced with two additional avocados, how many fruits would be present in total on the table, considering avocados are fruits?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  18%|█▊        | 9/50 [1:12:52<5:02:07, 442.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 10/50: image10\n",
      "Question: How many objects are present that are flexible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that are battery powered?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two phones with three camera lenses were replaced with phones having two camera lenses, how many phones with two camera lenses would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  20%|██        | 10/50 [1:25:33<6:00:33, 540.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 11/50: image11\n",
      "Question: How many objects made of glass are present on the table?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present at the table that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tables in the center are removed, how many objects are visible that have legs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  22%|██▏       | 11/50 [1:33:45<5:41:44, 525.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 12/50: image12\n",
      "Question: How many pieces of gym equipment are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shade?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two of the stationary bikes were replaced by two treadmills, how many objects would be present that have pedals?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  24%|██▍       | 12/50 [1:40:24<5:08:32, 487.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 13/50: image13\n",
      "Question: How many furniture items are present in the room?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many individual storage compartments are present in the furniture items in the room?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two bedside lamps were removed, how many objects are present that need electricity?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  26%|██▌       | 13/50 [1:52:00<5:39:23, 550.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 14/50: image14\n",
      "Question: How many objects are present that are transparent?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are positioned for student use to place other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the signages were removed, how many objects would be present that hang from the ceiling?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  28%|██▊       | 14/50 [1:54:17<4:15:23, 425.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 15/50: image15\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used to move up?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car on the ground is driven out of the garage, how many objects are present that is used to indicate slowing down to a stop?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  30%|███       | 15/50 [2:02:50<4:23:38, 451.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 16/50: image16\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects can be used as modes of transport if fixed?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the center is fixed and driven out of the garage, how many objects made of rubber would be visible in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  32%|███▏      | 16/50 [2:16:26<5:18:08, 561.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 17/50: image17\n",
      "Question: How many yellow colored objects are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are used to protect the head?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one person leaves the cleaning group, how many mammals would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  34%|███▍      | 17/50 [2:22:45<4:38:41, 506.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 18/50: image18\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the mammals are to all step inside the shelters, how many natural elements are visible in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  36%|███▌      | 18/50 [2:28:35<4:05:06, 459.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 19/50: image19\n",
      "Question: How many gardening tools are present that are made of metal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present in the garden that can hold other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If half the woven baskets are filled, how many containers would remain empty?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  38%|███▊      | 19/50 [2:38:40<4:20:04, 503.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 20/50: image20\n",
      "Question: How many objects in the background are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: CUDA out of memory. Tried to allocate 858.00 MiB. GPU 0 has a total capacity of 47.65 GiB of which 486.00 MiB is free. Including non-PyTorch memory, this process has 47.17 GiB memory in use. Of the allocated memory 45.34 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Question: How many objects in the foreground are visible that are foldable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: CUDA out of memory. Tried to allocate 858.00 MiB. GPU 0 has a total capacity of 47.65 GiB of which 672.00 MiB is free. Including non-PyTorch memory, this process has 46.98 GiB memory in use. Of the allocated memory 45.09 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Question: If the stack of books on the table in the foreground was moved to the shelf, how many objects in physical contact with the table would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  40%|████      | 20/50 [2:39:05<2:59:47, 359.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: CUDA out of memory. Tried to allocate 860.00 MiB. GPU 0 has a total capacity of 47.65 GiB of which 234.00 MiB is free. Including non-PyTorch memory, this process has 47.41 GiB memory in use. Of the allocated memory 45.84 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Processing image 21/50: image01\n",
      "Question: How many mammals are present in total?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can store items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bear were to be replaced by a tree, how many different types of mammals would be there at the zoo?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  42%|████▏     | 21/50 [2:49:08<3:29:04, 432.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 22/50: image02\n",
      "Question: How many kitchen tools are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that require electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If blinds were installed for the windows above the sink, how many transparent objects would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  44%|████▍     | 22/50 [2:57:56<3:35:20, 461.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 23/50: image03\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the worker was not wearing ear protection, how many protective items would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  46%|████▌     | 23/50 [3:04:33<3:18:51, 441.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 24/50: image04\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Excluding the drawers, how many items in the workshop serve as containers for storage?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If an electric fan were placed on the workstation to provide ventilation, how many objects in the room would require electricity to operate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  48%|████▊     | 24/50 [3:17:37<3:55:59, 544.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 25/50: image05\n",
      "Question: How many birds are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the clouds were to completely cover the sky, blocking the sunlight, how many natural elements would still be visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  50%|█████     | 25/50 [3:23:02<3:19:31, 478.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 26/50: image06\n",
      "Question: How many objects are present that have chimneys?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bus were replaced by a pedestrian, how many mammals would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  52%|█████▏    | 26/50 [3:33:54<3:32:17, 530.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 27/50: image07\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can be used to carry liquid?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the waste to be disposed was color-coded to match the bins, how many objects are to be thrown in the bin on the right?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  54%|█████▍    | 27/50 [3:41:27<3:14:29, 507.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 28/50: image08\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that are openable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bottle was removed from the table, how many objects are present on top of the table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  56%|█████▌    | 28/50 [3:53:22<3:28:53, 569.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 29/50: image09\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many kitchen items are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two jars on the top shelf were removed, how many breakable items would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  58%|█████▊    | 29/50 [3:59:44<2:59:44, 513.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 30/50: image10\n",
      "Question: How many objects made of plastic are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can record audio?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the microphones were replaced with headsets for every character, how many objects in total would be present that are worn on the head?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  60%|██████    | 30/50 [4:07:52<2:48:35, 505.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 31/50: image11\n",
      "Question: How many different food items are present on the kitchen countertop?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the objects on the two shelves above the counter were placed inside the cabinet, how many items that are breakable would be present on the counter?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  62%|██████▏   | 31/50 [4:20:23<3:03:25, 579.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 32/50: image12\n",
      "Question: How many different types of plants are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that behave as containers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the visible plants were potted individually and placed on the stand, how many pots would be present on the stand?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  64%|██████▍   | 32/50 [4:33:16<3:11:11, 637.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 33/50: image13\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacity of 47.65 GiB of which 764.00 MiB is free. Including non-PyTorch memory, this process has 46.89 GiB memory in use. Of the allocated memory 45.18 GiB is allocated by PyTorch, and 1.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Question: How many objects are present that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacity of 47.65 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 47.59 GiB memory in use. Of the allocated memory 45.68 GiB is allocated by PyTorch, and 1.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Question: If the character standing upright took a seat for themself and the huddled group are seated in pairs, that is two characters per seat. How many objects would remain that can be used for sitting?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  66%|██████▌   | 33/50 [4:33:40<2:08:30, 453.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: CUDA out of memory. Tried to allocate 866.00 MiB. GPU 0 has a total capacity of 47.65 GiB of which 46.00 MiB is free. Including non-PyTorch memory, this process has 47.60 GiB memory in use. Of the allocated memory 45.62 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Processing image 34/50: image14\n",
      "Question: How many cardboard objects are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bottled objects and the white cups are packed away, how many objects are present that can be used to drink out of?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  68%|██████▊   | 34/50 [4:38:23<1:47:17, 402.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 35/50: image15\n",
      "Question: How many objects that are present have wheels?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can be used to hold liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car drives away, how many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  70%|███████   | 35/50 [4:51:36<2:09:54, 519.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 36/50: image16\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools designed for gathering or sweeping are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If there was a flood and the water washed up the beach, completely submerging it, how many natural elements would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  72%|███████▏  | 36/50 [4:58:55<1:55:32, 495.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 37/50: image17\n",
      "Question: How many objects are visible that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are attached to the wall or ceiling?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the blinds are pulled over the window, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  74%|███████▍  | 37/50 [5:10:42<2:01:05, 558.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 38/50: image18\n",
      "Question: How many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can hold liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tools hanging on the wall were to be placed on the shelf, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  76%|███████▌  | 38/50 [5:23:25<2:03:59, 619.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 39/50: image19\n",
      "Question: How many different types of gym equipment are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pieces of exercise equipment primarily designed for cardiovascular workouts are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the blinds were pulled over the windows, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  78%|███████▊  | 39/50 [5:34:51<1:57:20, 640.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 40/50: image20\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that act as protection or shade?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the laptop were placed on the shelf next to the TV, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  80%|████████  | 40/50 [5:44:14<1:42:48, 616.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 41/50: image01\n",
      "Question: How many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the driveway were to leave, how many objects primarily made of metal would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  82%|████████▏ | 41/50 [5:52:25<1:26:51, 579.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 42/50: image02\n",
      "Question: How many objects made of concrete are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used for lifting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the orange paint spilled all over one of the plexiglass sheets, how many objects would remain that are transparent?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  84%|████████▍ | 42/50 [5:57:16<1:05:41, 492.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 43/50: image03\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are used for both meat and wool production?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two sheep were replaced by a cow grazing in the same area, how many objects would be present in between the two fences?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  86%|████████▌ | 43/50 [6:04:08<54:37, 468.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 44/50: image04\n",
      "Question: How many objects are visible that are made of paper?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that behave as storage spaces?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the glasses were placed inside the ceramic container, and we use this container as a dividing line between the left and right sides of the bookshelf, how many objects would be on the right side?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  88%|████████▊ | 44/50 [6:13:57<50:28, 504.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 45/50: image05\n",
      "Question: How many objects are visible that are made of porcelain?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many decoration items are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the drinks were split evenly between the two humans, how many drinks would each human consume?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  90%|█████████ | 45/50 [6:18:41<36:32, 438.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 46/50: image06\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are designed to contain liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the trash bags and bottles on the sand are only thrown into the black bin, how many mammals are actively holding some other object?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  92%|█████████▏| 46/50 [6:24:30<27:26, 411.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 47/50: image07\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the mammals douses the fire, how many objects are present that can be switched off?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  94%|█████████▍| 47/50 [6:30:34<19:51, 397.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 48/50: image08\n",
      "Question: How many different types of gym equipment are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are positioned between the row of treadmills and the bench press station?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the treadmills is faulty and removed from the gym, how many objects are present that convey some kind of information?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  96%|█████████▌| 48/50 [6:40:56<15:29, 464.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 49/50: image09\n",
      "Question: How many objects made of rubber are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the workers took a wrench off the table, how many objects would remain in physical contact with the table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  98%|█████████▊| 49/50 [6:51:20<08:32, 512.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 50/50: image10\n",
      "Question: How many objects are visible that are made of metal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects present are breakable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bowls with the tomatoes and the chickpeas were emptied into the steaming pot, how many containers would still have something remaining in them?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [7:01:42<00:00, 545.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [7:01:42<00:00, 506.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_Qwen2_5VL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec605fe",
   "metadata": {
    "papermill": {
     "duration": 0.019637,
     "end_time": "2025-05-26T21:04:28.695734",
     "exception": false,
     "start_time": "2025-05-26T21:04:28.676097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python ((op_bench)",
   "language": "python",
   "name": "op_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25418.482169,
   "end_time": "2025-05-26T21:04:33.250060",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-smolvlm2-qwen2-5-vl.ipynb",
   "output_path": "qwen2-5-vl-32b_output.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T14:00:54.767891",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}