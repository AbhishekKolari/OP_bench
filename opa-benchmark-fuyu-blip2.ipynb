{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11436696,"sourceType":"datasetVersion","datasetId":7163706}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VLM Benchmark for Object Property Abstraction\n\nThis notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n\n1. Direct Recognition\n2. Property Inference\n3. Counterfactual Reasoning\n\nAnd three types of images:\n- REAL\n- ANIMATED\n- AI GENERATED","metadata":{}},{"cell_type":"markdown","source":"## Setup and Imports\n\nFirst, let's import the necessary libraries and set up our environment.","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!pip install transformers torch Pillow tqdm bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:43:57.040138Z","iopub.execute_input":"2025-04-16T14:43:57.040434Z","iopub.status.idle":"2025-04-16T14:45:25.499057Z","shell.execute_reply.started":"2025-04-16T14:43:57.040411Z","shell.execute_reply":"2025-04-16T14:45:25.498154Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import required libraries\nimport torch\nimport json\nfrom pathlib import Path\nfrom PIL import Image\nimport gc\nimport re\nfrom tqdm import tqdm\nfrom typing import List, Dict, Any\n\n# Check if CUDA is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:45:25.500564Z","iopub.execute_input":"2025-04-16T14:45:25.501027Z","iopub.status.idle":"2025-04-16T14:45:29.006707Z","shell.execute_reply.started":"2025-04-16T14:45:25.501005Z","shell.execute_reply":"2025-04-16T14:45:29.005946Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Benchmark Tester Class\n\nThis class handles the evaluation of models against our benchmark.","metadata":{}},{"cell_type":"code","source":"class BenchmarkTester:\n    def __init__(self, benchmark_path=\"/kaggle/input/opabenchmark/benchmark.json\", data_dir=\"/kaggle/input/opabenchmark/data\"):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        with open(benchmark_path, 'r') as f:\n            self.benchmark = json.load(f)\n        self.data_dir = data_dir\n    \n    def format_question(self, question, model_name):\n        \"\"\"Format a question for the model.\"\"\"\n\n        if model_name==\"blip2\":\n            return f\"Question: {question['question']} Answer(total number):\"\n        else:\n            return f\"Question: {question['question']} Answer with a number and list of objects. Answer:\"\n\n    def clean_answer(self, answer):\n        \"\"\"Clean the model output to extract just the number.\"\"\"\n        # Remove any text that's not a number\n        # import re\n        # numbers = re.findall(r'\\d+', answer)\n        # if numbers:\n        #     return numbers[0]  # Return the first number found\n        # return answer\n        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n        # Try to extract number and reasoning using regex\n        import re\n        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n        match = re.search(pattern, answer)\n        \n        if match:\n            number = match.group(1)\n            objects = [obj.strip() for obj in match.group(2).split(',')]\n            return {\n                \"count\": number,\n                \"reasoning\": objects\n            }\n        else:\n            # Fallback if format isn't matched\n            numbers = re.findall(r'\\d+', answer)\n            return {\n                \"count\": numbers[0] if numbers else \"0\",\n                \"reasoning\": []\n            }\n\n    def model_generation(self, model_name, model, inputs, processor):\n        \"\"\"Generate answer and decode.\"\"\"\n        outputs = None  # Initialize outputs to None\n        \n        if model_name==\"blip2\":\n            outputs = model.generate(**inputs)\n            answer = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n            \n        elif model_name==\"fuyu-8b\":\n            outputs = model.generate(\n                **inputs,\n                max_new_tokens=200,  # Increased from 10 to 200\n                pad_token_id=processor.tokenizer.eos_token_id\n            )\n            answer = processor.batch_decode(outputs[:, -200:], skip_special_tokens=True)[0]\n        else:\n            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n            answer = \"\"  # Return an empty string\n\n        return answer, outputs\n    \n    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n        results = []\n        print(f\"\\nEvaluating {model_name}...\")\n        print(f\"Using device: {self.device}\")\n        \n        # Force garbage collection before starting\n        gc.collect()\n        torch.cuda.empty_cache()\n\n        try:\n            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n            total_images = len(images)\n            \n            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n                try:\n                    print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n                    image_path = Path(self.data_dir)/image_data['path']\n                    if not image_path.exists():\n                        print(f\"Warning: Image not found at {image_path}\")\n                        continue\n                    \n                    # Load and preprocess image\n                    image = Image.open(image_path).convert(\"RGB\")\n                    image_results = []  # Store results for current image\n                    \n                    for question in image_data['questions']:\n                        try:\n                            prompt = self.format_question(question, model_name)\n                            print(f\"Question: {question['question']}\")\n                            \n                            # Clear cache before processing each question\n                            torch.cuda.empty_cache()\n                            \n                            # Process image and text\n                            inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n                            \n                            # Generate answer with better settings\n                            with torch.no_grad():\n                                answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n                                \n                            cleaned_answer = self.clean_answer(answer)\n                            \n                            image_results.append({\n                                \"image_id\": image_data[\"image_id\"],\n                                \"image_type\": image_data[\"image_type\"],\n                                \"question_id\": question[\"id\"],\n                                \"question\": question[\"question\"],\n                                \"ground_truth\": question[\"answer\"],\n                                \"model_answer\": cleaned_answer[\"count\"],\n                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n                                \"raw_answer\": answer,  # Keep raw answer for debugging\n                                \"property_category\": question[\"property_category\"]\n                            })\n                            \n                            # Clear memory\n                            del outputs, inputs\n                            torch.cuda.empty_cache()\n                            \n                        except Exception as e:\n                            print(f\"Error processing question: {str(e)}\")\n                            continue\n                    \n                    # Add results from this image\n                    results.extend(image_results)\n                    \n                    # Save intermediate results only every 2 images or if it's the last image\n                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n                        with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n                            json.dump(results, f, indent=4)\n                            \n                except Exception as e:\n                    print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n                    continue\n            \n            # Save final results\n            if results:\n                with open(save_path, 'w') as f:\n                    json.dump(results, f, indent=4)\n            \n        except Exception as e:\n            print(f\"An error occurred during evaluation: {str(e)}\")\n            if results:\n                with open(f\"{save_path}_error_state.json\", 'w') as f:\n                    json.dump(results, f, indent=4)\n        \n        return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:45:29.025942Z","iopub.execute_input":"2025-04-16T14:45:29.026716Z","iopub.status.idle":"2025-04-16T14:45:29.047360Z","shell.execute_reply.started":"2025-04-16T14:45:29.026694Z","shell.execute_reply":"2025-04-16T14:45:29.046851Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/opabenchmark/\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:45:29.047909Z","iopub.execute_input":"2025-04-16T14:45:29.048102Z","iopub.status.idle":"2025-04-16T14:45:29.068173Z","shell.execute_reply.started":"2025-04-16T14:45:29.048087Z","shell.execute_reply":"2025-04-16T14:45:29.067667Z"}},"outputs":[{"name":"stdout","text":"['data', 'benchmark.json']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Test Fuyu Model\n\nLet's evaluate the Fuyu-8b model on our benchmark.","metadata":{}},{"cell_type":"code","source":"def test_fuyu():\n    #from transformers import AutoModelForCausalLM, AutoTokenizer\n    from transformers import FuyuProcessor, FuyuForCausalLM\n    \n    print(\"Loading Fuyu-8b model...\")\n    model = FuyuForCausalLM.from_pretrained(\n        \"adept/fuyu-8b\",\n        # load_in_8bit=True,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        low_cpu_mem_usage=True\n    ).eval()\n    processor = FuyuProcessor.from_pretrained(\"adept/fuyu-8b\")\n\n    ## fuyu-8b is very slow and average performance\n\n    # Optional: Enable memory efficient attention\n    if hasattr(model.config, 'use_memory_efficient_attention'):\n        model.config.use_memory_efficient_attention = True\n        \n    tester = BenchmarkTester()\n    fuyu_results = tester.evaluate_model(\n        \"fuyu-8b\",\n        model, \n        processor, \n        \"fuyu_results.json\", \n        batch_size=1\n    )\n    # tester.save_results(\"fuyu_results.json\")\n\n    if fuyu_results is not None:\n        print(\"Initial test successful!\")\n    \n    # Clean up\n    del model, processor\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:45:29.068878Z","iopub.execute_input":"2025-04-16T14:45:29.069123Z","iopub.status.idle":"2025-04-16T14:45:29.083334Z","shell.execute_reply.started":"2025-04-16T14:45:29.069101Z","shell.execute_reply":"2025-04-16T14:45:29.082860Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Test BLIP-2 Model\n\nNow let's evaluate the blip2 model.","metadata":{}},{"cell_type":"code","source":"def test_blip2():\n    from transformers import Blip2Processor, Blip2ForConditionalGeneration\n    \n    print(\"Loading BLIP-2 model...\")\n    model = Blip2ForConditionalGeneration.from_pretrained(\n        \"Salesforce/blip2-opt-2.7b\",\n        # load_in_8bit=True,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        low_cpu_mem_usage=True\n    ).eval()\n    processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n\n    ## opt-2.7b average performance, better instruction following \n        # Format - Answer(total number):\n    ## opt-6.7b(8bit) better performance with atleast answering, not well-instruction tuned, but provides number for answers\n        # Format - Answer(total number):\n    ## flan-t5-xl does fine but needs a lot of post processing, does not follow instructions to clearly\n        # Format - Answer(provide total number):\n    ## flan-t5-xxl(8bit) decent performance, better with instruction I think, slight postprocessing needed\n        # Format - Answer:\n    \n    # Optional: Enable memory efficient attention\n    if hasattr(model.config, 'use_memory_efficient_attention'):\n        model.config.use_memory_efficient_attention = True\n    \n    tester = BenchmarkTester()\n    blip2_results = tester.evaluate_model(\n        \"blip2\",\n        model, \n        processor, \n        \"blip2-opt2.7b_results.json\", \n        batch_size=25\n    )\n    # tester.save_results(\"blip2_results.json\")\n\n    if blip2_results is not None:\n        print(\"Initial test successful!\")\n    \n    # Clean up\n    del model, processor\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:45:29.084248Z","iopub.execute_input":"2025-04-16T14:45:29.084480Z","iopub.status.idle":"2025-04-16T14:45:29.100608Z","shell.execute_reply.started":"2025-04-16T14:45:29.084459Z","shell.execute_reply":"2025-04-16T14:45:29.100098Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Run Evaluation\n\nNow we can run our evaluation. Let's start with the Fuyu model:","metadata":{}},{"cell_type":"code","source":"test_fuyu()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:14:46.661896Z","iopub.execute_input":"2025-04-16T14:14:46.662203Z","iopub.status.idle":"2025-04-16T14:14:48.773339Z","shell.execute_reply.started":"2025-04-16T14:14:46.662181Z","shell.execute_reply":"2025-04-16T14:14:48.772372Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2802427009.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_fuyu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/2356691551.py\u001b[0m in \u001b[0;36mtest_fuyu\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_fuyu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#from transformers import AutoModelForCausalLM, AutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuyuProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFuyuForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Fuyu-8b model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1968\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m             raise RuntimeError(\n","\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/fuyu/processing_fuyu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessingKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_validate_images_text_input_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTokenizedInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"And then the BLIP-2 model:","metadata":{}},{"cell_type":"code","source":"test_blip2()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T14:45:29.101273Z","iopub.execute_input":"2025-04-16T14:45:29.101479Z","iopub.status.idle":"2025-04-16T14:47:36.178423Z","shell.execute_reply.started":"2025-04-16T14:45:29.101451Z","shell.execute_reply":"2025-04-16T14:47:36.177872Z"}},"outputs":[{"name":"stderr","text":"2025-04-16 14:45:36.782962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744814737.055848      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744814737.141343      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Loading BLIP-2 model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cde83f220734a11b50a9723064f1fa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/122k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adfad18aa33849e5b5b58addd468f952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0587eda054a473b8879e64ea92dda06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487bf8befe8c48df9658ab49b97496a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6906f3c22f304c5385d837644ff32c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9b605089dd741d283290f6c95280991"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2785e31dca0946b6b6691cbad760133e"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f84fd9ce325489ea70393e9a3e7b1fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/882 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4266c4e0fcc44bee86d7b067e6843e76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"104e8e6e0d884a07837815c3fa903648"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a40ab552ee844e4baf80abe3d43749b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b4357124b14573b2b3c1918e73218e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d587afe8ca434ac09ac040392bc6938f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36194d1c1ea84ddb8889fca5f5492888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b15d4061e6144f187e95389d54a693d"}},"metadata":{}},{"name":"stdout","text":"\nEvaluating blip2...\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Processing images:   0%|          | 0/25 [00:00<?, ?it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 1/25: image01\nQuestion: How many objects made of wood are present?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: Count the number of breakable items?\nQuestion: If one of the metal objects were replaced by a wooden object, how many wooden objects would be there in the image?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:   4%|▍         | 1/25 [00:02<00:53,  2.22s/it]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 2/25: image02\nQuestion: How many mammals are present in the image?\nQuestion: Count the number of items that can store other items?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:   8%|▊         | 2/25 [00:02<00:26,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Question: If one of the zebra were replaced by a tree, how many mammals would be present in the image?\n\nProcessing image 3/25: image03\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects made of rubber are present?\nQuestion: How many objects with the primary purpose of illumination can be seen?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  12%|█▏        | 3/25 [00:03<00:19,  1.13it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If the person riding one of the bicycles were replaced by a pedestrian, how many objects that have handles would be present?\n\nProcessing image 4/25: image04\nQuestion: How many tools are visible in the image?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many cutting tools are present in this image?\nQuestion: If the red handle were replaced by a wooden handle, how many colored artifacts would remain in the image?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  16%|█▌        | 4/25 [00:03<00:14,  1.44it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 5/25: image05\nQuestion: How many furniture items are present that have legs?\nQuestion: Count the number of containers that cannot hold hot liquids?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  20%|██        | 5/25 [00:04<00:12,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Question: If the room were transformed into an open workspace instead of a meeting room, how many privacy features would need to be removed?\n\nProcessing image 6/25: image06\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many reptiles are visible in this enclosure?\nQuestion: How many reptilian couples, at maximum, are present?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  24%|██▍       | 6/25 [00:04<00:11,  1.73it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If all the small pebbles forming the mosaic floor were replaced with sand, how many natural elements would still be visible in the enclosure?\n\nProcessing image 7/25: image07\nQuestion: How many birds are visible in this image?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects are present that can comfortably seat a human?\nQuestion: If the birds sitting together only on one railing were to fly away, how many birds would remain?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  28%|██▊       | 7/25 [00:04<00:09,  1.95it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 8/25: image08\nQuestion: How many reptiles are visible in this image?\nQuestion: How many objects are present that act as support?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  32%|███▏      | 8/25 [00:05<00:08,  2.12it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If one turtle slid off the log into the water, how many turtles would be in the water?\n\nProcessing image 9/25: image09\nQuestion: How many different types of vegetables are present in the image?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects are used as containers?\nQuestion: If the bag of limes were removed and replaced with two additional avocados, how many fruits would be present in total on the table, considering avocados are fruits?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  36%|███▌      | 9/25 [00:05<00:07,  2.27it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 10/25: image10\nQuestion: How many objects are present that are flexible?\nQuestion: Count the number of items that are battery powered?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  40%|████      | 10/25 [00:06<00:06,  2.39it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If two phones with three camera lenses were replaced with phones having two camera lenses, how many phones with two camera lenses would be present?\n\nProcessing image 11/25: image01\nQuestion: How many mammals are present in total?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects are visible that can store items?\nQuestion: If the bear were to be replaced by a tree, how many different types of mammals would be there at the zoo?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  44%|████▍     | 11/25 [00:06<00:05,  2.52it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 12/25: image02\nQuestion: How many kitchen tools are visible in the image?\nQuestion: Count the number of items that require electricity to operate?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  48%|████▊     | 12/25 [00:06<00:05,  2.59it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If blinds were installed for the windows above the sink, how many transparent objects would remain?\n\nProcessing image 13/25: image03\nQuestion: How many objects made of glass are present?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many tools are visible that can be used for cutting?\nQuestion: If the worker was not wearing ear protection, how many protective items would remain?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  52%|█████▏    | 13/25 [00:07<00:04,  2.58it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 14/25: image04\nQuestion: How many objects made of rubber are present?\nQuestion: Excluding the drawers, how many items in the workshop serve as containers for storage?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  56%|█████▌    | 14/25 [00:07<00:04,  2.53it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If an electric fan were placed on the workstation to provide ventilation, how many objects in the room would require electricity to operate?\n\nProcessing image 15/25: image05\nQuestion: How many birds are visible in the image?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects are present that act as support?\nQuestion: If the clouds were to completely cover the sky, blocking the sunlight, how many natural elements would still be visible?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  60%|██████    | 15/25 [00:07<00:03,  2.56it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 16/25: image06\nQuestion: How many objects are present that have chimneys?\nQuestion: How many objects are visible that are means of transportation?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  64%|██████▍   | 16/25 [00:08<00:03,  2.57it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If the bus were replaced by a pedestrian, how many mammals would be present?\n\nProcessing image 17/25: image07\nQuestion: How many objects made of glass are present?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: Count the number of items that can be used to carry liquid?\nQuestion: If the waste to be disposed was color-coded to match the bins, how many objects are to be thrown in the bin on the right?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  68%|██████▊   | 17/25 [00:08<00:03,  2.55it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 18/25: image08\nQuestion: How many objects are present that have legs?\nQuestion: How many items are visible that are openable?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  72%|███████▏  | 18/25 [00:09<00:02,  2.53it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If the bottle was removed from the table, how many objects are present on top of the table?\n\nProcessing image 19/25: image09\nQuestion: How many objects made of wood are present?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many kitchen items are visible that can be used for cutting?\nQuestion: If the two jars on the top shelf were removed, how many breakable items would be present in the image?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  76%|███████▌  | 19/25 [00:09<00:02,  2.55it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 20/25: image10\nQuestion: How many objects made of plastic are visible?\nQuestion: How many items are visible that can record audio?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  80%|████████  | 20/25 [00:09<00:01,  2.60it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If the microphones were replaced with headsets for every character, how many objects in total would be present that are worn on the head?\n\nProcessing image 21/25: image01\nQuestion: How many objects made of rubber are visible?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects are visible that are means of transportation?\nQuestion: If the car in the driveway were to leave, how many objects primarily made of metal would be present?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  84%|████████▍ | 21/25 [00:10<00:01,  2.51it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 22/25: image02\nQuestion: How many objects made of concrete are present?\nQuestion: How many objects are visible that can be used for lifting?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  88%|████████▊ | 22/25 [00:10<00:01,  2.44it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If the orange paint spilled all over one of the plexiglass sheets, how many objects would remain that are transparent?\n\nProcessing image 23/25: image03\nQuestion: How many mammals are present in the image?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many objects are visible that are used for both meat and wool production?\nQuestion: If the two sheep were replaced by a cow grazing in the same area, how many objects would be present in between the two fences?\n","output_type":"stream"},{"name":"stderr","text":"Processing images:  92%|█████████▏| 23/25 [00:11<00:00,  2.43it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing image 24/25: image04\nQuestion: How many objects are visible that are made of paper?\nQuestion: How many objects are present that behave as storage spaces?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nProcessing images:  96%|█████████▌| 24/25 [00:11<00:00,  2.34it/s]The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: If the glasses were placed inside the ceramic container, and we use this container as a dividing line between the left and right sides of the bookshelf, how many objects would be on the right side?\n\nProcessing image 25/25: image05\nQuestion: How many objects are visible that are made of porcelain?\n","output_type":"stream"},{"name":"stderr","text":"The `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\nThe `language_model` is not in the `hf_device_map` dictionary and you are running your script in a multi-GPU environment. this may lead to unexpected behavior when using `accelerate`. Please pass a `device_map` that contains `language_model` to remove this warning. Please refer to https://github.com/huggingface/blog/blob/main/accelerate-large-models.md for more details on creating a `device_map` for large models.\n","output_type":"stream"},{"name":"stdout","text":"Question: How many decoration items are present in the image?\nQuestion: If the drinks were split evenly between the two humans, how many drinks would each human consume?\n","output_type":"stream"},{"name":"stderr","text":"Processing images: 100%|██████████| 25/25 [00:12<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Initial test successful!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}