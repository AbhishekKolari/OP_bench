{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873ae9cb",
   "metadata": {
    "papermill": {
     "duration": 0.00727,
     "end_time": "2025-07-28T21:12:10.344279",
     "exception": false,
     "start_time": "2025-07-28T21:12:10.337009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9dab35",
   "metadata": {
    "papermill": {
     "duration": 0.004986,
     "end_time": "2025-07-28T21:12:10.354785",
     "exception": false,
     "start_time": "2025-07-28T21:12:10.349799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e1f6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:10.365498Z",
     "iopub.status.busy": "2025-07-28T21:12:10.365232Z",
     "iopub.status.idle": "2025-07-28T21:12:12.108126Z",
     "shell.execute_reply": "2025-07-28T21:12:12.107175Z"
    },
    "papermill": {
     "duration": 1.749739,
     "end_time": "2025-07-28T21:12:12.109482",
     "exception": false,
     "start_time": "2025-07-28T21:12:10.359743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (4.51.1)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: Pillow in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (10.3.0)\r\n",
      "Requirement already satisfied: tqdm in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (4.66.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch Pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da6a29b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:12.128801Z",
     "iopub.status.busy": "2025-07-28T21:12:12.128406Z",
     "iopub.status.idle": "2025-07-28T21:12:15.728680Z",
     "shell.execute_reply": "2025-07-28T21:12:15.727721Z"
    },
    "papermill": {
     "duration": 3.607845,
     "end_time": "2025-07-28T21:12:15.730038",
     "exception": false,
     "start_time": "2025-07-28T21:12:12.122193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afb38a",
   "metadata": {
    "papermill": {
     "duration": 0.005355,
     "end_time": "2025-07-28T21:12:15.745234",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.739879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01fd3d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:15.757609Z",
     "iopub.status.busy": "2025-07-28T21:12:15.757200Z",
     "iopub.status.idle": "2025-07-28T21:12:15.767672Z",
     "shell.execute_reply": "2025-07-28T21:12:15.766937Z"
    },
    "papermill": {
     "duration": 0.018041,
     "end_time": "2025-07-28T21:12:15.768772",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.750731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BenchmarkTester:\n",
    "#     def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "#         self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#         with open(benchmark_path, 'r') as f:\n",
    "#             self.benchmark = json.load(f)\n",
    "#         self.data_dir = data_dir\n",
    "    \n",
    "#     def format_question(self, question, model_name):\n",
    "#         \"\"\"Format a question for the model.\"\"\"\n",
    "\n",
    "#         if model_name==\"blip2\":\n",
    "#             return f\"Question: {question['question']} Provide only the total number. Answer:\" #Provide just the total count and the list of objects in the given format \\n Format: number [objects] Answer: \"\n",
    "#         else:\n",
    "#             return f\"Question: {question['question']} Answer(total number):\"\n",
    "\n",
    "#     def clean_answer(self, answer):\n",
    "#         \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "#         # Remove any text that's not a number\n",
    "#         # import re\n",
    "#         # numbers = re.findall(r'\\d+', answer)\n",
    "#         # if numbers:\n",
    "#         #     return numbers[0]  # Return the first number found\n",
    "#         # return answer\n",
    "#         \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "#         # Try to extract number and reasoning using regex\n",
    "#         import re\n",
    "#         pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "#         match = re.search(pattern, answer)\n",
    "        \n",
    "#         if match:\n",
    "#             number = match.group(1)\n",
    "#             objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "#             return {\n",
    "#                 \"count\": number,\n",
    "#                 \"reasoning\": objects\n",
    "#             }\n",
    "#         else:\n",
    "#             # Fallback if format isn't matched\n",
    "#             numbers = re.findall(r'\\d+', answer)\n",
    "#             return {\n",
    "#                 \"count\": numbers[0] if numbers else \"0\",\n",
    "#                 \"reasoning\": []\n",
    "#             }\n",
    "\n",
    "#     def model_generation(self, model_name, model, inputs, processor):\n",
    "#         \"\"\"Generate answer and decode.\"\"\"\n",
    "#         outputs = None  # Initialize outputs to None\n",
    "        \n",
    "#         if model_name==\"blip2\":\n",
    "#             outputs = model.generate(**inputs)\n",
    "#             answer = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "            \n",
    "#         elif model_name==\"fuyu-8b\":\n",
    "#             outputs = model.generate(\n",
    "#                 **inputs,\n",
    "#                 max_new_tokens=30,  # Increased from 10 to 200\n",
    "#                 pad_token_id=processor.tokenizer.eos_token_id\n",
    "#             )\n",
    "#             answer = processor.batch_decode(outputs[:, -30:], skip_special_tokens=True)[0]\n",
    "#         else:\n",
    "#             print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "#             answer = \"\"  # Return an empty string\n",
    "\n",
    "#         return answer, outputs\n",
    "    \n",
    "#     def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "#         results = []\n",
    "#         print(f\"\\nEvaluating {model_name}...\")\n",
    "#         print(f\"Using device: {self.device}\")\n",
    "        \n",
    "#         # Force garbage collection before starting\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         try:\n",
    "#             images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "#             total_images = len(images)\n",
    "            \n",
    "#             for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "#                 try:\n",
    "#                     print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "#                     image_path = Path(self.data_dir)/image_data['path']\n",
    "#                     if not image_path.exists():\n",
    "#                         print(f\"Warning: Image not found at {image_path}\")\n",
    "#                         continue\n",
    "                    \n",
    "#                     # Load and preprocess image\n",
    "#                     image = Image.open(image_path).convert(\"RGB\")\n",
    "#                     image_results = []  # Store results for current image\n",
    "                    \n",
    "#                     for question in image_data['questions']:\n",
    "#                         try:\n",
    "#                             prompt = self.format_question(question, model_name)\n",
    "#                             print(f\"Question: {question['question']}\")\n",
    "                            \n",
    "#                             # Clear cache before processing each question\n",
    "#                             torch.cuda.empty_cache()\n",
    "                            \n",
    "#                             # Process image and text\n",
    "#                             inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "                            \n",
    "#                             # Generate answer with better settings\n",
    "#                             with torch.no_grad():\n",
    "#                                 answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n",
    "                                \n",
    "#                             cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "#                             image_results.append({\n",
    "#                                 \"image_id\": image_data[\"image_id\"],\n",
    "#                                 \"image_type\": image_data[\"image_type\"],\n",
    "#                                 \"question_id\": question[\"id\"],\n",
    "#                                 \"question\": question[\"question\"],\n",
    "#                                 \"ground_truth\": question[\"answer\"],\n",
    "#                                 \"model_answer\": cleaned_answer[\"count\"],\n",
    "#                                 \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "#                                 \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "#                                 \"property_category\": question[\"property_category\"]\n",
    "#                             })\n",
    "                            \n",
    "#                             # Clear memory\n",
    "#                             del outputs, inputs\n",
    "#                             torch.cuda.empty_cache()\n",
    "                            \n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing question: {str(e)}\")\n",
    "#                             continue\n",
    "                    \n",
    "#                     # Add results from this image\n",
    "#                     results.extend(image_results)\n",
    "                    \n",
    "#                     # Save intermediate results only every 2 images or if it's the last image\n",
    "#                     if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "#                         with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "#                             json.dump(results, f, indent=4)\n",
    "                            \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "#                     continue\n",
    "            \n",
    "#             # Save final results\n",
    "#             if results:\n",
    "#                 with open(save_path, 'w') as f:\n",
    "#                     json.dump(results, f, indent=4)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "#             if results:\n",
    "#                 with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "#                     json.dump(results, f, indent=4)\n",
    "        \n",
    "#         return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94ee303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:15.780805Z",
     "iopub.status.busy": "2025-07-28T21:12:15.780519Z",
     "iopub.status.idle": "2025-07-28T21:12:15.812086Z",
     "shell.execute_reply": "2025-07-28T21:12:15.811351Z"
    },
    "papermill": {
     "duration": 0.039113,
     "end_time": "2025-07-28T21:12:15.813218",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.774105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "    \n",
    "    def format_question(self, question, model_name):\n",
    "        \"\"\"Format a question for the model.\"\"\"\n",
    "        if model_name==\"blip2\":\n",
    "        #     return f\"Question: {question['question']} Provide only the total number. Answer:\"\n",
    "        # else:\n",
    "            return f\"Question: {question['question']} Answer(total number):\"\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    def model_generation(self, model_name, model, inputs, processor):\n",
    "        \"\"\"Generate answer and decode with greedy decoding.\"\"\"\n",
    "        outputs = None  # Initialize outputs to None\n",
    "        \n",
    "        if model_name==\"blip2\":\n",
    "            # Explicit greedy decoding parameters for BLIP2\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=50,\n",
    "                do_sample=False,          # Disable sampling for greedy decoding\n",
    "                temperature=None,         # Not used in greedy decoding\n",
    "                top_p=None,              # Not used in greedy decoding  \n",
    "                top_k=None,              # Not used in greedy decoding\n",
    "                num_beams=1,             # Single beam for greedy decoding\n",
    "                early_stopping=False,    # Let it generate until max_tokens or EOS\n",
    "            )\n",
    "            answer = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "            \n",
    "        elif model_name==\"fuyu-8b\":\n",
    "            # Explicit greedy decoding parameters for Fuyu-8B\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=30,\n",
    "                do_sample=False,          # Disable sampling for greedy decoding\n",
    "                temperature=None,         # Not used in greedy decoding\n",
    "                top_p=None,              # Not used in greedy decoding  \n",
    "                top_k=None,              # Not used in greedy decoding\n",
    "                num_beams=1,             # Single beam for greedy decoding\n",
    "                early_stopping=False,    # Let it generate until max_tokens or EOS\n",
    "                pad_token_id=processor.tokenizer.eos_token_id\n",
    "            )\n",
    "            answer = processor.batch_decode(outputs[:, -30:], skip_special_tokens=True)[0]\n",
    "        else:\n",
    "            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "            answer = \"\"  # Return an empty string\n",
    "\n",
    "        return answer, outputs\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        successful_images = []\n",
    "        failed_images = []\n",
    "        total_questions_processed = 0\n",
    "        total_questions_failed = 0\n",
    "        \n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                image_start_time = time.time()\n",
    "                current_image_questions_failed = 0\n",
    "                current_image_questions_total = 0\n",
    "                \n",
    "                try:\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        failed_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'error_type': 'file_not_found',\n",
    "                            'error_message': f'Image not found at {image_path}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question_idx, question in enumerate(image_data['questions']):\n",
    "                        current_image_questions_total += 1\n",
    "                        total_questions_processed += 1\n",
    "                        \n",
    "                        try:\n",
    "                            prompt = self.format_question(question, model_name)\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            # Process image and text\n",
    "                            inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "                            \n",
    "                            # Generate answer with greedy decoding\n",
    "                            with torch.no_grad():\n",
    "                                answer, outputs = self.model_generation(model_name, model, inputs, processor)\n",
    "                                \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data.get(\"image_type\", \"unknown\"),\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            current_image_questions_failed += 1\n",
    "                            total_questions_failed += 1\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Calculate success rate for this image\n",
    "                    questions_succeeded = current_image_questions_total - current_image_questions_failed\n",
    "                    \n",
    "                    if current_image_questions_failed == 0:\n",
    "                        # All questions succeeded\n",
    "                        successful_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'questions_total': current_image_questions_total,\n",
    "                            'questions_succeeded': questions_succeeded,\n",
    "                            'processing_time': time.time() - image_start_time\n",
    "                        })\n",
    "                    else:\n",
    "                        # Some questions failed\n",
    "                        image_success_rate = (questions_succeeded / current_image_questions_total * 100) if current_image_questions_total > 0 else 0\n",
    "                        failed_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'error_type': 'partial_failure',\n",
    "                            'questions_total': current_image_questions_total,\n",
    "                            'questions_failed': current_image_questions_failed,\n",
    "                            'questions_succeeded': questions_succeeded,\n",
    "                            'success_rate': f\"{image_success_rate:.1f}%\"\n",
    "                        })\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        checkpoint_path = f\"{save_path}_checkpoint.json\"\n",
    "                        with open(checkpoint_path, 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    failed_images.append({\n",
    "                        'image_id': image_data['image_id'],\n",
    "                        'image_type': image_data.get('image_type', 'unknown'),\n",
    "                        'error_type': 'complete_failure',\n",
    "                        'error_message': str(e)\n",
    "                    })\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if results:\n",
    "                error_save_path = f\"{save_path}_error_state.json\"\n",
    "                with open(error_save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        # Print comprehensive summary\n",
    "        self._print_evaluation_summary(\n",
    "            model_name, total_images, successful_images, failed_images, \n",
    "            total_questions_processed, total_questions_failed, len(results)\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _print_evaluation_summary(self, model_name, total_images, successful_images, \n",
    "                                failed_images, total_questions_processed, total_questions_failed, total_results):\n",
    "        \"\"\"Print a comprehensive evaluation summary.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EVALUATION SUMMARY FOR {model_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Image-level statistics\n",
    "        num_successful = len(successful_images)\n",
    "        num_failed = len(failed_images)\n",
    "        \n",
    "        print(f\"📊 IMAGE PROCESSING SUMMARY:\")\n",
    "        print(f\"   Total images attempted: {total_images}\")\n",
    "        print(f\"   Successfully processed: {num_successful} ({num_successful/total_images*100:.1f}%)\")\n",
    "        print(f\"   Failed images: {num_failed} ({num_failed/total_images*100:.1f}%)\")\n",
    "        \n",
    "        # Question-level statistics\n",
    "        questions_succeeded = total_questions_processed - total_questions_failed\n",
    "        print(f\"\\n📝 QUESTION PROCESSING SUMMARY:\")\n",
    "        print(f\"   Total questions attempted: {total_questions_processed}\")\n",
    "        print(f\"   Successfully processed: {questions_succeeded} ({questions_succeeded/total_questions_processed*100:.1f}%)\")\n",
    "        print(f\"   Failed questions: {total_questions_failed} ({total_questions_failed/total_questions_processed*100:.1f}%)\")\n",
    "        print(f\"   Results saved: {total_results}\")\n",
    "        \n",
    "        # Successful images details\n",
    "        if successful_images:\n",
    "            print(f\"\\n✅ SUCCESSFUL IMAGES ({len(successful_images)}):\")\n",
    "            for img in successful_images:\n",
    "                print(f\"   • {img['image_id']} (Type: {img['image_type']}, \"\n",
    "                      f\"Questions: {img['questions_succeeded']}/{img['questions_total']}, \"\n",
    "                      f\"Time: {img['processing_time']:.1f}s)\")\n",
    "        \n",
    "        # Failed images details\n",
    "        if failed_images:\n",
    "            print(f\"\\n❌ FAILED/PROBLEMATIC IMAGES ({len(failed_images)}):\")\n",
    "            for img in failed_images:\n",
    "                if img['error_type'] == 'complete_failure':\n",
    "                    print(f\"   • {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"COMPLETE FAILURE: {img.get('error_message', 'Unknown error')}\")\n",
    "                elif img['error_type'] == 'partial_failure':\n",
    "                    print(f\"   • {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"PARTIAL: {img['questions_failed']}/{img['questions_total']} failed \"\n",
    "                          f\"({img['success_rate']} success)\")\n",
    "                elif img['error_type'] == 'file_not_found':\n",
    "                    print(f\"   • {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"FILE NOT FOUND: {img['error_message']}\")\n",
    "        \n",
    "        # Group failed images by type\n",
    "        if failed_images:\n",
    "            print(f\"\\n📈 FAILURE ANALYSIS BY IMAGE TYPE:\")\n",
    "            from collections import defaultdict\n",
    "            failures_by_type = defaultdict(list)\n",
    "            for img in failed_images:\n",
    "                failures_by_type[img['image_type']].append(img)\n",
    "            \n",
    "            for img_type, failures in failures_by_type.items():\n",
    "                print(f\"   • {img_type}: {len(failures)} failed images\")\n",
    "                for failure in failures:\n",
    "                    print(f\"     - {failure['image_id']} ({failure['error_type']})\")\n",
    "        \n",
    "        print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d628d79",
   "metadata": {
    "papermill": {
     "duration": 0.005411,
     "end_time": "2025-07-28T21:12:15.824151",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.818740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Fuyu Model\n",
    "\n",
    "Let's evaluate the Fuyu-8b model on our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6256801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:15.835804Z",
     "iopub.status.busy": "2025-07-28T21:12:15.835519Z",
     "iopub.status.idle": "2025-07-28T21:12:15.840856Z",
     "shell.execute_reply": "2025-07-28T21:12:15.840125Z"
    },
    "papermill": {
     "duration": 0.012431,
     "end_time": "2025-07-28T21:12:15.841976",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.829545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_fuyu():\n",
    "    #from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    from transformers import FuyuProcessor, FuyuForCausalLM\n",
    "    \n",
    "    print(\"Loading Fuyu-8b model...\")\n",
    "    model = FuyuForCausalLM.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/fuyu-8b\",\n",
    "        # load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "    processor = FuyuProcessor.from_pretrained(\"/var/scratch/ave303/models/fuyu-8b\")\n",
    "\n",
    "    ## fuyu-8b is very slow and average performance\n",
    "\n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "        \n",
    "    tester = BenchmarkTester()\n",
    "    fuyu_results = tester.evaluate_model(\n",
    "        \"fuyu-8b\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"fuyu_8b_results.json\", \n",
    "        batch_size=360\n",
    "    )\n",
    "    # tester.save_results(\"fuyu_results.json\")\n",
    "\n",
    "    if fuyu_results is not None:\n",
    "        print(\"Initial test successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aac956",
   "metadata": {
    "papermill": {
     "duration": 0.005314,
     "end_time": "2025-07-28T21:12:15.852997",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.847683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test BLIP-2 Model\n",
    "\n",
    "Now let's evaluate the blip2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5090d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:15.864720Z",
     "iopub.status.busy": "2025-07-28T21:12:15.864431Z",
     "iopub.status.idle": "2025-07-28T21:12:15.870015Z",
     "shell.execute_reply": "2025-07-28T21:12:15.869298Z"
    },
    "papermill": {
     "duration": 0.012758,
     "end_time": "2025-07-28T21:12:15.871247",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.858489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_blip2():\n",
    "    from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "    \n",
    "    print(\"Loading BLIP-2 model...\")\n",
    "    model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/blip2opt2.7b\",\n",
    "        # load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        # temperature=0.8,\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "    processor = Blip2Processor.from_pretrained(\"/var/scratch/ave303/models/blip2opt2.7b\")\n",
    "\n",
    "    ## opt-2.7b average performance, better instruction following \n",
    "        # Format - Answer(total number):\n",
    "    ## opt-6.7b(8bit) better performance with atleast answering, not well-instruction tuned, but provides number for answers\n",
    "        # Format - Answer(total number):\n",
    "    ## flan-t5-xl does fine but needs a lot of post processing, does not follow instructions to clearly\n",
    "        # Format - Answer(provide total number):\n",
    "    ## flan-t5-xxl(8bit) decent performance, better with instruction I think, slight postprocessing needed\n",
    "        # Format - Answer:\n",
    "    \n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "    \n",
    "    tester = BenchmarkTester()\n",
    "    blip2_results = tester.evaluate_model(\n",
    "        \"blip2\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"blip2-opt-2.7b_results.json\", \n",
    "        batch_size=360\n",
    "    )\n",
    "    # tester.save_results(\"blip2_results.json\")\n",
    "\n",
    "    if blip2_results is not None:\n",
    "        print(\"Initial test successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbee2f",
   "metadata": {
    "papermill": {
     "duration": 0.005188,
     "end_time": "2025-07-28T21:12:15.881788",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.876600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the Fuyu model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d130e94",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:15.893367Z",
     "iopub.status.busy": "2025-07-28T21:12:15.893090Z",
     "iopub.status.idle": "2025-07-28T21:12:15.896332Z",
     "shell.execute_reply": "2025-07-28T21:12:15.895629Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.010311,
     "end_time": "2025-07-28T21:12:15.897500",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.887189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fuyu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648a783",
   "metadata": {
    "papermill": {
     "duration": 0.005281,
     "end_time": "2025-07-28T21:12:15.908068",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.902787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And then the BLIP-2 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ef03b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T21:12:15.919558Z",
     "iopub.status.busy": "2025-07-28T21:12:15.919268Z",
     "iopub.status.idle": "2025-07-28T21:14:24.488000Z",
     "shell.execute_reply": "2025-07-28T21:14:24.487104Z"
    },
    "papermill": {
     "duration": 128.575885,
     "end_time": "2025-07-28T21:14:24.489254",
     "exception": false,
     "start_time": "2025-07-28T21:12:15.913369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP-2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating blip2...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   0%|          | 0/360 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   0%|          | 1/360 [00:01<07:57,  1.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 2/360 [00:01<04:25,  1.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 3/360 [00:02<03:40,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 4/360 [00:02<02:56,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|▏         | 5/360 [00:02<02:42,  2.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▏         | 6/360 [00:03<02:22,  2.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▏         | 7/360 [00:03<01:57,  3.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▏         | 8/360 [00:03<01:39,  3.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▎         | 9/360 [00:03<01:27,  4.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|▎         | 10/360 [00:03<01:19,  4.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|▎         | 11/360 [00:04<01:19,  4.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|▎         | 12/360 [00:04<01:16,  4.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▎         | 13/360 [00:04<01:10,  4.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▍         | 14/360 [00:04<01:09,  4.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▍         | 15/360 [00:04<01:16,  4.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▍         | 16/360 [00:05<01:23,  4.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|▍         | 17/360 [00:05<01:16,  4.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|▌         | 18/360 [00:05<01:11,  4.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|▌         | 19/360 [00:05<01:10,  4.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▌         | 20/360 [00:05<01:12,  4.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▌         | 21/360 [00:06<01:10,  4.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▌         | 22/360 [00:07<02:34,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▋         | 23/360 [00:08<03:37,  1.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|▋         | 24/360 [00:08<02:52,  1.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|▋         | 25/360 [00:08<02:17,  2.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|▋         | 26/360 [00:08<01:56,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 27/360 [00:09<01:40,  3.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 28/360 [00:09<01:27,  3.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 29/360 [00:09<01:17,  4.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 30/360 [00:09<01:14,  4.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▊         | 31/360 [00:09<01:12,  4.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▉         | 32/360 [00:10<01:09,  4.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▉         | 33/360 [00:10<01:09,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▉         | 34/360 [00:10<01:06,  4.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|▉         | 35/360 [00:10<01:05,  4.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|█         | 36/360 [00:10<01:03,  5.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|█         | 37/360 [00:11<01:04,  5.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█         | 38/360 [00:11<01:07,  4.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█         | 39/360 [00:11<01:07,  4.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█         | 40/360 [00:11<01:09,  4.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█▏        | 41/360 [00:11<01:05,  4.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▏        | 42/360 [00:12<01:06,  4.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▏        | 43/360 [00:12<01:05,  4.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▏        | 44/360 [00:12<01:11,  4.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▎        | 45/360 [00:12<01:11,  4.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|█▎        | 46/360 [00:12<01:08,  4.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|█▎        | 47/360 [00:13<01:06,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|█▎        | 48/360 [00:13<01:04,  4.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▎        | 49/360 [00:13<01:04,  4.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▍        | 50/360 [00:13<01:09,  4.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▍        | 51/360 [00:14<01:10,  4.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▍        | 52/360 [00:14<01:09,  4.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|█▍        | 53/360 [00:14<01:09,  4.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|█▌        | 54/360 [00:15<01:47,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|█▌        | 55/360 [00:15<01:40,  3.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▌        | 56/360 [00:16<02:37,  1.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▌        | 57/360 [00:16<02:17,  2.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▌        | 58/360 [00:16<01:57,  2.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▋        | 59/360 [00:17<01:41,  2.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|█▋        | 60/360 [00:17<01:41,  2.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|█▋        | 61/360 [00:17<01:37,  3.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|█▋        | 62/360 [00:18<01:32,  3.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 63/360 [00:18<01:30,  3.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 64/360 [00:18<01:37,  3.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 65/360 [00:18<01:25,  3.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 66/360 [00:19<01:16,  3.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▊        | 67/360 [00:19<01:17,  3.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▉        | 68/360 [00:19<01:17,  3.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▉        | 69/360 [00:19<01:17,  3.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▉        | 70/360 [00:20<01:21,  3.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|█▉        | 71/360 [00:20<01:27,  3.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|██        | 72/360 [00:20<01:23,  3.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|██        | 73/360 [00:21<01:20,  3.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██        | 74/360 [00:21<01:16,  3.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██        | 75/360 [00:22<01:55,  2.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██        | 76/360 [00:22<01:43,  2.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██▏       | 77/360 [00:22<01:32,  3.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▏       | 78/360 [00:23<01:44,  2.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▏       | 79/360 [00:23<01:50,  2.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▏       | 80/360 [00:23<01:54,  2.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▎       | 81/360 [00:24<01:54,  2.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|██▎       | 82/360 [00:24<01:55,  2.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|██▎       | 83/360 [00:25<01:36,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|██▎       | 84/360 [00:25<01:49,  2.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▎       | 85/360 [00:25<01:50,  2.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▍       | 86/360 [00:26<01:33,  2.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▍       | 87/360 [00:26<01:27,  3.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▍       | 88/360 [00:26<01:23,  3.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|██▍       | 89/360 [00:27<01:27,  3.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|██▌       | 90/360 [00:27<01:32,  2.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|██▌       | 91/360 [00:27<01:20,  3.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▌       | 92/360 [00:28<01:52,  2.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▌       | 93/360 [00:28<01:39,  2.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▌       | 94/360 [00:28<01:31,  2.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▋       | 95/360 [00:29<01:25,  3.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|██▋       | 96/360 [00:29<01:27,  3.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|██▋       | 97/360 [00:29<01:30,  2.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|██▋       | 98/360 [00:30<01:25,  3.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 99/360 [00:30<01:39,  2.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 100/360 [00:30<01:30,  2.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 101/360 [00:31<01:22,  3.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 102/360 [00:31<01:19,  3.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▊       | 103/360 [00:31<01:17,  3.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▉       | 104/360 [00:32<01:14,  3.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▉       | 105/360 [00:32<01:10,  3.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▉       | 106/360 [00:32<01:14,  3.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|██▉       | 107/360 [00:32<01:11,  3.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|███       | 108/360 [00:33<01:18,  3.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|███       | 109/360 [00:33<01:22,  3.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███       | 110/360 [00:33<01:24,  2.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███       | 111/360 [00:34<01:26,  2.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███       | 112/360 [00:34<01:19,  3.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███▏      | 113/360 [00:34<01:09,  3.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▏      | 114/360 [00:35<01:07,  3.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▏      | 115/360 [00:35<01:08,  3.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▏      | 116/360 [00:35<01:14,  3.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▎      | 117/360 [00:35<01:11,  3.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|███▎      | 118/360 [00:36<01:08,  3.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|███▎      | 119/360 [00:36<01:05,  3.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|███▎      | 120/360 [00:36<01:05,  3.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▎      | 121/360 [00:36<00:56,  4.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▍      | 122/360 [00:37<00:52,  4.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▍      | 123/360 [00:37<00:50,  4.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▍      | 124/360 [00:37<00:51,  4.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|███▍      | 125/360 [00:37<00:49,  4.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|███▌      | 126/360 [00:37<00:48,  4.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|███▌      | 127/360 [00:38<00:47,  4.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▌      | 128/360 [00:38<00:48,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▌      | 129/360 [00:38<00:48,  4.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▌      | 130/360 [00:39<01:29,  2.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▋      | 131/360 [00:39<01:28,  2.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|███▋      | 132/360 [00:39<01:21,  2.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|███▋      | 133/360 [00:40<01:18,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|███▋      | 134/360 [00:40<01:07,  3.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 135/360 [00:40<01:09,  3.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 136/360 [00:41<01:19,  2.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 137/360 [00:41<01:10,  3.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 138/360 [00:41<01:03,  3.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▊      | 139/360 [00:41<00:56,  3.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▉      | 140/360 [00:42<00:54,  4.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▉      | 141/360 [00:42<01:19,  2.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▉      | 142/360 [00:43<01:16,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|███▉      | 143/360 [00:43<01:47,  2.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|████      | 144/360 [00:44<01:27,  2.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|████      | 145/360 [00:44<01:13,  2.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████      | 146/360 [00:44<01:03,  3.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████      | 147/360 [00:44<00:56,  3.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████      | 148/360 [00:44<00:51,  4.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████▏     | 149/360 [00:45<00:47,  4.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▏     | 150/360 [00:45<00:44,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▏     | 151/360 [00:45<00:42,  4.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▏     | 152/360 [00:45<00:41,  4.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▎     | 153/360 [00:45<00:40,  5.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|████▎     | 154/360 [00:46<00:40,  5.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|████▎     | 155/360 [00:46<00:39,  5.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|████▎     | 156/360 [00:46<00:40,  4.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▎     | 157/360 [00:46<00:39,  5.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▍     | 158/360 [00:46<00:39,  5.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▍     | 159/360 [00:47<00:38,  5.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▍     | 160/360 [00:47<00:38,  5.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|████▍     | 161/360 [00:47<01:02,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|████▌     | 162/360 [00:48<01:03,  3.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|████▌     | 163/360 [00:48<01:19,  2.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▌     | 164/360 [00:49<02:09,  1.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▌     | 165/360 [00:50<02:12,  1.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▌     | 166/360 [00:51<02:24,  1.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▋     | 167/360 [00:52<02:03,  1.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|████▋     | 168/360 [00:52<01:45,  1.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|████▋     | 169/360 [00:52<01:35,  2.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|████▋     | 170/360 [00:53<01:23,  2.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 171/360 [00:53<01:38,  1.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 172/360 [00:54<01:53,  1.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 173/360 [00:55<01:57,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 174/360 [00:55<01:32,  2.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▊     | 175/360 [00:55<01:14,  2.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▉     | 176/360 [00:55<01:01,  2.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▉     | 177/360 [00:55<00:52,  3.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▉     | 178/360 [00:56<01:15,  2.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|████▉     | 179/360 [00:57<01:31,  1.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|█████     | 180/360 [00:57<01:13,  2.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|█████     | 181/360 [00:57<01:02,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████     | 182/360 [00:57<00:55,  3.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████     | 183/360 [00:58<00:50,  3.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████     | 184/360 [00:58<00:44,  3.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████▏    | 185/360 [00:58<00:42,  4.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▏    | 186/360 [00:58<00:41,  4.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▏    | 187/360 [00:59<00:41,  4.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▏    | 188/360 [00:59<00:41,  4.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▎    | 189/360 [00:59<00:40,  4.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|█████▎    | 190/360 [00:59<00:41,  4.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|█████▎    | 191/360 [01:00<00:40,  4.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|█████▎    | 192/360 [01:00<00:40,  4.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▎    | 193/360 [01:00<00:39,  4.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▍    | 194/360 [01:00<00:39,  4.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▍    | 195/360 [01:00<00:38,  4.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▍    | 196/360 [01:01<00:38,  4.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|█████▍    | 197/360 [01:01<00:37,  4.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|█████▌    | 198/360 [01:01<00:37,  4.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|█████▌    | 199/360 [01:01<00:37,  4.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▌    | 200/360 [01:02<00:37,  4.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▌    | 201/360 [01:02<00:36,  4.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▌    | 202/360 [01:02<00:36,  4.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▋    | 203/360 [01:02<00:35,  4.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▋    | 204/360 [01:03<01:03,  2.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▋    | 205/360 [01:03<00:55,  2.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▋    | 206/360 [01:04<00:47,  3.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▊    | 207/360 [01:04<00:41,  3.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|█████▊    | 208/360 [01:04<00:37,  4.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|█████▊    | 209/360 [01:04<00:34,  4.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|█████▊    | 210/360 [01:04<00:32,  4.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▊    | 211/360 [01:05<00:30,  4.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▉    | 212/360 [01:05<00:29,  5.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▉    | 213/360 [01:05<00:28,  5.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▉    | 214/360 [01:05<00:27,  5.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|█████▉    | 215/360 [01:05<00:27,  5.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|██████    | 216/360 [01:05<00:27,  5.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|██████    | 217/360 [01:06<00:31,  4.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████    | 218/360 [01:06<00:30,  4.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████    | 219/360 [01:06<00:30,  4.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████    | 220/360 [01:06<00:30,  4.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████▏   | 221/360 [01:07<00:30,  4.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▏   | 222/360 [01:07<00:29,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▏   | 223/360 [01:07<00:27,  5.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▏   | 224/360 [01:07<00:28,  4.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▎   | 225/360 [01:07<00:26,  5.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|██████▎   | 226/360 [01:08<00:25,  5.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|██████▎   | 227/360 [01:08<00:24,  5.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|██████▎   | 228/360 [01:08<00:24,  5.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▎   | 229/360 [01:08<00:25,  5.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▍   | 230/360 [01:09<00:40,  3.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▍   | 231/360 [01:09<00:54,  2.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▍   | 232/360 [01:11<01:31,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|██████▍   | 233/360 [01:11<01:28,  1.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|██████▌   | 234/360 [01:12<01:14,  1.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|██████▌   | 235/360 [01:12<01:17,  1.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▌   | 236/360 [01:13<01:26,  1.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▌   | 237/360 [01:14<01:22,  1.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▌   | 238/360 [01:15<01:21,  1.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▋   | 239/360 [01:15<01:21,  1.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|██████▋   | 240/360 [01:16<01:22,  1.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|██████▋   | 241/360 [01:16<01:04,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|██████▋   | 242/360 [01:16<00:53,  2.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 243/360 [01:17<00:44,  2.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 244/360 [01:17<00:39,  2.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 245/360 [01:17<00:34,  3.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 246/360 [01:17<00:30,  3.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▊   | 247/360 [01:18<00:29,  3.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▉   | 248/360 [01:18<00:28,  3.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▉   | 249/360 [01:18<00:27,  4.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▉   | 250/360 [01:18<00:26,  4.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|██████▉   | 251/360 [01:18<00:25,  4.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|███████   | 252/360 [01:19<00:25,  4.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|███████   | 253/360 [01:19<00:25,  4.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████   | 254/360 [01:19<00:24,  4.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████   | 255/360 [01:19<00:22,  4.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████   | 256/360 [01:20<00:22,  4.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████▏  | 257/360 [01:20<00:21,  4.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▏  | 258/360 [01:20<00:22,  4.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▏  | 259/360 [01:20<00:21,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▏  | 260/360 [01:20<00:21,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▎  | 261/360 [01:21<00:20,  4.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|███████▎  | 262/360 [01:21<00:20,  4.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|███████▎  | 263/360 [01:21<00:20,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|███████▎  | 264/360 [01:21<00:20,  4.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▎  | 265/360 [01:21<00:19,  4.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▍  | 266/360 [01:22<00:20,  4.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▍  | 267/360 [01:22<00:23,  4.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▍  | 268/360 [01:22<00:21,  4.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|███████▍  | 269/360 [01:22<00:19,  4.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|███████▌  | 270/360 [01:23<00:19,  4.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|███████▌  | 271/360 [01:23<00:18,  4.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▌  | 272/360 [01:23<00:17,  4.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▌  | 273/360 [01:23<00:17,  5.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▌  | 274/360 [01:23<00:17,  4.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▋  | 275/360 [01:24<00:16,  5.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|███████▋  | 276/360 [01:24<00:16,  4.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|███████▋  | 277/360 [01:24<00:16,  5.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|███████▋  | 278/360 [01:24<00:16,  4.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 279/360 [01:24<00:18,  4.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 280/360 [01:25<00:18,  4.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 281/360 [01:25<00:17,  4.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 282/360 [01:25<00:16,  4.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▊  | 283/360 [01:25<00:18,  4.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▉  | 284/360 [01:26<00:17,  4.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▉  | 285/360 [01:26<00:16,  4.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▉  | 286/360 [01:26<00:15,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|███████▉  | 287/360 [01:26<00:15,  4.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|████████  | 288/360 [01:26<00:15,  4.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|████████  | 289/360 [01:27<00:16,  4.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████  | 290/360 [01:27<00:18,  3.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████  | 291/360 [01:27<00:19,  3.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████  | 292/360 [01:28<00:19,  3.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████▏ | 293/360 [01:28<00:19,  3.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▏ | 294/360 [01:28<00:20,  3.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▏ | 295/360 [01:29<00:18,  3.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▏ | 296/360 [01:29<00:17,  3.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▎ | 297/360 [01:29<00:16,  3.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|████████▎ | 298/360 [01:29<00:15,  3.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|████████▎ | 299/360 [01:29<00:15,  3.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|████████▎ | 300/360 [01:30<00:15,  4.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▎ | 301/360 [01:30<00:15,  3.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▍ | 302/360 [01:30<00:16,  3.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▍ | 303/360 [01:31<00:16,  3.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▍ | 304/360 [01:31<00:16,  3.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|████████▍ | 305/360 [01:31<00:16,  3.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|████████▌ | 306/360 [01:32<00:16,  3.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|████████▌ | 307/360 [01:32<00:16,  3.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▌ | 308/360 [01:32<00:16,  3.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▌ | 309/360 [01:33<00:15,  3.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▌ | 310/360 [01:33<00:15,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▋ | 311/360 [01:33<00:13,  3.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|████████▋ | 312/360 [01:33<00:12,  3.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|████████▋ | 313/360 [01:33<00:11,  4.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|████████▋ | 314/360 [01:34<00:10,  4.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 315/360 [01:34<00:09,  4.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 316/360 [01:34<00:09,  4.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 317/360 [01:34<00:09,  4.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 318/360 [01:35<00:09,  4.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▊ | 319/360 [01:35<00:09,  4.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▉ | 320/360 [01:35<00:08,  4.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▉ | 321/360 [01:35<00:08,  4.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▉ | 322/360 [01:35<00:08,  4.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|████████▉ | 323/360 [01:36<00:09,  4.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|█████████ | 324/360 [01:36<00:08,  4.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|█████████ | 325/360 [01:36<00:08,  4.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████ | 326/360 [01:36<00:07,  4.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████ | 327/360 [01:37<00:08,  3.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████ | 328/360 [01:37<00:08,  3.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████▏| 329/360 [01:37<00:07,  3.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▏| 330/360 [01:37<00:07,  4.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▏| 331/360 [01:38<00:07,  3.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▏| 332/360 [01:38<00:07,  3.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▎| 333/360 [01:38<00:06,  4.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|█████████▎| 334/360 [01:38<00:06,  4.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|█████████▎| 335/360 [01:39<00:05,  4.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|█████████▎| 336/360 [01:39<00:06,  3.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▎| 337/360 [01:39<00:05,  4.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▍| 338/360 [01:40<00:06,  3.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▍| 339/360 [01:40<00:05,  3.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▍| 340/360 [01:40<00:05,  3.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|█████████▍| 341/360 [01:40<00:05,  3.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|█████████▌| 342/360 [01:41<00:04,  3.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|█████████▌| 343/360 [01:41<00:04,  3.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▌| 344/360 [01:41<00:03,  4.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▌| 345/360 [01:41<00:03,  4.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▌| 346/360 [01:42<00:03,  3.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▋| 347/360 [01:42<00:03,  3.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|█████████▋| 348/360 [01:42<00:03,  3.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|█████████▋| 349/360 [01:42<00:02,  4.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|█████████▋| 350/360 [01:43<00:02,  3.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 351/360 [01:43<00:02,  3.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 352/360 [01:43<00:01,  4.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 353/360 [01:43<00:01,  4.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 354/360 [01:44<00:01,  4.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▊| 355/360 [01:44<00:01,  4.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▉| 356/360 [01:44<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▉| 357/360 [01:44<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▉| 358/360 [01:45<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|█████████▉| 359/360 [01:45<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|██████████| 360/360 [01:45<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|██████████| 360/360 [01:45<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY FOR BLIP2\n",
      "============================================================\n",
      "📊 IMAGE PROCESSING SUMMARY:\n",
      "   Total images attempted: 360\n",
      "   Successfully processed: 360 (100.0%)\n",
      "   Failed images: 0 (0.0%)\n",
      "\n",
      "📝 QUESTION PROCESSING SUMMARY:\n",
      "   Total questions attempted: 1080\n",
      "   Successfully processed: 1080 (100.0%)\n",
      "   Failed questions: 0 (0.0%)\n",
      "   Results saved: 1080\n",
      "\n",
      "✅ SUCCESSFUL IMAGES (360):\n",
      "   • image01 (Type: REAL, Questions: 3/3, Time: 1.3s)\n",
      "   • image02 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image03 (Type: REAL, Questions: 3/3, Time: 0.5s)\n",
      "   • image04 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image05 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image06 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image07 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image08 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image09 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image10 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image11 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image12 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image13 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image14 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image15 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image16 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image17 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image18 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image19 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image20 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image21 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image22 (Type: REAL, Questions: 3/3, Time: 1.0s)\n",
      "   • image23 (Type: REAL, Questions: 3/3, Time: 1.1s)\n",
      "   • image24 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image25 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image26 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image27 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image28 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image29 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image30 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image31 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image32 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image33 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image34 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image35 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image36 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image37 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image38 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image39 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image40 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image41 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image42 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image43 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image44 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image45 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image46 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image47 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image48 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image49 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image50 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image51 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image52 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image53 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image54 (Type: REAL, Questions: 3/3, Time: 0.6s)\n",
      "   • image55 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image56 (Type: REAL, Questions: 3/3, Time: 0.9s)\n",
      "   • image57 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image58 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image59 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image60 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image61 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image62 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image63 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image64 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image65 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image66 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image67 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image68 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image69 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image70 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image71 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image72 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image73 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image74 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image75 (Type: REAL, Questions: 3/3, Time: 0.7s)\n",
      "   • image76 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image77 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image78 (Type: REAL, Questions: 3/3, Time: 0.5s)\n",
      "   • image79 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image80 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image81 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image82 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image83 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image84 (Type: REAL, Questions: 3/3, Time: 0.5s)\n",
      "   • image85 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image86 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image87 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image88 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image89 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image90 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image91 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image92 (Type: REAL, Questions: 3/3, Time: 0.7s)\n",
      "   • image93 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image94 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image95 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image96 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image97 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image98 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image99 (Type: REAL, Questions: 3/3, Time: 0.5s)\n",
      "   • image100 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image101 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image102 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image103 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image104 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image105 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image106 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image107 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image108 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image109 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image110 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image111 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image112 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image113 (Type: REAL, Questions: 3/3, Time: 0.2s)\n",
      "   • image114 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image115 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image116 (Type: REAL, Questions: 3/3, Time: 0.4s)\n",
      "   • image117 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image118 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image119 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image120 (Type: REAL, Questions: 3/3, Time: 0.3s)\n",
      "   • image01 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image02 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image03 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image04 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image05 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image06 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image07 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image08 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image09 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image10 (Type: ANIMATED, Questions: 3/3, Time: 0.8s)\n",
      "   • image11 (Type: ANIMATED, Questions: 3/3, Time: 0.4s)\n",
      "   • image12 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image13 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image14 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image15 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image16 (Type: ANIMATED, Questions: 3/3, Time: 0.4s)\n",
      "   • image17 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image18 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image19 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image20 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image21 (Type: ANIMATED, Questions: 3/3, Time: 0.6s)\n",
      "   • image22 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image23 (Type: ANIMATED, Questions: 3/3, Time: 0.8s)\n",
      "   • image24 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image25 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image26 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image27 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image28 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image29 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image30 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image31 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image32 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image33 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image34 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image35 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image36 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image37 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image38 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image39 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image40 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image41 (Type: ANIMATED, Questions: 3/3, Time: 0.6s)\n",
      "   • image42 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image43 (Type: ANIMATED, Questions: 3/3, Time: 0.6s)\n",
      "   • image44 (Type: ANIMATED, Questions: 3/3, Time: 1.2s)\n",
      "   • image45 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image46 (Type: ANIMATED, Questions: 3/3, Time: 0.9s)\n",
      "   • image47 (Type: ANIMATED, Questions: 3/3, Time: 0.4s)\n",
      "   • image48 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image49 (Type: ANIMATED, Questions: 3/3, Time: 0.4s)\n",
      "   • image50 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image51 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image52 (Type: ANIMATED, Questions: 3/3, Time: 0.8s)\n",
      "   • image53 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image54 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image55 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image56 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image57 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image58 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image59 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image60 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image61 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image62 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image63 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image64 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image65 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image66 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image67 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image68 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image69 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image70 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image71 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image72 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image73 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image74 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image75 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image76 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image77 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image78 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image79 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image80 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image81 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image82 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image83 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image84 (Type: ANIMATED, Questions: 3/3, Time: 0.8s)\n",
      "   • image85 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image86 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image87 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image88 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image89 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image90 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image91 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image92 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image93 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image94 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image95 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image96 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image97 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image98 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image99 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image100 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image101 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image102 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image103 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image104 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image105 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image106 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image107 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image108 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image109 (Type: ANIMATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image110 (Type: ANIMATED, Questions: 3/3, Time: 0.6s)\n",
      "   • image111 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image112 (Type: ANIMATED, Questions: 3/3, Time: 1.4s)\n",
      "   • image113 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image114 (Type: ANIMATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image115 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image116 (Type: ANIMATED, Questions: 3/3, Time: 0.9s)\n",
      "   • image117 (Type: ANIMATED, Questions: 3/3, Time: 0.6s)\n",
      "   • image118 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image119 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image120 (Type: ANIMATED, Questions: 3/3, Time: 0.7s)\n",
      "   • image01 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image02 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image03 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image04 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image05 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image06 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image07 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image08 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image09 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image10 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image11 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image12 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image13 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image14 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image15 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image16 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image17 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image18 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image19 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image20 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image21 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image22 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image23 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image24 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image25 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image26 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image27 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image28 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image29 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image30 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image31 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image32 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image33 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image34 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image35 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image36 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image37 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image38 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image39 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image40 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image41 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image42 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image43 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image44 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image45 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image46 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image47 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image48 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image49 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image50 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image51 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image52 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image53 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image54 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image55 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image56 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image57 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image58 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image59 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image60 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image61 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image62 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image63 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image64 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image65 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image66 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image67 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image68 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image69 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image70 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image71 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image72 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image73 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image74 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image75 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image76 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image77 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image78 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image79 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image80 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image81 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image82 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image83 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image84 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image85 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image86 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image87 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image88 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image89 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image90 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image91 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image92 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image93 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image94 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image95 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image96 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image97 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image98 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image99 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image100 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image101 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image102 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image103 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image104 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image105 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image106 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image107 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image108 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image109 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image110 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image111 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image112 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image113 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image114 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image115 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image116 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image117 (Type: AI_GENERATED, Questions: 3/3, Time: 0.2s)\n",
      "   • image118 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image119 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "   • image120 (Type: AI_GENERATED, Questions: 3/3, Time: 0.3s)\n",
      "============================================================\n",
      "\n",
      "Initial test successful!\n"
     ]
    }
   ],
   "source": [
    "test_blip2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b2369",
   "metadata": {
    "papermill": {
     "duration": 0.029238,
     "end_time": "2025-07-28T21:14:24.553690",
     "exception": false,
     "start_time": "2025-07-28T21:14:24.524452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 138.623634,
   "end_time": "2025-07-28T21:14:27.352191",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-fuyu-blip2.ipynb",
   "output_path": "blip2-opt-2.7b_output.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T21:12:08.728557",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
