{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdead5bb",
   "metadata": {
    "papermill": {
     "duration": 0.005341,
     "end_time": "2025-07-27T20:34:04.032755",
     "exception": false,
     "start_time": "2025-07-27T20:34:04.027414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054ebe9",
   "metadata": {
    "papermill": {
     "duration": 0.00425,
     "end_time": "2025-07-27T20:34:04.041649",
     "exception": false,
     "start_time": "2025-07-27T20:34:04.037399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5157a60",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:04.051082Z",
     "iopub.status.busy": "2025-07-27T20:34:04.050828Z",
     "iopub.status.idle": "2025-07-27T20:34:04.054594Z",
     "shell.execute_reply": "2025-07-27T20:34:04.054034Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.009956,
     "end_time": "2025-07-27T20:34:04.055838",
     "exception": false,
     "start_time": "2025-07-27T20:34:04.045882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install transformers torch Pillow tqdm bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccf8a7c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:04.065345Z",
     "iopub.status.busy": "2025-07-27T20:34:04.065044Z",
     "iopub.status.idle": "2025-07-27T20:34:05.797243Z",
     "shell.execute_reply": "2025-07-27T20:34:05.796264Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.738338,
     "end_time": "2025-07-27T20:34:05.798557",
     "exception": false,
     "start_time": "2025-07-27T20:34:04.060219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (0.0.11)\r\n",
      "Requirement already satisfied: flash-attn in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.7.4.post1)\r\n",
      "Requirement already satisfied: av in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (14.3.0)\r\n",
      "Requirement already satisfied: packaging in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (25.0)\r\n",
      "Requirement already satisfied: pillow in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (10.3.0)\r\n",
      "Requirement already satisfied: requests in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (2.32.3)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (2.2.1)\r\n",
      "Requirement already satisfied: einops in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (0.8.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2025.4.26)\r\n",
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.93)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (3.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch->flash-attn) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qwen-vl-utils flash-attn #--no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2356f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:05.810615Z",
     "iopub.status.busy": "2025-07-27T20:34:05.810156Z",
     "iopub.status.idle": "2025-07-27T20:34:11.443677Z",
     "shell.execute_reply": "2025-07-27T20:34:11.442707Z"
    },
    "papermill": {
     "duration": 5.640516,
     "end_time": "2025-07-27T20:34:11.445057",
     "exception": false,
     "start_time": "2025-07-27T20:34:05.804541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca2b9a",
   "metadata": {
    "papermill": {
     "duration": 0.00483,
     "end_time": "2025-07-27T20:34:11.455278",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.450448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28935166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:11.466481Z",
     "iopub.status.busy": "2025-07-27T20:34:11.466075Z",
     "iopub.status.idle": "2025-07-27T20:34:11.476688Z",
     "shell.execute_reply": "2025-07-27T20:34:11.475948Z"
    },
    "papermill": {
     "duration": 0.017851,
     "end_time": "2025-07-27T20:34:11.477878",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.460027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BenchmarkTester:\n",
    "#     def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "#         self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#         with open(benchmark_path, 'r') as f:\n",
    "#             self.benchmark = json.load(f)\n",
    "#         self.data_dir = data_dir\n",
    "\n",
    "#     def clean_answer(self, answer):\n",
    "#         \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "#         # Remove any text that's not a number\n",
    "#         # import re\n",
    "#         # numbers = re.findall(r'\\d+', answer)\n",
    "#         # if numbers:\n",
    "#         #     return numbers[0]  # Return the first number found\n",
    "#         # return answer\n",
    "#         \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "#         # Try to extract number and reasoning using regex\n",
    "#         import re\n",
    "#         pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "#         match = re.search(pattern, answer)\n",
    "        \n",
    "#         if match:\n",
    "#             number = match.group(1)\n",
    "#             objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "#             return {\n",
    "#                 \"count\": number,\n",
    "#                 \"reasoning\": objects\n",
    "#             }\n",
    "#         else:\n",
    "#             # Fallback if format isn't matched\n",
    "#             numbers = re.findall(r'\\d+', answer)\n",
    "#             return {\n",
    "#                 \"count\": numbers[0] if numbers else \"0\",\n",
    "#                 \"reasoning\": []\n",
    "#             }\n",
    "\n",
    "#     def model_generation(self, model_name, model, inputs, processor):\n",
    "#         \"\"\"Generate answer and decode.\"\"\"\n",
    "#         outputs = None  # Initialize outputs to None\n",
    "#         input_len = inputs[\"input_ids\"].shape[-1]\n",
    "        \n",
    "#         if model_name==\"Gemma3\":\n",
    "#             outputs = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "#             outputs = outputs[0][input_len:]\n",
    "#             answer = processor.decode(outputs, skip_special_tokens=True)\n",
    "#             # outputs = model.generate(**inputs, do_sample=False, max_new_tokens=100)\n",
    "#             # answer = processor.batch_decode(\n",
    "#             #     outputs,\n",
    "#             #     skip_special_tokens=True,\n",
    "#             # )[0]\n",
    "#         else:\n",
    "#             print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "#             answer = \"\"  # Return an empty string\n",
    "\n",
    "#         return answer, outputs\n",
    "    \n",
    "#     def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "#         results = []\n",
    "#         print(f\"\\nEvaluating {model_name}...\")\n",
    "#         print(f\"Using device: {self.device}\")\n",
    "        \n",
    "#         # Force garbage collection before starting\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         try:\n",
    "#             images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "#             total_images = len(images)\n",
    "            \n",
    "#             for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "#                 try:\n",
    "#                     print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "#                     image_path = Path(self.data_dir)/image_data['path']\n",
    "#                     if not image_path.exists():\n",
    "#                         print(f\"Warning: Image not found at {image_path}\")\n",
    "#                         continue\n",
    "                    \n",
    "#                     # Load and preprocess image\n",
    "#                     image = Image.open(image_path).convert(\"RGB\")\n",
    "#                     image_results = []  # Store results for current image\n",
    "                    \n",
    "#                     for question in image_data['questions']:\n",
    "#                         try:\n",
    "#                             # prompt = self.format_question(question, model_name)\n",
    "#                             print(f\"Question: {question['question']}\")\n",
    "\n",
    "#                             # messages = [\n",
    "#                             #     {\n",
    "#                             #         \"role\": \"user\",\n",
    "#                             #         \"content\": [\n",
    "#                             #             {\"type\": \"image\", \"image\": image},\n",
    "#                             #             # {\"type\": \"text\", \"text\": f\"{question['question']} Answer format: total number(numerical) objects(within square brackets)\"},\n",
    "#                             #             # {\"type\": \"text\", \"text\": f\"{question['question']} Provide just the total count and the list of objects in the given format \\n Format: number [objects]\"},\n",
    "#                             #             # {\"type\": \"text\", \"text\": f\"{question['question']} Answer Format: number [objects]\"},\n",
    "#                             #             {\"type\": \"text\", \"text\": f\"{question[\"question\"]} Your response MUST be in the following format and nothing else:\\n <NUMBER> [<OBJECT1>, <OBJECT2>, <OBJECT3>, ...]\"}\n",
    "#                             #         ]\n",
    "#                             #     },\n",
    "#                             # ]\n",
    "#                             messages = [\n",
    "#                                 {\n",
    "#                                     \"role\": \"system\",\n",
    "#                                     \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "#                                 },\n",
    "#                                 {\n",
    "#                                     \"role\": \"user\",\n",
    "#                                     \"content\": [\n",
    "#                                         {\"type\": \"image\", \"image\": image},\n",
    "#                                         {\"type\": \"text\", \"text\": f\"{question['question']} Your response MUST be in the following format and nothing else:\\n <NUMBER> [<OBJECT1>, <OBJECT2>, <OBJECT3>, ...]\"}\n",
    "#                                     ]\n",
    "#                                 }\n",
    "#                             ]\n",
    "                            \n",
    "#                             # Clear cache before processing each question\n",
    "#                             torch.cuda.empty_cache()\n",
    "                            \n",
    "#                             # Process image and text\n",
    "#                             # inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "#                             # if model_name==\"smolVLM2\":\n",
    "#                             inputs = processor.apply_chat_template(\n",
    "#                                 messages,\n",
    "#                                 add_generation_prompt=True,\n",
    "#                                 tokenize=True,\n",
    "#                                 return_dict=True,\n",
    "#                                 return_tensors=\"pt\",\n",
    "#                             ).to(model.device, dtype=torch.bfloat16)\n",
    "                           \n",
    "#                             with torch.no_grad():\n",
    "#                                 answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n",
    "        \n",
    "#                             cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "#                             image_results.append({\n",
    "#                                 \"image_id\": image_data[\"image_id\"],\n",
    "#                                 \"image_type\": image_data[\"image_type\"],\n",
    "#                                 \"question_id\": question[\"id\"],\n",
    "#                                 \"question\": question[\"question\"],\n",
    "#                                 \"ground_truth\": question[\"answer\"],\n",
    "#                                 \"model_answer\": cleaned_answer[\"count\"],\n",
    "#                                 \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "#                                 \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "#                                 \"property_category\": question[\"property_category\"]\n",
    "#                             })\n",
    "                            \n",
    "#                             # Clear memory\n",
    "#                             del outputs, inputs\n",
    "#                             torch.cuda.empty_cache()\n",
    "                            \n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing question: {str(e)}\")\n",
    "#                             continue\n",
    "                    \n",
    "#                     # Add results from this image\n",
    "#                     results.extend(image_results)\n",
    "                    \n",
    "#                     # Save intermediate results only every 2 images or if it's the last image\n",
    "#                     if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "#                         with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "#                             json.dump(results, f, indent=4)\n",
    "                            \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "#                     continue\n",
    "            \n",
    "#             # Save final results\n",
    "#             if results:\n",
    "#                 with open(save_path, 'w') as f:\n",
    "#                     json.dump(results, f, indent=4)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "#             if results:\n",
    "#                 with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "#                     json.dump(results, f, indent=4)\n",
    "        \n",
    "#         return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b3b2e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:11.488688Z",
     "iopub.status.busy": "2025-07-27T20:34:11.488431Z",
     "iopub.status.idle": "2025-07-27T20:34:11.520830Z",
     "shell.execute_reply": "2025-07-27T20:34:11.520054Z"
    },
    "papermill": {
     "duration": 0.03942,
     "end_time": "2025-07-27T20:34:11.522055",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.482635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    def model_generation(self, model_name, model, inputs, processor):\n",
    "        \"\"\"Generate answer and decode.\"\"\"\n",
    "        outputs = None  # Initialize outputs to None\n",
    "        input_len = inputs[\"input_ids\"].shape[-1]\n",
    "        \n",
    "        if model_name==\"Gemma3\":\n",
    "            outputs = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "            outputs = outputs[0][input_len:]\n",
    "            answer = processor.decode(outputs, skip_special_tokens=True)\n",
    "        else:\n",
    "            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "            answer = \"\"  # Return an empty string\n",
    "\n",
    "        return answer, outputs\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        successful_images = []\n",
    "        failed_images = []\n",
    "        total_questions_processed = 0\n",
    "        total_questions_failed = 0\n",
    "        \n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                image_start_time = time.time()\n",
    "                current_image_questions_failed = 0\n",
    "                current_image_questions_total = 0\n",
    "                \n",
    "                try:\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        failed_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'error_type': 'file_not_found',\n",
    "                            'error_message': f'Image not found at {image_path}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question_idx, question in enumerate(image_data['questions']):\n",
    "                        current_image_questions_total += 1\n",
    "                        total_questions_processed += 1\n",
    "                        \n",
    "                        try:\n",
    "                            messages = [\n",
    "                                {\n",
    "                                    \"role\": \"system\",\n",
    "                                    \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "                                },\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [\n",
    "                                        {\"type\": \"image\", \"image\": image},\n",
    "                                        {\"type\": \"text\", \"text\": f\"{question['question']} Your response MUST be in the following format and nothing else:\\n <NUMBER> [<OBJECT1>, <OBJECT2>, <OBJECT3>, ...]\"}\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            # Process image and text\n",
    "                            inputs = processor.apply_chat_template(\n",
    "                                messages,\n",
    "                                add_generation_prompt=True,\n",
    "                                tokenize=True,\n",
    "                                return_dict=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                            ).to(model.device, dtype=torch.bfloat16)\n",
    "                           \n",
    "                            with torch.no_grad():\n",
    "                                answer, outputs = self.model_generation(model_name, model, inputs, processor)\n",
    "        \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data.get(\"image_type\", \"unknown\"),\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            current_image_questions_failed += 1\n",
    "                            total_questions_failed += 1\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Calculate success rate for this image\n",
    "                    questions_succeeded = current_image_questions_total - current_image_questions_failed\n",
    "                    \n",
    "                    if current_image_questions_failed == 0:\n",
    "                        # All questions succeeded\n",
    "                        successful_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'questions_total': current_image_questions_total,\n",
    "                            'questions_succeeded': questions_succeeded,\n",
    "                            'processing_time': time.time() - image_start_time\n",
    "                        })\n",
    "                    else:\n",
    "                        # Some questions failed\n",
    "                        image_success_rate = (questions_succeeded / current_image_questions_total * 100) if current_image_questions_total > 0 else 0\n",
    "                        failed_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'error_type': 'partial_failure',\n",
    "                            'questions_total': current_image_questions_total,\n",
    "                            'questions_failed': current_image_questions_failed,\n",
    "                            'questions_succeeded': questions_succeeded,\n",
    "                            'success_rate': f\"{image_success_rate:.1f}%\"\n",
    "                        })\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        checkpoint_path = f\"{save_path}_checkpoint.json\"\n",
    "                        with open(checkpoint_path, 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    failed_images.append({\n",
    "                        'image_id': image_data['image_id'],\n",
    "                        'image_type': image_data.get('image_type', 'unknown'),\n",
    "                        'error_type': 'complete_failure',\n",
    "                        'error_message': str(e)\n",
    "                    })\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if results:\n",
    "                error_save_path = f\"{save_path}_error_state.json\"\n",
    "                with open(error_save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        # Print comprehensive summary\n",
    "        self._print_evaluation_summary(\n",
    "            model_name, total_images, successful_images, failed_images, \n",
    "            total_questions_processed, total_questions_failed, len(results)\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _print_evaluation_summary(self, model_name, total_images, successful_images, \n",
    "                                failed_images, total_questions_processed, total_questions_failed, total_results):\n",
    "        \"\"\"Print a comprehensive evaluation summary.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EVALUATION SUMMARY FOR {model_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Image-level statistics\n",
    "        num_successful = len(successful_images)\n",
    "        num_failed = len(failed_images)\n",
    "        \n",
    "        print(f\"📊 IMAGE PROCESSING SUMMARY:\")\n",
    "        print(f\"   Total images attempted: {total_images}\")\n",
    "        print(f\"   Successfully processed: {num_successful} ({num_successful/total_images*100:.1f}%)\")\n",
    "        print(f\"   Failed images: {num_failed} ({num_failed/total_images*100:.1f}%)\")\n",
    "        \n",
    "        # Question-level statistics\n",
    "        questions_succeeded = total_questions_processed - total_questions_failed\n",
    "        print(f\"\\n📝 QUESTION PROCESSING SUMMARY:\")\n",
    "        print(f\"   Total questions attempted: {total_questions_processed}\")\n",
    "        print(f\"   Successfully processed: {questions_succeeded} ({questions_succeeded/total_questions_processed*100:.1f}%)\")\n",
    "        print(f\"   Failed questions: {total_questions_failed} ({total_questions_failed/total_questions_processed*100:.1f}%)\")\n",
    "        print(f\"   Results saved: {total_results}\")\n",
    "        \n",
    "        # Successful images details\n",
    "        if successful_images:\n",
    "            print(f\"\\n✅ SUCCESSFUL IMAGES ({len(successful_images)}):\")\n",
    "            for img in successful_images:\n",
    "                print(f\"   • {img['image_id']} (Type: {img['image_type']}, \"\n",
    "                      f\"Questions: {img['questions_succeeded']}/{img['questions_total']}, \"\n",
    "                      f\"Time: {img['processing_time']:.1f}s)\")\n",
    "        \n",
    "        # Failed images details\n",
    "        if failed_images:\n",
    "            print(f\"\\n❌ FAILED/PROBLEMATIC IMAGES ({len(failed_images)}):\")\n",
    "            for img in failed_images:\n",
    "                if img['error_type'] == 'complete_failure':\n",
    "                    print(f\"   • {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"COMPLETE FAILURE: {img.get('error_message', 'Unknown error')}\")\n",
    "                elif img['error_type'] == 'partial_failure':\n",
    "                    print(f\"   • {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"PARTIAL: {img['questions_failed']}/{img['questions_total']} failed \"\n",
    "                          f\"({img['success_rate']} success)\")\n",
    "                elif img['error_type'] == 'file_not_found':\n",
    "                    print(f\"   • {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"FILE NOT FOUND: {img['error_message']}\")\n",
    "        \n",
    "        # Group failed images by type\n",
    "        if failed_images:\n",
    "            print(f\"\\n📈 FAILURE ANALYSIS BY IMAGE TYPE:\")\n",
    "            from collections import defaultdict\n",
    "            failures_by_type = defaultdict(list)\n",
    "            for img in failed_images:\n",
    "                failures_by_type[img['image_type']].append(img)\n",
    "            \n",
    "            for img_type, failures in failures_by_type.items():\n",
    "                print(f\"   • {img_type}: {len(failures)} failed images\")\n",
    "                for failure in failures:\n",
    "                    print(f\"     - {failure['image_id']} ({failure['error_type']})\")\n",
    "        \n",
    "        print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57ce28",
   "metadata": {
    "papermill": {
     "duration": 0.004758,
     "end_time": "2025-07-27T20:34:11.531651",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.526893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Gemma3\n",
    "\n",
    "Let's evaluate the Gemma-3-27B-it model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da013cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:11.542170Z",
     "iopub.status.busy": "2025-07-27T20:34:11.541925Z",
     "iopub.status.idle": "2025-07-27T20:34:11.547122Z",
     "shell.execute_reply": "2025-07-27T20:34:11.546353Z"
    },
    "papermill": {
     "duration": 0.011775,
     "end_time": "2025-07-27T20:34:11.548256",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.536481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_Gemma3():\n",
    "    from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "\n",
    "    print(\"Loading Gemma3 model...\")\n",
    "\n",
    "    model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/gemma-3-27b-it\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        # attn_implementation=\"flash_attention_2\",\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    ).eval()\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(\"/var/scratch/ave303/models/gemma-3-27b-it\")\n",
    "\n",
    "    tester = BenchmarkTester()\n",
    "    Gemma3_results = tester.evaluate_model(\n",
    "        \"Gemma3\",\n",
    "        model,\n",
    "        processor,\n",
    "        \"Gemma3_27b_results.json\",\n",
    "        batch_size=360\n",
    "    )\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f4a8a",
   "metadata": {
    "papermill": {
     "duration": 0.00466,
     "end_time": "2025-07-27T20:34:11.557881",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.553221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the Gemma3 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986c501a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T20:34:11.568253Z",
     "iopub.status.busy": "2025-07-27T20:34:11.568015Z",
     "iopub.status.idle": "2025-07-27T23:22:49.816749Z",
     "shell.execute_reply": "2025-07-27T23:22:49.816037Z"
    },
    "papermill": {
     "duration": 10118.255398,
     "end_time": "2025-07-27T23:22:49.817970",
     "exception": false,
     "start_time": "2025-07-27T20:34:11.562572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gemma3 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   5%|▍         | 1/22 [00:03<01:18,  3.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   9%|▉         | 2/22 [00:07<01:11,  3.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  14%|█▎        | 3/22 [00:10<01:02,  3.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  18%|█▊        | 4/22 [00:13<00:57,  3.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  23%|██▎       | 5/22 [00:16<00:52,  3.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  27%|██▋       | 6/22 [00:18<00:47,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  32%|███▏      | 7/22 [00:21<00:44,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  36%|███▋      | 8/22 [00:24<00:42,  3.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  41%|████      | 9/22 [00:27<00:38,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  45%|████▌     | 10/22 [00:30<00:35,  2.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  50%|█████     | 11/22 [00:33<00:32,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  55%|█████▍    | 12/22 [00:36<00:29,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  59%|█████▉    | 13/22 [00:39<00:26,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  64%|██████▎   | 14/22 [00:42<00:23,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  68%|██████▊   | 15/22 [00:45<00:20,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  73%|███████▎  | 16/22 [00:48<00:17,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  77%|███████▋  | 17/22 [00:51<00:14,  3.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  82%|████████▏ | 18/22 [00:54<00:12,  3.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  86%|████████▋ | 19/22 [00:57<00:08,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  91%|█████████ | 20/22 [01:00<00:05,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  95%|█████████▌| 21/22 [01:03<00:02,  2.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|██████████| 22/22 [01:05<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|██████████| 22/22 [01:05<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Gemma3...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   0%|          | 0/360 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `64` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   0%|          | 1/360 [00:25<2:33:18, 25.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 2/360 [00:57<2:56:12, 29.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 3/360 [01:17<2:27:43, 24.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 4/360 [01:42<2:28:30, 25.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|▏         | 5/360 [02:17<2:48:31, 28.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▏         | 6/360 [02:40<2:37:06, 26.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▏         | 7/360 [02:52<2:08:57, 21.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▏         | 8/360 [03:09<1:59:05, 20.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|▎         | 9/360 [03:41<2:20:32, 24.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|▎         | 10/360 [04:11<2:30:46, 25.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|▎         | 11/360 [04:38<2:33:33, 26.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|▎         | 12/360 [05:10<2:42:03, 27.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▎         | 13/360 [05:41<2:47:43, 29.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▍         | 14/360 [05:57<2:23:23, 24.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▍         | 15/360 [06:17<2:14:30, 23.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|▍         | 16/360 [06:42<2:17:35, 24.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|▍         | 17/360 [07:02<2:10:07, 22.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|▌         | 18/360 [07:35<2:27:16, 25.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|▌         | 19/360 [07:53<2:14:08, 23.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▌         | 20/360 [08:14<2:08:49, 22.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▌         | 21/360 [08:39<2:12:48, 23.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▌         | 22/360 [09:04<2:14:09, 23.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|▋         | 23/360 [09:34<2:24:09, 25.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|▋         | 24/360 [10:06<2:34:46, 27.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|▋         | 25/360 [10:37<2:39:23, 28.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|▋         | 26/360 [11:06<2:39:57, 28.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 27/360 [11:29<2:29:56, 27.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 28/360 [11:50<2:18:58, 25.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 29/360 [12:28<2:40:28, 29.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|▊         | 30/360 [13:09<3:00:25, 32.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▊         | 31/360 [13:28<2:36:10, 28.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▉         | 32/360 [14:20<3:14:40, 35.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▉         | 33/360 [14:55<3:13:35, 35.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|▉         | 34/360 [15:18<2:51:18, 31.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|▉         | 35/360 [16:23<3:45:41, 41.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|█         | 36/360 [17:11<3:54:39, 43.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|█         | 37/360 [17:37<3:25:51, 38.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█         | 38/360 [18:04<3:06:56, 34.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█         | 39/360 [18:56<3:34:19, 40.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█         | 40/360 [19:32<3:27:20, 38.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|█▏        | 41/360 [19:51<2:55:12, 32.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▏        | 42/360 [20:12<2:35:10, 29.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▏        | 43/360 [20:35<2:24:44, 27.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▏        | 44/360 [20:55<2:12:34, 25.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|█▎        | 45/360 [21:25<2:20:53, 26.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|█▎        | 46/360 [22:08<2:45:49, 31.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|█▎        | 47/360 [22:34<2:35:19, 29.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|█▎        | 48/360 [22:56<2:23:03, 27.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▎        | 49/360 [23:25<2:25:10, 28.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▍        | 50/360 [24:01<2:37:19, 30.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▍        | 51/360 [25:17<3:46:15, 43.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|█▍        | 52/360 [25:45<3:21:35, 39.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|█▍        | 53/360 [26:14<3:04:17, 36.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|█▌        | 54/360 [26:42<2:51:29, 33.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|█▌        | 55/360 [27:12<2:46:35, 32.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▌        | 56/360 [27:40<2:38:05, 31.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▌        | 57/360 [28:09<2:34:36, 30.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▌        | 58/360 [28:40<2:34:14, 30.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|█▋        | 59/360 [29:01<2:19:55, 27.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|█▋        | 60/360 [30:05<3:13:30, 38.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|█▋        | 61/360 [30:29<2:50:42, 34.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|█▋        | 62/360 [31:00<2:44:54, 33.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 63/360 [31:32<2:43:03, 32.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 64/360 [32:05<2:41:43, 32.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 65/360 [32:21<2:16:32, 27.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|█▊        | 66/360 [32:42<2:06:47, 25.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▊        | 67/360 [33:15<2:16:52, 28.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▉        | 68/360 [33:32<2:00:09, 24.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▉        | 69/360 [34:09<2:17:29, 28.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|█▉        | 70/360 [34:32<2:09:25, 26.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|█▉        | 71/360 [34:51<1:58:09, 24.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|██        | 72/360 [35:17<1:58:56, 24.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|██        | 73/360 [35:32<1:44:59, 21.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██        | 74/360 [36:01<1:53:53, 23.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██        | 75/360 [36:38<2:12:41, 27.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██        | 76/360 [36:59<2:03:07, 26.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|██▏       | 77/360 [37:29<2:08:13, 27.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▏       | 78/360 [38:06<2:21:29, 30.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▏       | 79/360 [38:38<2:22:58, 30.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▏       | 80/360 [39:11<2:25:59, 31.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|██▎       | 81/360 [39:25<2:01:07, 26.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|██▎       | 82/360 [39:43<1:50:12, 23.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|██▎       | 83/360 [40:15<2:01:30, 26.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|██▎       | 84/360 [40:37<1:54:46, 24.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▎       | 85/360 [41:00<1:51:58, 24.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▍       | 86/360 [41:20<1:45:24, 23.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▍       | 87/360 [41:56<2:02:54, 27.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|██▍       | 88/360 [42:23<2:02:20, 26.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|██▍       | 89/360 [42:55<2:08:13, 28.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|██▌       | 90/360 [43:17<1:59:40, 26.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|██▌       | 91/360 [43:50<2:06:50, 28.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▌       | 92/360 [44:22<2:12:16, 29.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▌       | 93/360 [44:50<2:09:12, 29.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▌       | 94/360 [45:12<1:59:46, 27.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|██▋       | 95/360 [45:30<1:46:56, 24.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|██▋       | 96/360 [45:49<1:39:02, 22.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|██▋       | 97/360 [46:09<1:35:28, 21.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|██▋       | 98/360 [46:36<1:41:50, 23.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 99/360 [47:03<1:46:26, 24.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 100/360 [47:36<1:57:11, 27.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 101/360 [48:06<2:00:33, 27.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|██▊       | 102/360 [48:50<2:20:37, 32.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▊       | 103/360 [49:17<2:12:39, 30.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▉       | 104/360 [49:40<2:03:01, 28.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▉       | 105/360 [50:06<1:58:05, 27.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|██▉       | 106/360 [50:34<1:58:32, 28.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|██▉       | 107/360 [51:21<2:21:59, 33.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|███       | 108/360 [51:52<2:17:54, 32.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|███       | 109/360 [52:54<2:54:29, 41.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███       | 110/360 [53:27<2:42:10, 38.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███       | 111/360 [53:50<2:21:55, 34.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███       | 112/360 [54:29<2:27:34, 35.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|███▏      | 113/360 [54:45<2:01:46, 29.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▏      | 114/360 [55:23<2:12:10, 32.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▏      | 115/360 [55:49<2:04:12, 30.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▏      | 116/360 [56:12<1:54:51, 28.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|███▎      | 117/360 [56:42<1:55:35, 28.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|███▎      | 118/360 [57:14<1:59:38, 29.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|███▎      | 119/360 [57:46<2:02:19, 30.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|███▎      | 120/360 [58:22<2:08:38, 32.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▎      | 121/360 [58:55<2:09:06, 32.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▍      | 122/360 [59:26<2:06:32, 31.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▍      | 123/360 [59:48<1:54:33, 29.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|███▍      | 124/360 [1:00:15<1:51:34, 28.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|███▍      | 125/360 [1:00:33<1:38:26, 25.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|███▌      | 126/360 [1:01:00<1:40:01, 25.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|███▌      | 127/360 [1:01:19<1:32:00, 23.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▌      | 128/360 [1:01:52<1:42:28, 26.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▌      | 129/360 [1:02:42<2:09:07, 33.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▌      | 130/360 [1:03:12<2:05:02, 32.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|███▋      | 131/360 [1:03:42<2:01:36, 31.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|███▋      | 132/360 [1:04:30<2:19:09, 36.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|███▋      | 133/360 [1:04:59<2:09:20, 34.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|███▋      | 134/360 [1:05:22<1:56:07, 30.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 135/360 [1:05:51<1:53:51, 30.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 136/360 [1:06:25<1:57:21, 31.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 137/360 [1:06:48<1:47:28, 28.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|███▊      | 138/360 [1:07:13<1:42:59, 27.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▊      | 139/360 [1:07:46<1:48:14, 29.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▉      | 140/360 [1:08:12<1:44:08, 28.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▉      | 141/360 [1:08:47<1:50:47, 30.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|███▉      | 142/360 [1:09:16<1:48:15, 29.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|███▉      | 143/360 [1:09:46<1:48:29, 30.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|████      | 144/360 [1:10:09<1:40:25, 27.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|████      | 145/360 [1:10:34<1:36:20, 26.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████      | 146/360 [1:11:07<1:42:26, 28.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████      | 147/360 [1:11:50<1:58:00, 33.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████      | 148/360 [1:12:34<2:08:36, 36.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|████▏     | 149/360 [1:12:56<1:53:02, 32.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▏     | 150/360 [1:13:23<1:46:56, 30.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▏     | 151/360 [1:14:04<1:57:00, 33.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▏     | 152/360 [1:14:25<1:43:49, 29.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|████▎     | 153/360 [1:14:45<1:32:07, 26.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|████▎     | 154/360 [1:15:17<1:37:22, 28.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|████▎     | 155/360 [1:15:51<1:42:27, 29.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|████▎     | 156/360 [1:16:14<1:34:50, 27.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▎     | 157/360 [1:16:49<1:41:53, 30.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▍     | 158/360 [1:17:23<1:45:50, 31.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▍     | 159/360 [1:17:49<1:39:07, 29.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|████▍     | 160/360 [1:18:12<1:32:49, 27.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|████▍     | 161/360 [1:18:36<1:27:52, 26.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|████▌     | 162/360 [1:19:08<1:33:12, 28.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|████▌     | 163/360 [1:19:28<1:24:52, 25.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▌     | 164/360 [1:19:45<1:14:58, 22.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▌     | 165/360 [1:20:03<1:10:33, 21.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▌     | 166/360 [1:20:39<1:23:56, 25.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|████▋     | 167/360 [1:21:05<1:23:47, 26.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|████▋     | 168/360 [1:21:22<1:13:54, 23.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|████▋     | 169/360 [1:21:53<1:21:40, 25.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|████▋     | 170/360 [1:22:16<1:18:03, 24.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 171/360 [1:22:49<1:25:56, 27.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 172/360 [1:23:11<1:20:30, 25.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 173/360 [1:23:43<1:25:49, 27.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|████▊     | 174/360 [1:23:57<1:13:16, 23.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▊     | 175/360 [1:24:22<1:13:41, 23.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▉     | 176/360 [1:24:35<1:03:14, 20.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▉     | 177/360 [1:24:51<58:43, 19.25s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|████▉     | 178/360 [1:25:08<56:38, 18.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|████▉     | 179/360 [1:25:42<1:09:41, 23.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|█████     | 180/360 [1:26:06<1:10:35, 23.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|█████     | 181/360 [1:26:22<1:02:49, 21.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████     | 182/360 [1:26:48<1:06:57, 22.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████     | 183/360 [1:27:24<1:18:32, 26.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████     | 184/360 [1:27:48<1:16:15, 25.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|█████▏    | 185/360 [1:28:08<1:10:32, 24.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▏    | 186/360 [1:28:28<1:06:27, 22.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▏    | 187/360 [1:28:49<1:04:10, 22.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▏    | 188/360 [1:29:10<1:03:08, 22.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|█████▎    | 189/360 [1:29:27<58:22, 20.48s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|█████▎    | 190/360 [1:29:44<54:58, 19.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|█████▎    | 191/360 [1:30:04<55:06, 19.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|█████▎    | 192/360 [1:30:35<1:04:09, 22.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▎    | 193/360 [1:30:56<1:02:35, 22.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▍    | 194/360 [1:31:15<58:49, 21.26s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▍    | 195/360 [1:31:36<58:39, 21.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|█████▍    | 196/360 [1:31:58<59:04, 21.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|█████▍    | 197/360 [1:32:39<1:14:16, 27.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|█████▌    | 198/360 [1:33:23<1:27:09, 32.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|█████▌    | 199/360 [1:33:41<1:14:50, 27.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▌    | 200/360 [1:34:24<1:26:30, 32.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▌    | 201/360 [1:34:58<1:27:39, 33.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▌    | 202/360 [1:35:20<1:17:57, 29.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|█████▋    | 203/360 [1:35:47<1:15:54, 29.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▋    | 204/360 [1:36:13<1:12:58, 28.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▋    | 205/360 [1:36:38<1:10:07, 27.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▋    | 206/360 [1:37:03<1:07:39, 26.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|█████▊    | 207/360 [1:37:25<1:04:02, 25.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|█████▊    | 208/360 [1:37:45<59:38, 23.55s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|█████▊    | 209/360 [1:38:11<1:01:09, 24.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|█████▊    | 210/360 [1:38:28<55:08, 22.06s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▊    | 211/360 [1:38:51<56:02, 22.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▉    | 212/360 [1:39:44<1:18:11, 31.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▉    | 213/360 [1:40:06<1:10:07, 28.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|█████▉    | 214/360 [1:40:44<1:16:12, 31.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|█████▉    | 215/360 [1:41:02<1:06:18, 27.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|██████    | 216/360 [1:41:28<1:04:52, 27.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|██████    | 217/360 [1:42:02<1:09:17, 29.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████    | 218/360 [1:42:26<1:05:34, 27.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████    | 219/360 [1:42:54<1:05:04, 27.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████    | 220/360 [1:43:16<1:00:46, 26.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|██████▏   | 221/360 [1:43:35<55:33, 23.98s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▏   | 222/360 [1:44:00<55:32, 24.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▏   | 223/360 [1:44:47<1:10:41, 30.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▏   | 224/360 [1:45:09<1:04:15, 28.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|██████▎   | 225/360 [1:45:56<1:16:14, 33.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|██████▎   | 226/360 [1:46:23<1:11:27, 32.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|██████▎   | 227/360 [1:46:47<1:05:35, 29.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|██████▎   | 228/360 [1:47:08<59:14, 26.92s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▎   | 229/360 [1:47:33<57:26, 26.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▍   | 230/360 [1:47:45<47:26, 21.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▍   | 231/360 [1:48:23<58:00, 26.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|██████▍   | 232/360 [1:48:58<1:02:11, 29.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|██████▍   | 233/360 [1:49:22<58:45, 27.76s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|██████▌   | 234/360 [1:49:46<56:03, 26.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|██████▌   | 235/360 [1:50:14<56:08, 26.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▌   | 236/360 [1:50:38<53:48, 26.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▌   | 237/360 [1:50:59<50:33, 24.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▌   | 238/360 [1:51:34<56:02, 27.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|██████▋   | 239/360 [1:52:43<1:21:09, 40.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|██████▋   | 240/360 [1:53:15<1:15:09, 37.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|██████▋   | 241/360 [1:53:46<1:10:34, 35.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|██████▋   | 242/360 [1:54:02<58:18, 29.65s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 243/360 [1:54:23<52:49, 27.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 244/360 [1:54:51<53:17, 27.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 245/360 [1:55:17<51:42, 26.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|██████▊   | 246/360 [1:55:41<49:36, 26.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▊   | 247/360 [1:56:05<48:03, 25.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▉   | 248/360 [1:56:42<54:02, 28.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▉   | 249/360 [1:57:18<57:35, 31.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|██████▉   | 250/360 [1:57:52<58:36, 31.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|██████▉   | 251/360 [1:58:41<1:07:22, 37.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|███████   | 252/360 [1:59:03<58:32, 32.52s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|███████   | 253/360 [1:59:23<51:29, 28.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████   | 254/360 [1:59:49<49:17, 27.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████   | 255/360 [2:00:11<45:37, 26.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████   | 256/360 [2:00:40<46:54, 27.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|███████▏  | 257/360 [2:01:06<45:43, 26.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▏  | 258/360 [2:01:31<44:23, 26.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▏  | 259/360 [2:01:57<44:04, 26.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▏  | 260/360 [2:02:20<41:50, 25.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|███████▎  | 261/360 [2:02:46<42:02, 25.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|███████▎  | 262/360 [2:03:12<41:41, 25.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|███████▎  | 263/360 [2:03:36<40:35, 25.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|███████▎  | 264/360 [2:04:00<39:41, 24.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▎  | 265/360 [2:04:23<38:34, 24.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▍  | 266/360 [2:04:44<36:17, 23.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▍  | 267/360 [2:05:00<32:31, 20.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|███████▍  | 268/360 [2:05:28<35:41, 23.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|███████▍  | 269/360 [2:05:42<30:51, 20.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|███████▌  | 270/360 [2:06:22<39:41, 26.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|███████▌  | 271/360 [2:06:50<39:52, 26.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▌  | 272/360 [2:07:12<37:12, 25.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▌  | 273/360 [2:07:46<40:29, 27.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▌  | 274/360 [2:08:18<41:57, 29.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|███████▋  | 275/360 [2:08:40<37:59, 26.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|███████▋  | 276/360 [2:09:02<35:45, 25.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|███████▋  | 277/360 [2:09:25<34:25, 24.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|███████▋  | 278/360 [2:09:59<37:24, 27.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 279/360 [2:10:29<38:06, 28.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 280/360 [2:10:57<37:30, 28.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 281/360 [2:11:29<38:43, 29.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|███████▊  | 282/360 [2:11:54<36:27, 28.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▊  | 283/360 [2:12:17<33:55, 26.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▉  | 284/360 [2:12:58<39:12, 30.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▉  | 285/360 [2:13:22<36:07, 28.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|███████▉  | 286/360 [2:13:51<35:32, 28.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|███████▉  | 287/360 [2:14:18<34:26, 28.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|████████  | 288/360 [2:14:53<36:16, 30.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|████████  | 289/360 [2:15:20<34:42, 29.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████  | 290/360 [2:15:46<32:56, 28.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████  | 291/360 [2:16:18<33:57, 29.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████  | 292/360 [2:16:49<33:57, 29.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|████████▏ | 293/360 [2:17:37<39:22, 35.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▏ | 294/360 [2:18:27<43:36, 39.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▏ | 295/360 [2:18:52<38:09, 35.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▏ | 296/360 [2:19:06<30:52, 28.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|████████▎ | 297/360 [2:19:48<34:35, 32.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|████████▎ | 298/360 [2:20:30<36:41, 35.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|████████▎ | 299/360 [2:20:48<30:47, 30.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|████████▎ | 300/360 [2:21:15<29:21, 29.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▎ | 301/360 [2:21:41<27:47, 28.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▍ | 302/360 [2:22:13<28:33, 29.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▍ | 303/360 [2:22:42<27:49, 29.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|████████▍ | 304/360 [2:23:13<27:49, 29.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|████████▍ | 305/360 [2:23:45<28:04, 30.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|████████▌ | 306/360 [2:24:01<23:35, 26.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|████████▌ | 307/360 [2:24:21<21:25, 24.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▌ | 308/360 [2:24:43<20:24, 23.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▌ | 309/360 [2:25:09<20:34, 24.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▌ | 310/360 [2:25:51<24:41, 29.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|████████▋ | 311/360 [2:26:10<21:32, 26.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|████████▋ | 312/360 [2:26:27<18:55, 23.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|████████▋ | 313/360 [2:26:58<20:13, 25.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|████████▋ | 314/360 [2:27:20<19:03, 24.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 315/360 [2:27:39<17:06, 22.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 316/360 [2:28:06<17:40, 24.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 317/360 [2:28:51<21:48, 30.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|████████▊ | 318/360 [2:29:14<19:49, 28.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▊ | 319/360 [2:29:35<17:51, 26.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▉ | 320/360 [2:30:02<17:37, 26.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▉ | 321/360 [2:30:26<16:34, 25.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|████████▉ | 322/360 [2:30:48<15:35, 24.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|████████▉ | 323/360 [2:31:22<16:55, 27.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|█████████ | 324/360 [2:31:57<17:45, 29.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|█████████ | 325/360 [2:32:17<15:30, 26.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████ | 326/360 [2:32:44<15:09, 26.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████ | 327/360 [2:33:00<13:02, 23.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████ | 328/360 [2:33:15<11:16, 21.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|█████████▏| 329/360 [2:33:35<10:40, 20.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▏| 330/360 [2:34:04<11:31, 23.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▏| 331/360 [2:34:26<11:05, 22.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▏| 332/360 [2:34:58<11:55, 25.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|█████████▎| 333/360 [2:35:19<10:53, 24.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|█████████▎| 334/360 [2:35:59<12:32, 28.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|█████████▎| 335/360 [2:36:50<14:45, 35.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|█████████▎| 336/360 [2:37:09<12:13, 30.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▎| 337/360 [2:37:38<11:34, 30.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▍| 338/360 [2:38:10<11:13, 30.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▍| 339/360 [2:38:40<10:39, 30.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|█████████▍| 340/360 [2:39:05<09:39, 28.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|█████████▍| 341/360 [2:39:36<09:21, 29.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|█████████▌| 342/360 [2:40:03<08:34, 28.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|█████████▌| 343/360 [2:40:25<07:34, 26.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▌| 344/360 [2:40:46<06:40, 25.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▌| 345/360 [2:41:10<06:10, 24.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▌| 346/360 [2:41:30<05:27, 23.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|█████████▋| 347/360 [2:41:48<04:40, 21.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|█████████▋| 348/360 [2:42:09<04:17, 21.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|█████████▋| 349/360 [2:42:48<04:53, 26.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|█████████▋| 350/360 [2:43:12<04:20, 26.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 351/360 [2:43:32<03:37, 24.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 352/360 [2:43:49<02:54, 21.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 353/360 [2:44:10<02:32, 21.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|█████████▊| 354/360 [2:44:35<02:16, 22.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▊| 355/360 [2:44:57<01:52, 22.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▉| 356/360 [2:45:29<01:40, 25.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▉| 357/360 [2:45:55<01:16, 25.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|█████████▉| 358/360 [2:46:22<00:51, 25.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|█████████▉| 359/360 [2:46:53<00:27, 27.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|██████████| 360/360 [2:47:23<00:00, 28.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|██████████| 360/360 [2:47:23<00:00, 27.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY FOR GEMMA3\n",
      "============================================================\n",
      "📊 IMAGE PROCESSING SUMMARY:\n",
      "   Total images attempted: 360\n",
      "   Successfully processed: 360 (100.0%)\n",
      "   Failed images: 0 (0.0%)\n",
      "\n",
      "📝 QUESTION PROCESSING SUMMARY:\n",
      "   Total questions attempted: 1080\n",
      "   Successfully processed: 1080 (100.0%)\n",
      "   Failed questions: 0 (0.0%)\n",
      "   Results saved: 1080\n",
      "\n",
      "✅ SUCCESSFUL IMAGES (360):\n",
      "   • image01 (Type: REAL, Questions: 3/3, Time: 25.6s)\n",
      "   • image02 (Type: REAL, Questions: 3/3, Time: 32.3s)\n",
      "   • image03 (Type: REAL, Questions: 3/3, Time: 19.2s)\n",
      "   • image04 (Type: REAL, Questions: 3/3, Time: 25.3s)\n",
      "   • image05 (Type: REAL, Questions: 3/3, Time: 34.6s)\n",
      "   • image06 (Type: REAL, Questions: 3/3, Time: 23.0s)\n",
      "   • image07 (Type: REAL, Questions: 3/3, Time: 12.2s)\n",
      "   • image08 (Type: REAL, Questions: 3/3, Time: 16.8s)\n",
      "   • image09 (Type: REAL, Questions: 3/3, Time: 32.2s)\n",
      "   • image10 (Type: REAL, Questions: 3/3, Time: 29.9s)\n",
      "   • image11 (Type: REAL, Questions: 3/3, Time: 27.7s)\n",
      "   • image12 (Type: REAL, Questions: 3/3, Time: 31.5s)\n",
      "   • image13 (Type: REAL, Questions: 3/3, Time: 31.4s)\n",
      "   • image14 (Type: REAL, Questions: 3/3, Time: 15.3s)\n",
      "   • image15 (Type: REAL, Questions: 3/3, Time: 20.0s)\n",
      "   • image16 (Type: REAL, Questions: 3/3, Time: 25.4s)\n",
      "   • image17 (Type: REAL, Questions: 3/3, Time: 19.9s)\n",
      "   • image18 (Type: REAL, Questions: 3/3, Time: 33.0s)\n",
      "   • image19 (Type: REAL, Questions: 3/3, Time: 18.4s)\n",
      "   • image20 (Type: REAL, Questions: 3/3, Time: 20.7s)\n",
      "   • image21 (Type: REAL, Questions: 3/3, Time: 25.3s)\n",
      "   • image22 (Type: REAL, Questions: 3/3, Time: 24.5s)\n",
      "   • image23 (Type: REAL, Questions: 3/3, Time: 30.0s)\n",
      "   • image24 (Type: REAL, Questions: 3/3, Time: 32.2s)\n",
      "   • image25 (Type: REAL, Questions: 3/3, Time: 30.7s)\n",
      "   • image26 (Type: REAL, Questions: 3/3, Time: 29.2s)\n",
      "   • image27 (Type: REAL, Questions: 3/3, Time: 23.0s)\n",
      "   • image28 (Type: REAL, Questions: 3/3, Time: 20.7s)\n",
      "   • image29 (Type: REAL, Questions: 3/3, Time: 38.4s)\n",
      "   • image30 (Type: REAL, Questions: 3/3, Time: 41.5s)\n",
      "   • image31 (Type: REAL, Questions: 3/3, Time: 18.4s)\n",
      "   • image32 (Type: REAL, Questions: 3/3, Time: 52.2s)\n",
      "   • image33 (Type: REAL, Questions: 3/3, Time: 35.3s)\n",
      "   • image34 (Type: REAL, Questions: 3/3, Time: 22.2s)\n",
      "   • image35 (Type: REAL, Questions: 3/3, Time: 65.3s)\n",
      "   • image36 (Type: REAL, Questions: 3/3, Time: 47.6s)\n",
      "   • image37 (Type: REAL, Questions: 3/3, Time: 26.1s)\n",
      "   • image38 (Type: REAL, Questions: 3/3, Time: 26.9s)\n",
      "   • image39 (Type: REAL, Questions: 3/3, Time: 52.3s)\n",
      "   • image40 (Type: REAL, Questions: 3/3, Time: 36.1s)\n",
      "   • image41 (Type: REAL, Questions: 3/3, Time: 19.1s)\n",
      "   • image42 (Type: REAL, Questions: 3/3, Time: 20.7s)\n",
      "   • image43 (Type: REAL, Questions: 3/3, Time: 23.0s)\n",
      "   • image44 (Type: REAL, Questions: 3/3, Time: 20.0s)\n",
      "   • image45 (Type: REAL, Questions: 3/3, Time: 30.7s)\n",
      "   • image46 (Type: REAL, Questions: 3/3, Time: 43.0s)\n",
      "   • image47 (Type: REAL, Questions: 3/3, Time: 25.3s)\n",
      "   • image48 (Type: REAL, Questions: 3/3, Time: 22.2s)\n",
      "   • image49 (Type: REAL, Questions: 3/3, Time: 29.2s)\n",
      "   • image50 (Type: REAL, Questions: 3/3, Time: 36.1s)\n",
      "   • image51 (Type: REAL, Questions: 3/3, Time: 75.4s)\n",
      "   • image52 (Type: REAL, Questions: 3/3, Time: 28.4s)\n",
      "   • image53 (Type: REAL, Questions: 3/3, Time: 28.4s)\n",
      "   • image54 (Type: REAL, Questions: 3/3, Time: 28.0s)\n",
      "   • image55 (Type: REAL, Questions: 3/3, Time: 30.8s)\n",
      "   • image56 (Type: REAL, Questions: 3/3, Time: 27.5s)\n",
      "   • image57 (Type: REAL, Questions: 3/3, Time: 29.2s)\n",
      "   • image58 (Type: REAL, Questions: 3/3, Time: 30.7s)\n",
      "   • image59 (Type: REAL, Questions: 3/3, Time: 21.5s)\n",
      "   • image60 (Type: REAL, Questions: 3/3, Time: 63.9s)\n",
      "   • image61 (Type: REAL, Questions: 3/3, Time: 23.9s)\n",
      "   • image62 (Type: REAL, Questions: 3/3, Time: 30.7s)\n",
      "   • image63 (Type: REAL, Questions: 3/3, Time: 32.3s)\n",
      "   • image64 (Type: REAL, Questions: 3/3, Time: 32.4s)\n",
      "   • image65 (Type: REAL, Questions: 3/3, Time: 16.1s)\n",
      "   • image66 (Type: REAL, Questions: 3/3, Time: 21.5s)\n",
      "   • image67 (Type: REAL, Questions: 3/3, Time: 33.1s)\n",
      "   • image68 (Type: REAL, Questions: 3/3, Time: 16.9s)\n",
      "   • image69 (Type: REAL, Questions: 3/3, Time: 36.9s)\n",
      "   • image70 (Type: REAL, Questions: 3/3, Time: 23.1s)\n",
      "   • image71 (Type: REAL, Questions: 3/3, Time: 19.3s)\n",
      "   • image72 (Type: REAL, Questions: 3/3, Time: 25.4s)\n",
      "   • image73 (Type: REAL, Questions: 3/3, Time: 15.3s)\n",
      "   • image74 (Type: REAL, Questions: 3/3, Time: 28.4s)\n",
      "   • image75 (Type: REAL, Questions: 3/3, Time: 37.4s)\n",
      "   • image76 (Type: REAL, Questions: 3/3, Time: 21.5s)\n",
      "   • image77 (Type: REAL, Questions: 3/3, Time: 29.9s)\n",
      "   • image78 (Type: REAL, Questions: 3/3, Time: 36.9s)\n",
      "   • image79 (Type: REAL, Questions: 3/3, Time: 31.5s)\n",
      "   • image80 (Type: REAL, Questions: 3/3, Time: 33.0s)\n",
      "   • image81 (Type: REAL, Questions: 3/3, Time: 13.8s)\n",
      "   • image82 (Type: REAL, Questions: 3/3, Time: 18.5s)\n",
      "   • image83 (Type: REAL, Questions: 3/3, Time: 32.2s)\n",
      "   • image84 (Type: REAL, Questions: 3/3, Time: 21.8s)\n",
      "   • image85 (Type: REAL, Questions: 3/3, Time: 23.2s)\n",
      "   • image86 (Type: REAL, Questions: 3/3, Time: 19.9s)\n",
      "   • image87 (Type: REAL, Questions: 3/3, Time: 36.2s)\n",
      "   • image88 (Type: REAL, Questions: 3/3, Time: 26.9s)\n",
      "   • image89 (Type: REAL, Questions: 3/3, Time: 31.7s)\n",
      "   • image90 (Type: REAL, Questions: 3/3, Time: 22.4s)\n",
      "   • image91 (Type: REAL, Questions: 3/3, Time: 32.2s)\n",
      "   • image92 (Type: REAL, Questions: 3/3, Time: 32.7s)\n",
      "   • image93 (Type: REAL, Questions: 3/3, Time: 27.7s)\n",
      "   • image94 (Type: REAL, Questions: 3/3, Time: 22.3s)\n",
      "   • image95 (Type: REAL, Questions: 3/3, Time: 17.7s)\n",
      "   • image96 (Type: REAL, Questions: 3/3, Time: 18.5s)\n",
      "   • image97 (Type: REAL, Questions: 3/3, Time: 20.1s)\n",
      "   • image98 (Type: REAL, Questions: 3/3, Time: 26.9s)\n",
      "   • image99 (Type: REAL, Questions: 3/3, Time: 27.1s)\n",
      "   • image100 (Type: REAL, Questions: 3/3, Time: 33.1s)\n",
      "   • image101 (Type: REAL, Questions: 3/3, Time: 30.0s)\n",
      "   • image102 (Type: REAL, Questions: 3/3, Time: 43.8s)\n",
      "   • image103 (Type: REAL, Questions: 3/3, Time: 26.9s)\n",
      "   • image104 (Type: REAL, Questions: 3/3, Time: 23.8s)\n",
      "   • image105 (Type: REAL, Questions: 3/3, Time: 25.3s)\n",
      "   • image106 (Type: REAL, Questions: 3/3, Time: 28.5s)\n",
      "   • image107 (Type: REAL, Questions: 3/3, Time: 46.9s)\n",
      "   • image108 (Type: REAL, Questions: 3/3, Time: 30.9s)\n",
      "   • image109 (Type: REAL, Questions: 3/3, Time: 62.4s)\n",
      "   • image110 (Type: REAL, Questions: 3/3, Time: 32.4s)\n",
      "   • image111 (Type: REAL, Questions: 3/3, Time: 23.2s)\n",
      "   • image112 (Type: REAL, Questions: 3/3, Time: 39.2s)\n",
      "   • image113 (Type: REAL, Questions: 3/3, Time: 15.3s)\n",
      "   • image114 (Type: REAL, Questions: 3/3, Time: 38.4s)\n",
      "   • image115 (Type: REAL, Questions: 3/3, Time: 26.2s)\n",
      "   • image116 (Type: REAL, Questions: 3/3, Time: 23.2s)\n",
      "   • image117 (Type: REAL, Questions: 3/3, Time: 29.2s)\n",
      "   • image118 (Type: REAL, Questions: 3/3, Time: 32.3s)\n",
      "   • image119 (Type: REAL, Questions: 3/3, Time: 32.3s)\n",
      "   • image120 (Type: REAL, Questions: 3/3, Time: 36.1s)\n",
      "   • image01 (Type: ANIMATED, Questions: 3/3, Time: 33.0s)\n",
      "   • image02 (Type: ANIMATED, Questions: 3/3, Time: 30.7s)\n",
      "   • image03 (Type: ANIMATED, Questions: 3/3, Time: 22.2s)\n",
      "   • image04 (Type: ANIMATED, Questions: 3/3, Time: 26.9s)\n",
      "   • image05 (Type: ANIMATED, Questions: 3/3, Time: 17.6s)\n",
      "   • image06 (Type: ANIMATED, Questions: 3/3, Time: 26.8s)\n",
      "   • image07 (Type: ANIMATED, Questions: 3/3, Time: 19.1s)\n",
      "   • image08 (Type: ANIMATED, Questions: 3/3, Time: 33.0s)\n",
      "   • image09 (Type: ANIMATED, Questions: 3/3, Time: 50.0s)\n",
      "   • image10 (Type: ANIMATED, Questions: 3/3, Time: 30.5s)\n",
      "   • image11 (Type: ANIMATED, Questions: 3/3, Time: 30.1s)\n",
      "   • image12 (Type: ANIMATED, Questions: 3/3, Time: 47.7s)\n",
      "   • image13 (Type: ANIMATED, Questions: 3/3, Time: 28.5s)\n",
      "   • image14 (Type: ANIMATED, Questions: 3/3, Time: 23.0s)\n",
      "   • image15 (Type: ANIMATED, Questions: 3/3, Time: 29.3s)\n",
      "   • image16 (Type: ANIMATED, Questions: 3/3, Time: 33.9s)\n",
      "   • image17 (Type: ANIMATED, Questions: 3/3, Time: 23.0s)\n",
      "   • image18 (Type: ANIMATED, Questions: 3/3, Time: 25.3s)\n",
      "   • image19 (Type: ANIMATED, Questions: 3/3, Time: 33.0s)\n",
      "   • image20 (Type: ANIMATED, Questions: 3/3, Time: 26.1s)\n",
      "   • image21 (Type: ANIMATED, Questions: 3/3, Time: 34.9s)\n",
      "   • image22 (Type: ANIMATED, Questions: 3/3, Time: 28.5s)\n",
      "   • image23 (Type: ANIMATED, Questions: 3/3, Time: 30.5s)\n",
      "   • image24 (Type: ANIMATED, Questions: 3/3, Time: 23.0s)\n",
      "   • image25 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image26 (Type: ANIMATED, Questions: 3/3, Time: 33.0s)\n",
      "   • image27 (Type: ANIMATED, Questions: 3/3, Time: 43.8s)\n",
      "   • image28 (Type: ANIMATED, Questions: 3/3, Time: 43.8s)\n",
      "   • image29 (Type: ANIMATED, Questions: 3/3, Time: 22.2s)\n",
      "   • image30 (Type: ANIMATED, Questions: 3/3, Time: 26.8s)\n",
      "   • image31 (Type: ANIMATED, Questions: 3/3, Time: 40.7s)\n",
      "   • image32 (Type: ANIMATED, Questions: 3/3, Time: 21.4s)\n",
      "   • image33 (Type: ANIMATED, Questions: 3/3, Time: 19.1s)\n",
      "   • image34 (Type: ANIMATED, Questions: 3/3, Time: 32.2s)\n",
      "   • image35 (Type: ANIMATED, Questions: 3/3, Time: 33.8s)\n",
      "   • image36 (Type: ANIMATED, Questions: 3/3, Time: 23.0s)\n",
      "   • image37 (Type: ANIMATED, Questions: 3/3, Time: 35.3s)\n",
      "   • image38 (Type: ANIMATED, Questions: 3/3, Time: 34.5s)\n",
      "   • image39 (Type: ANIMATED, Questions: 3/3, Time: 25.3s)\n",
      "   • image40 (Type: ANIMATED, Questions: 3/3, Time: 23.8s)\n",
      "   • image41 (Type: ANIMATED, Questions: 3/3, Time: 23.3s)\n",
      "   • image42 (Type: ANIMATED, Questions: 3/3, Time: 32.3s)\n",
      "   • image43 (Type: ANIMATED, Questions: 3/3, Time: 20.3s)\n",
      "   • image44 (Type: ANIMATED, Questions: 3/3, Time: 16.2s)\n",
      "   • image45 (Type: ANIMATED, Questions: 3/3, Time: 18.8s)\n",
      "   • image46 (Type: ANIMATED, Questions: 3/3, Time: 35.9s)\n",
      "   • image47 (Type: ANIMATED, Questions: 3/3, Time: 26.3s)\n",
      "   • image48 (Type: ANIMATED, Questions: 3/3, Time: 16.2s)\n",
      "   • image49 (Type: ANIMATED, Questions: 3/3, Time: 31.6s)\n",
      "   • image50 (Type: ANIMATED, Questions: 3/3, Time: 22.3s)\n",
      "   • image51 (Type: ANIMATED, Questions: 3/3, Time: 33.4s)\n",
      "   • image52 (Type: ANIMATED, Questions: 3/3, Time: 22.0s)\n",
      "   • image53 (Type: ANIMATED, Questions: 3/3, Time: 31.8s)\n",
      "   • image54 (Type: ANIMATED, Questions: 3/3, Time: 14.5s)\n",
      "   • image55 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image56 (Type: ANIMATED, Questions: 3/3, Time: 13.0s)\n",
      "   • image57 (Type: ANIMATED, Questions: 3/3, Time: 16.1s)\n",
      "   • image58 (Type: ANIMATED, Questions: 3/3, Time: 17.3s)\n",
      "   • image59 (Type: ANIMATED, Questions: 3/3, Time: 33.4s)\n",
      "   • image60 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image61 (Type: ANIMATED, Questions: 3/3, Time: 15.3s)\n",
      "   • image62 (Type: ANIMATED, Questions: 3/3, Time: 26.1s)\n",
      "   • image63 (Type: ANIMATED, Questions: 3/3, Time: 36.1s)\n",
      "   • image64 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image65 (Type: ANIMATED, Questions: 3/3, Time: 20.0s)\n",
      "   • image66 (Type: ANIMATED, Questions: 3/3, Time: 19.9s)\n",
      "   • image67 (Type: ANIMATED, Questions: 3/3, Time: 20.7s)\n",
      "   • image68 (Type: ANIMATED, Questions: 3/3, Time: 21.5s)\n",
      "   • image69 (Type: ANIMATED, Questions: 3/3, Time: 16.9s)\n",
      "   • image70 (Type: ANIMATED, Questions: 3/3, Time: 16.9s)\n",
      "   • image71 (Type: ANIMATED, Questions: 3/3, Time: 19.9s)\n",
      "   • image72 (Type: ANIMATED, Questions: 3/3, Time: 30.7s)\n",
      "   • image73 (Type: ANIMATED, Questions: 3/3, Time: 21.5s)\n",
      "   • image74 (Type: ANIMATED, Questions: 3/3, Time: 18.4s)\n",
      "   • image75 (Type: ANIMATED, Questions: 3/3, Time: 21.5s)\n",
      "   • image76 (Type: ANIMATED, Questions: 3/3, Time: 22.3s)\n",
      "   • image77 (Type: ANIMATED, Questions: 3/3, Time: 40.7s)\n",
      "   • image78 (Type: ANIMATED, Questions: 3/3, Time: 43.8s)\n",
      "   • image79 (Type: ANIMATED, Questions: 3/3, Time: 17.6s)\n",
      "   • image80 (Type: ANIMATED, Questions: 3/3, Time: 43.0s)\n",
      "   • image81 (Type: ANIMATED, Questions: 3/3, Time: 34.6s)\n",
      "   • image82 (Type: ANIMATED, Questions: 3/3, Time: 21.5s)\n",
      "   • image83 (Type: ANIMATED, Questions: 3/3, Time: 27.6s)\n",
      "   • image84 (Type: ANIMATED, Questions: 3/3, Time: 25.9s)\n",
      "   • image85 (Type: ANIMATED, Questions: 3/3, Time: 25.0s)\n",
      "   • image86 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image87 (Type: ANIMATED, Questions: 3/3, Time: 22.2s)\n",
      "   • image88 (Type: ANIMATED, Questions: 3/3, Time: 19.9s)\n",
      "   • image89 (Type: ANIMATED, Questions: 3/3, Time: 26.1s)\n",
      "   • image90 (Type: ANIMATED, Questions: 3/3, Time: 16.8s)\n",
      "   • image91 (Type: ANIMATED, Questions: 3/3, Time: 23.8s)\n",
      "   • image92 (Type: ANIMATED, Questions: 3/3, Time: 53.0s)\n",
      "   • image93 (Type: ANIMATED, Questions: 3/3, Time: 21.4s)\n",
      "   • image94 (Type: ANIMATED, Questions: 3/3, Time: 37.6s)\n",
      "   • image95 (Type: ANIMATED, Questions: 3/3, Time: 18.4s)\n",
      "   • image96 (Type: ANIMATED, Questions: 3/3, Time: 26.1s)\n",
      "   • image97 (Type: ANIMATED, Questions: 3/3, Time: 33.9s)\n",
      "   • image98 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image99 (Type: ANIMATED, Questions: 3/3, Time: 27.6s)\n",
      "   • image100 (Type: ANIMATED, Questions: 3/3, Time: 22.2s)\n",
      "   • image101 (Type: ANIMATED, Questions: 3/3, Time: 19.2s)\n",
      "   • image102 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image103 (Type: ANIMATED, Questions: 3/3, Time: 46.9s)\n",
      "   • image104 (Type: ANIMATED, Questions: 3/3, Time: 22.2s)\n",
      "   • image105 (Type: ANIMATED, Questions: 3/3, Time: 46.8s)\n",
      "   • image106 (Type: ANIMATED, Questions: 3/3, Time: 27.6s)\n",
      "   • image107 (Type: ANIMATED, Questions: 3/3, Time: 24.0s)\n",
      "   • image108 (Type: ANIMATED, Questions: 3/3, Time: 20.7s)\n",
      "   • image109 (Type: ANIMATED, Questions: 3/3, Time: 24.9s)\n",
      "   • image110 (Type: ANIMATED, Questions: 3/3, Time: 11.6s)\n",
      "   • image111 (Type: ANIMATED, Questions: 3/3, Time: 38.8s)\n",
      "   • image112 (Type: ANIMATED, Questions: 3/3, Time: 34.2s)\n",
      "   • image113 (Type: ANIMATED, Questions: 3/3, Time: 24.5s)\n",
      "   • image114 (Type: ANIMATED, Questions: 3/3, Time: 24.2s)\n",
      "   • image115 (Type: ANIMATED, Questions: 3/3, Time: 27.5s)\n",
      "   • image116 (Type: ANIMATED, Questions: 3/3, Time: 23.9s)\n",
      "   • image117 (Type: ANIMATED, Questions: 3/3, Time: 21.4s)\n",
      "   • image118 (Type: ANIMATED, Questions: 3/3, Time: 34.3s)\n",
      "   • image119 (Type: ANIMATED, Questions: 3/3, Time: 69.8s)\n",
      "   • image120 (Type: ANIMATED, Questions: 3/3, Time: 31.4s)\n",
      "   • image01 (Type: AI_GENERATED, Questions: 3/3, Time: 30.9s)\n",
      "   • image02 (Type: AI_GENERATED, Questions: 3/3, Time: 15.8s)\n",
      "   • image03 (Type: AI_GENERATED, Questions: 3/3, Time: 21.1s)\n",
      "   • image04 (Type: AI_GENERATED, Questions: 3/3, Time: 28.7s)\n",
      "   • image05 (Type: AI_GENERATED, Questions: 3/3, Time: 25.6s)\n",
      "   • image06 (Type: AI_GENERATED, Questions: 3/3, Time: 24.1s)\n",
      "   • image07 (Type: AI_GENERATED, Questions: 3/3, Time: 24.1s)\n",
      "   • image08 (Type: AI_GENERATED, Questions: 3/3, Time: 37.0s)\n",
      "   • image09 (Type: AI_GENERATED, Questions: 3/3, Time: 36.2s)\n",
      "   • image10 (Type: AI_GENERATED, Questions: 3/3, Time: 33.9s)\n",
      "   • image11 (Type: AI_GENERATED, Questions: 3/3, Time: 49.0s)\n",
      "   • image12 (Type: AI_GENERATED, Questions: 3/3, Time: 21.9s)\n",
      "   • image13 (Type: AI_GENERATED, Questions: 3/3, Time: 20.4s)\n",
      "   • image14 (Type: AI_GENERATED, Questions: 3/3, Time: 25.6s)\n",
      "   • image15 (Type: AI_GENERATED, Questions: 3/3, Time: 21.8s)\n",
      "   • image16 (Type: AI_GENERATED, Questions: 3/3, Time: 29.4s)\n",
      "   • image17 (Type: AI_GENERATED, Questions: 3/3, Time: 25.6s)\n",
      "   • image18 (Type: AI_GENERATED, Questions: 3/3, Time: 24.9s)\n",
      "   • image19 (Type: AI_GENERATED, Questions: 3/3, Time: 26.4s)\n",
      "   • image20 (Type: AI_GENERATED, Questions: 3/3, Time: 22.6s)\n",
      "   • image21 (Type: AI_GENERATED, Questions: 3/3, Time: 26.4s)\n",
      "   • image22 (Type: AI_GENERATED, Questions: 3/3, Time: 25.6s)\n",
      "   • image23 (Type: AI_GENERATED, Questions: 3/3, Time: 24.1s)\n",
      "   • image24 (Type: AI_GENERATED, Questions: 3/3, Time: 24.1s)\n",
      "   • image25 (Type: AI_GENERATED, Questions: 3/3, Time: 23.3s)\n",
      "   • image26 (Type: AI_GENERATED, Questions: 3/3, Time: 20.3s)\n",
      "   • image27 (Type: AI_GENERATED, Questions: 3/3, Time: 15.9s)\n",
      "   • image28 (Type: AI_GENERATED, Questions: 3/3, Time: 28.6s)\n",
      "   • image29 (Type: AI_GENERATED, Questions: 3/3, Time: 13.5s)\n",
      "   • image30 (Type: AI_GENERATED, Questions: 3/3, Time: 40.7s)\n",
      "   • image31 (Type: AI_GENERATED, Questions: 3/3, Time: 27.9s)\n",
      "   • image32 (Type: AI_GENERATED, Questions: 3/3, Time: 21.8s)\n",
      "   • image33 (Type: AI_GENERATED, Questions: 3/3, Time: 33.9s)\n",
      "   • image34 (Type: AI_GENERATED, Questions: 3/3, Time: 32.4s)\n",
      "   • image35 (Type: AI_GENERATED, Questions: 3/3, Time: 21.1s)\n",
      "   • image36 (Type: AI_GENERATED, Questions: 3/3, Time: 22.6s)\n",
      "   • image37 (Type: AI_GENERATED, Questions: 3/3, Time: 23.3s)\n",
      "   • image38 (Type: AI_GENERATED, Questions: 3/3, Time: 33.1s)\n",
      "   • image39 (Type: AI_GENERATED, Questions: 3/3, Time: 30.2s)\n",
      "   • image40 (Type: AI_GENERATED, Questions: 3/3, Time: 27.9s)\n",
      "   • image41 (Type: AI_GENERATED, Questions: 3/3, Time: 32.4s)\n",
      "   • image42 (Type: AI_GENERATED, Questions: 3/3, Time: 24.9s)\n",
      "   • image43 (Type: AI_GENERATED, Questions: 3/3, Time: 22.7s)\n",
      "   • image44 (Type: AI_GENERATED, Questions: 3/3, Time: 41.5s)\n",
      "   • image45 (Type: AI_GENERATED, Questions: 3/3, Time: 24.1s)\n",
      "   • image46 (Type: AI_GENERATED, Questions: 3/3, Time: 28.6s)\n",
      "   • image47 (Type: AI_GENERATED, Questions: 3/3, Time: 27.1s)\n",
      "   • image48 (Type: AI_GENERATED, Questions: 3/3, Time: 34.7s)\n",
      "   • image49 (Type: AI_GENERATED, Questions: 3/3, Time: 27.2s)\n",
      "   • image50 (Type: AI_GENERATED, Questions: 3/3, Time: 25.7s)\n",
      "   • image51 (Type: AI_GENERATED, Questions: 3/3, Time: 32.5s)\n",
      "   • image52 (Type: AI_GENERATED, Questions: 3/3, Time: 31.0s)\n",
      "   • image53 (Type: AI_GENERATED, Questions: 3/3, Time: 47.6s)\n",
      "   • image54 (Type: AI_GENERATED, Questions: 3/3, Time: 49.9s)\n",
      "   • image55 (Type: AI_GENERATED, Questions: 3/3, Time: 24.9s)\n",
      "   • image56 (Type: AI_GENERATED, Questions: 3/3, Time: 14.3s)\n",
      "   • image57 (Type: AI_GENERATED, Questions: 3/3, Time: 42.3s)\n",
      "   • image58 (Type: AI_GENERATED, Questions: 3/3, Time: 41.5s)\n",
      "   • image59 (Type: AI_GENERATED, Questions: 3/3, Time: 18.1s)\n",
      "   • image60 (Type: AI_GENERATED, Questions: 3/3, Time: 27.2s)\n",
      "   • image61 (Type: AI_GENERATED, Questions: 3/3, Time: 25.7s)\n",
      "   • image62 (Type: AI_GENERATED, Questions: 3/3, Time: 32.5s)\n",
      "   • image63 (Type: AI_GENERATED, Questions: 3/3, Time: 28.7s)\n",
      "   • image64 (Type: AI_GENERATED, Questions: 3/3, Time: 31.0s)\n",
      "   • image65 (Type: AI_GENERATED, Questions: 3/3, Time: 32.5s)\n",
      "   • image66 (Type: AI_GENERATED, Questions: 3/3, Time: 15.9s)\n",
      "   • image67 (Type: AI_GENERATED, Questions: 3/3, Time: 19.7s)\n",
      "   • image68 (Type: AI_GENERATED, Questions: 3/3, Time: 21.9s)\n",
      "   • image69 (Type: AI_GENERATED, Questions: 3/3, Time: 25.7s)\n",
      "   • image70 (Type: AI_GENERATED, Questions: 3/3, Time: 42.3s)\n",
      "   • image71 (Type: AI_GENERATED, Questions: 3/3, Time: 18.8s)\n",
      "   • image72 (Type: AI_GENERATED, Questions: 3/3, Time: 17.3s)\n",
      "   • image73 (Type: AI_GENERATED, Questions: 3/3, Time: 30.9s)\n",
      "   • image74 (Type: AI_GENERATED, Questions: 3/3, Time: 22.6s)\n",
      "   • image75 (Type: AI_GENERATED, Questions: 3/3, Time: 18.0s)\n",
      "   • image76 (Type: AI_GENERATED, Questions: 3/3, Time: 27.1s)\n",
      "   • image77 (Type: AI_GENERATED, Questions: 3/3, Time: 45.2s)\n",
      "   • image78 (Type: AI_GENERATED, Questions: 3/3, Time: 23.3s)\n",
      "   • image79 (Type: AI_GENERATED, Questions: 3/3, Time: 21.1s)\n",
      "   • image80 (Type: AI_GENERATED, Questions: 3/3, Time: 27.1s)\n",
      "   • image81 (Type: AI_GENERATED, Questions: 3/3, Time: 23.3s)\n",
      "   • image82 (Type: AI_GENERATED, Questions: 3/3, Time: 22.6s)\n",
      "   • image83 (Type: AI_GENERATED, Questions: 3/3, Time: 34.0s)\n",
      "   • image84 (Type: AI_GENERATED, Questions: 3/3, Time: 34.7s)\n",
      "   • image85 (Type: AI_GENERATED, Questions: 3/3, Time: 19.5s)\n",
      "   • image86 (Type: AI_GENERATED, Questions: 3/3, Time: 27.1s)\n",
      "   • image87 (Type: AI_GENERATED, Questions: 3/3, Time: 16.6s)\n",
      "   • image88 (Type: AI_GENERATED, Questions: 3/3, Time: 15.1s)\n",
      "   • image89 (Type: AI_GENERATED, Questions: 3/3, Time: 19.6s)\n",
      "   • image90 (Type: AI_GENERATED, Questions: 3/3, Time: 28.6s)\n",
      "   • image91 (Type: AI_GENERATED, Questions: 3/3, Time: 22.7s)\n",
      "   • image92 (Type: AI_GENERATED, Questions: 3/3, Time: 31.6s)\n",
      "   • image93 (Type: AI_GENERATED, Questions: 3/3, Time: 21.1s)\n",
      "   • image94 (Type: AI_GENERATED, Questions: 3/3, Time: 40.0s)\n",
      "   • image95 (Type: AI_GENERATED, Questions: 3/3, Time: 50.5s)\n",
      "   • image96 (Type: AI_GENERATED, Questions: 3/3, Time: 19.3s)\n",
      "   • image97 (Type: AI_GENERATED, Questions: 3/3, Time: 29.3s)\n",
      "   • image98 (Type: AI_GENERATED, Questions: 3/3, Time: 31.6s)\n",
      "   • image99 (Type: AI_GENERATED, Questions: 3/3, Time: 30.0s)\n",
      "   • image100 (Type: AI_GENERATED, Questions: 3/3, Time: 25.6s)\n",
      "   • image101 (Type: AI_GENERATED, Questions: 3/3, Time: 30.9s)\n",
      "   • image102 (Type: AI_GENERATED, Questions: 3/3, Time: 26.3s)\n",
      "   • image103 (Type: AI_GENERATED, Questions: 3/3, Time: 22.5s)\n",
      "   • image104 (Type: AI_GENERATED, Questions: 3/3, Time: 21.0s)\n",
      "   • image105 (Type: AI_GENERATED, Questions: 3/3, Time: 24.0s)\n",
      "   • image106 (Type: AI_GENERATED, Questions: 3/3, Time: 20.3s)\n",
      "   • image107 (Type: AI_GENERATED, Questions: 3/3, Time: 17.3s)\n",
      "   • image108 (Type: AI_GENERATED, Questions: 3/3, Time: 21.0s)\n",
      "   • image109 (Type: AI_GENERATED, Questions: 3/3, Time: 39.0s)\n",
      "   • image110 (Type: AI_GENERATED, Questions: 3/3, Time: 24.6s)\n",
      "   • image111 (Type: AI_GENERATED, Questions: 3/3, Time: 19.6s)\n",
      "   • image112 (Type: AI_GENERATED, Questions: 3/3, Time: 16.5s)\n",
      "   • image113 (Type: AI_GENERATED, Questions: 3/3, Time: 21.8s)\n",
      "   • image114 (Type: AI_GENERATED, Questions: 3/3, Time: 24.8s)\n",
      "   • image115 (Type: AI_GENERATED, Questions: 3/3, Time: 21.8s)\n",
      "   • image116 (Type: AI_GENERATED, Questions: 3/3, Time: 31.6s)\n",
      "   • image117 (Type: AI_GENERATED, Questions: 3/3, Time: 26.3s)\n",
      "   • image118 (Type: AI_GENERATED, Questions: 3/3, Time: 26.5s)\n",
      "   • image119 (Type: AI_GENERATED, Questions: 3/3, Time: 31.7s)\n",
      "   • image120 (Type: AI_GENERATED, Questions: 3/3, Time: 29.4s)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_Gemma3()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python ((op_bench)",
   "language": "python",
   "name": "op_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10131.636125,
   "end_time": "2025-07-27T23:22:54.110636",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-gemma3-27b-it.ipynb",
   "output_path": "gemma3-27b-it_output.ipynb",
   "parameters": {},
   "start_time": "2025-07-27T20:34:02.474511",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
