{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2e5397",
   "metadata": {
    "papermill": {
     "duration": 0.0055,
     "end_time": "2025-06-09T13:09:48.410253",
     "exception": false,
     "start_time": "2025-06-09T13:09:48.404753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb94d93",
   "metadata": {
    "papermill": {
     "duration": 0.004148,
     "end_time": "2025-06-09T13:09:48.419007",
     "exception": false,
     "start_time": "2025-06-09T13:09:48.414859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d09be81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:48.428360Z",
     "iopub.status.busy": "2025-06-09T13:09:48.428085Z",
     "iopub.status.idle": "2025-06-09T13:09:50.185314Z",
     "shell.execute_reply": "2025-06-09T13:09:50.184303Z"
    },
    "papermill": {
     "duration": 1.763602,
     "end_time": "2025-06-09T13:09:50.186820",
     "exception": false,
     "start_time": "2025-06-09T13:09:48.423218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (4.51.1)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: Pillow in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (10.3.0)\r\n",
      "Requirement already satisfied: tqdm in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (4.66.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch Pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2b24a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:50.198007Z",
     "iopub.status.busy": "2025-06-09T13:09:50.197561Z",
     "iopub.status.idle": "2025-06-09T13:09:53.396234Z",
     "shell.execute_reply": "2025-06-09T13:09:53.395297Z"
    },
    "papermill": {
     "duration": 3.205907,
     "end_time": "2025-06-09T13:09:53.397908",
     "exception": false,
     "start_time": "2025-06-09T13:09:50.192001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed24e79",
   "metadata": {
    "papermill": {
     "duration": 0.004568,
     "end_time": "2025-06-09T13:09:53.407942",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.403374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d6d5f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:53.418471Z",
     "iopub.status.busy": "2025-06-09T13:09:53.418097Z",
     "iopub.status.idle": "2025-06-09T13:09:53.438335Z",
     "shell.execute_reply": "2025-06-09T13:09:53.437569Z"
    },
    "papermill": {
     "duration": 0.027134,
     "end_time": "2025-06-09T13:09:53.439602",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.412468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "    \n",
    "    def format_question(self, question, model_name):\n",
    "        \"\"\"Format a question for the model.\"\"\"\n",
    "\n",
    "        if model_name==\"blip2\":\n",
    "            return f\"Question: {question['question']} Answer(total number):\" # Provide just the total count and the list of objects in the given format \\n Format: number [objects] Answer: \"\n",
    "        else:\n",
    "            return f\"Question: {question['question']} Answer(total number):\"\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "        # Remove any text that's not a number\n",
    "        # import re\n",
    "        # numbers = re.findall(r'\\d+', answer)\n",
    "        # if numbers:\n",
    "        #     return numbers[0]  # Return the first number found\n",
    "        # return answer\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    def model_generation(self, model_name, model, inputs, processor):\n",
    "        \"\"\"Generate answer and decode.\"\"\"\n",
    "        outputs = None  # Initialize outputs to None\n",
    "        \n",
    "        if model_name==\"blip2\":\n",
    "            outputs = model.generate(**inputs)\n",
    "            answer = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "            \n",
    "        elif model_name==\"fuyu-8b\":\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=30,  # Increased from 10 to 200\n",
    "                pad_token_id=processor.tokenizer.eos_token_id\n",
    "            )\n",
    "            answer = processor.batch_decode(outputs[:, -30:], skip_special_tokens=True)[0]\n",
    "        else:\n",
    "            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "            answer = \"\"  # Return an empty string\n",
    "\n",
    "        return answer, outputs\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                try:\n",
    "                    print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        print(f\"Warning: Image not found at {image_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question in image_data['questions']:\n",
    "                        try:\n",
    "                            prompt = self.format_question(question, model_name)\n",
    "                            print(f\"Question: {question['question']}\")\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            # Process image and text\n",
    "                            inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "                            \n",
    "                            # Generate answer with better settings\n",
    "                            with torch.no_grad():\n",
    "                                answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n",
    "                                \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data[\"image_type\"],\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing question: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "            if results:\n",
    "                with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68516ae4",
   "metadata": {
    "papermill": {
     "duration": 0.004386,
     "end_time": "2025-06-09T13:09:53.448840",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.444454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Fuyu Model\n",
    "\n",
    "Let's evaluate the Fuyu-8b model on our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a3ef90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:53.458617Z",
     "iopub.status.busy": "2025-06-09T13:09:53.458373Z",
     "iopub.status.idle": "2025-06-09T13:09:53.463770Z",
     "shell.execute_reply": "2025-06-09T13:09:53.463128Z"
    },
    "papermill": {
     "duration": 0.011604,
     "end_time": "2025-06-09T13:09:53.464867",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.453263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_fuyu():\n",
    "    #from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    from transformers import FuyuProcessor, FuyuForCausalLM\n",
    "    \n",
    "    print(\"Loading Fuyu-8b model...\")\n",
    "    model = FuyuForCausalLM.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/fuyu-8b\",\n",
    "        # load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "    processor = FuyuProcessor.from_pretrained(\"/var/scratch/ave303/models/fuyu-8b\")\n",
    "\n",
    "    ## fuyu-8b is very slow and average performance\n",
    "\n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "        \n",
    "    tester = BenchmarkTester()\n",
    "    fuyu_results = tester.evaluate_model(\n",
    "        \"fuyu-8b\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"fuyu_8b_results.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "    # tester.save_results(\"fuyu_results.json\")\n",
    "\n",
    "    if fuyu_results is not None:\n",
    "        print(\"Initial test successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ebb4a",
   "metadata": {
    "papermill": {
     "duration": 0.004508,
     "end_time": "2025-06-09T13:09:53.473892",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.469384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test BLIP-2 Model\n",
    "\n",
    "Now let's evaluate the blip2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c82afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:53.483728Z",
     "iopub.status.busy": "2025-06-09T13:09:53.483491Z",
     "iopub.status.idle": "2025-06-09T13:09:53.489209Z",
     "shell.execute_reply": "2025-06-09T13:09:53.488552Z"
    },
    "papermill": {
     "duration": 0.012051,
     "end_time": "2025-06-09T13:09:53.490375",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.478324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_blip2():\n",
    "    from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "    \n",
    "    print(\"Loading BLIP-2 model...\")\n",
    "    model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/blip2opt6.7b\",\n",
    "        # load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        # temperature=0.8,\n",
    "        low_cpu_mem_usage=True\n",
    "    ).to('cuda').eval()\n",
    "    processor = Blip2Processor.from_pretrained(\"/var/scratch/ave303/models/blip2opt6.7b\")\n",
    "\n",
    "    ## opt-2.7b average performance, better instruction following \n",
    "        # Format - Answer(total number):\n",
    "    ## opt-6.7b(8bit) better performance with atleast answering, not well-instruction tuned, but provides number for answers\n",
    "        # Format - Answer(total number):\n",
    "    ## flan-t5-xl does fine but needs a lot of post processing, does not follow instructions to clearly\n",
    "        # Format - Answer(provide total number):\n",
    "    ## flan-t5-xxl(8bit) decent performance, better with instruction I think, slight postprocessing needed\n",
    "        # Format - Answer:\n",
    "    \n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "    \n",
    "    tester = BenchmarkTester()\n",
    "    blip2_results = tester.evaluate_model(\n",
    "        \"blip2\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"blip2-opt6.7b_results.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "    # tester.save_results(\"blip2_results.json\")\n",
    "\n",
    "    if blip2_results is not None:\n",
    "        print(\"Initial test successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98777cec",
   "metadata": {
    "papermill": {
     "duration": 0.004444,
     "end_time": "2025-06-09T13:09:53.499478",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.495034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the Fuyu model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462c6bed",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:53.509671Z",
     "iopub.status.busy": "2025-06-09T13:09:53.509434Z",
     "iopub.status.idle": "2025-06-09T13:09:53.512735Z",
     "shell.execute_reply": "2025-06-09T13:09:53.512099Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.009603,
     "end_time": "2025-06-09T13:09:53.513843",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.504240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fuyu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b00db",
   "metadata": {
    "papermill": {
     "duration": 0.004366,
     "end_time": "2025-06-09T13:09:53.522828",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.518462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And then the BLIP-2 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2397d0fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T13:09:53.533015Z",
     "iopub.status.busy": "2025-06-09T13:09:53.532703Z",
     "iopub.status.idle": "2025-06-09T13:10:47.794221Z",
     "shell.execute_reply": "2025-06-09T13:10:47.793323Z"
    },
    "papermill": {
     "duration": 54.26811,
     "end_time": "2025-06-09T13:10:47.795505",
     "exception": false,
     "start_time": "2025-06-09T13:09:53.527395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP-2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  14%|█▍        | 1/7 [00:04<00:29,  5.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  29%|██▊       | 2/7 [00:09<00:24,  4.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  43%|████▎     | 3/7 [00:14<00:19,  4.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  57%|█████▋    | 4/7 [00:19<00:14,  4.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  71%|███████▏  | 5/7 [00:24<00:09,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  86%|████████▌ | 6/7 [00:29<00:04,  4.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:31<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:31<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating blip2...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 1/50: image01\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of breakable items?\n",
      "Question: If one of the metal objects were replaced by a wooden object, how many wooden objects would be there in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   2%|▏         | 1/50 [00:01<01:10,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 2/50: image02\n",
      "Question: How many mammals are present in the image?\n",
      "Question: Count the number of items that can store other items?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   4%|▍         | 2/50 [00:01<00:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the zebra were replaced by a tree, how many mammals would be present in the image?\n",
      "\n",
      "Processing image 3/50: image03\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects with the primary purpose of illumination can be seen?\n",
      "Question: If the person riding one of the bicycles were replaced by a pedestrian, how many objects that have handles would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   6%|▌         | 3/50 [00:02<00:30,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 4/50: image04\n",
      "Question: How many tools are visible in the image?\n",
      "Question: How many cutting tools are present in this image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   8%|▊         | 4/50 [00:02<00:24,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the red handle were replaced by a wooden handle, how many colored artifacts would remain in the image?\n",
      "\n",
      "Processing image 5/50: image05\n",
      "Question: How many furniture items are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of containers that cannot hold hot liquids?\n",
      "Question: If the room were transformed into an open workspace instead of a meeting room, how many privacy features would need to be removed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  10%|█         | 5/50 [00:02<00:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 6/50: image06\n",
      "Question: How many reptiles are visible in this enclosure?\n",
      "Question: How many reptilian couples, at maximum, are present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  12%|█▏        | 6/50 [00:03<00:18,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the small pebbles forming the mosaic floor were replaced with sand, how many natural elements would still be visible in the enclosure?\n",
      "\n",
      "Processing image 7/50: image07\n",
      "Question: How many birds are visible in this image?\n",
      "Question: How many objects are present that can comfortably seat a human?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  14%|█▍        | 7/50 [00:03<00:15,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the birds sitting together only on one railing were to fly away, how many birds would remain?\n",
      "\n",
      "Processing image 8/50: image08\n",
      "Question: How many reptiles are visible in this image?\n",
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  16%|█▌        | 8/50 [00:03<00:13,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one turtle slid off the log into the water, how many turtles would be in the water?\n",
      "\n",
      "Processing image 9/50: image09\n",
      "Question: How many different types of vegetables are present in the image?\n",
      "Question: How many objects are used as containers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  18%|█▊        | 9/50 [00:04<00:12,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bag of limes were removed and replaced with two additional avocados, how many fruits would be present in total on the table, considering avocados are fruits?\n",
      "\n",
      "Processing image 10/50: image10\n",
      "Question: How many objects are present that are flexible?\n",
      "Question: Count the number of items that are battery powered?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  20%|██        | 10/50 [00:04<00:11,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two phones with three camera lenses were replaced with phones having two camera lenses, how many phones with two camera lenses would be present?\n",
      "\n",
      "Processing image 11/50: image11\n",
      "Question: How many objects made of glass are present on the table?\n",
      "Question: How many objects are present at the table that can be used for sitting?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  22%|██▏       | 11/50 [00:04<00:11,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tables in the center are removed, how many objects are visible that have legs?\n",
      "\n",
      "Processing image 12/50: image12\n",
      "Question: How many pieces of gym equipment are visible in the image?\n",
      "Question: How many objects are present that provide shade?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  24%|██▍       | 12/50 [00:04<00:10,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two of the stationary bikes were replaced by two treadmills, how many objects would be present that have pedals?\n",
      "\n",
      "Processing image 13/50: image13\n",
      "Question: How many furniture items are present in the room?\n",
      "Question: How many individual storage compartments are present in the furniture items in the room?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  26%|██▌       | 13/50 [00:05<00:09,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two bedside lamps were removed, how many objects are present that need electricity?\n",
      "\n",
      "Processing image 14/50: image14\n",
      "Question: How many objects are present that are transparent?\n",
      "Question: How many objects are positioned for student use to place other items?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  28%|██▊       | 14/50 [00:05<00:09,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the signages were removed, how many objects would be present that hang from the ceiling?\n",
      "\n",
      "Processing image 15/50: image15\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used to move up?\n",
      "Question: If the car on the ground is driven out of the garage, how many objects are present that is used to indicate slowing down to a stop?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  30%|███       | 15/50 [00:05<00:09,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 16/50: image16\n",
      "Question: How many objects made of rubber are present?\n",
      "Question: How many objects can be used as modes of transport if fixed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  32%|███▏      | 16/50 [00:06<00:10,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the center is fixed and driven out of the garage, how many objects made of rubber would be visible in the image?\n",
      "\n",
      "Processing image 17/50: image17\n",
      "Question: How many yellow colored objects are present?\n",
      "Question: How many objects are visible that are used to protect the head?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  34%|███▍      | 17/50 [00:06<00:09,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one person leaves the cleaning group, how many mammals would remain?\n",
      "\n",
      "Processing image 18/50: image18\n",
      "Question: How many mammals are visible in the image?\n",
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  36%|███▌      | 18/50 [00:06<00:08,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the mammals are to all step inside the shelters, how many natural elements are visible in the image?\n",
      "\n",
      "Processing image 19/50: image19\n",
      "Question: How many gardening tools are present that are made of metal?\n",
      "Question: How many objects are present in the garden that can hold other items?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  38%|███▊      | 19/50 [00:06<00:08,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If half the woven baskets are filled, how many containers would remain empty?\n",
      "\n",
      "Processing image 20/50: image20\n",
      "Question: How many objects in the background are present that have legs?\n",
      "Question: How many objects in the foreground are visible that are foldable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  40%|████      | 20/50 [00:07<00:08,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the stack of books on the table in the foreground was moved to the shelf, how many objects in physical contact with the table would be present?\n",
      "\n",
      "Processing image 21/50: image01\n",
      "Question: How many mammals are present in total?\n",
      "Question: How many objects are visible that can store items?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  42%|████▏     | 21/50 [00:07<00:07,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bear were to be replaced by a tree, how many different types of mammals would be there at the zoo?\n",
      "\n",
      "Processing image 22/50: image02\n",
      "Question: How many kitchen tools are visible in the image?\n",
      "Question: Count the number of items that require electricity to operate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  44%|████▍     | 22/50 [00:07<00:07,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If blinds were installed for the windows above the sink, how many transparent objects would remain?\n",
      "\n",
      "Processing image 23/50: image03\n",
      "Question: How many objects made of glass are present?\n",
      "Question: How many tools are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  46%|████▌     | 23/50 [00:07<00:06,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the worker was not wearing ear protection, how many protective items would remain?\n",
      "\n",
      "Processing image 24/50: image04\n",
      "Question: How many objects made of rubber are present?\n",
      "Question: Excluding the drawers, how many items in the workshop serve as containers for storage?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  48%|████▊     | 24/50 [00:08<00:06,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If an electric fan were placed on the workstation to provide ventilation, how many objects in the room would require electricity to operate?\n",
      "\n",
      "Processing image 25/50: image05\n",
      "Question: How many birds are visible in the image?\n",
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  50%|█████     | 25/50 [00:08<00:06,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the clouds were to completely cover the sky, blocking the sunlight, how many natural elements would still be visible?\n",
      "\n",
      "Processing image 26/50: image06\n",
      "Question: How many objects are present that have chimneys?\n",
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  52%|█████▏    | 26/50 [00:08<00:06,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bus were replaced by a pedestrian, how many mammals would be present?\n",
      "\n",
      "Processing image 27/50: image07\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  54%|█████▍    | 27/50 [00:08<00:06,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can be used to carry liquid?\n",
      "Question: If the waste to be disposed was color-coded to match the bins, how many objects are to be thrown in the bin on the right?\n",
      "\n",
      "Processing image 28/50: image08\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  56%|█████▌    | 28/50 [00:09<00:05,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that are openable?\n",
      "Question: If the bottle was removed from the table, how many objects are present on top of the table?\n",
      "\n",
      "Processing image 29/50: image09\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  58%|█████▊    | 29/50 [00:09<00:05,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many kitchen items are visible that can be used for cutting?\n",
      "Question: If the two jars on the top shelf were removed, how many breakable items would be present in the image?\n",
      "\n",
      "Processing image 30/50: image10\n",
      "Question: How many objects made of plastic are visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  60%|██████    | 30/50 [00:09<00:05,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can record audio?\n",
      "Question: If the microphones were replaced with headsets for every character, how many objects in total would be present that are worn on the head?\n",
      "\n",
      "Processing image 31/50: image11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many different food items are present on the kitchen countertop?\n",
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  62%|██████▏   | 31/50 [00:10<00:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the objects on the two shelves above the counter were placed inside the cabinet, how many items that are breakable would be present on the counter?\n",
      "\n",
      "Processing image 32/50: image12\n",
      "Question: How many different types of plants are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that behave as containers?\n",
      "Question: If all the visible plants were potted individually and placed on the stand, how many pots would be present on the stand?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  64%|██████▍   | 32/50 [00:10<00:05,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 33/50: image13\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can be used for sitting?\n",
      "Question: If the character standing upright took a seat for themself and the huddled group are seated in pairs, that is two characters per seat. How many objects would remain that can be used for sitting?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  66%|██████▌   | 33/50 [00:11<00:07,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 34/50: image14\n",
      "Question: How many cardboard objects are visible in the image?\n",
      "Question: How many objects are visible that can be used for sitting?\n",
      "Question: If the bottled objects and the white cups are packed away, how many objects are present that can be used to drink out of?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  68%|██████▊   | 34/50 [00:11<00:05,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 35/50: image15\n",
      "Question: How many objects that are present have wheels?\n",
      "Question: How many items are visible that can be used to hold liquids?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  70%|███████   | 35/50 [00:11<00:05,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car drives away, how many objects made of rubber are visible?\n",
      "\n",
      "Processing image 36/50: image16\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools designed for gathering or sweeping are visible?\n",
      "Question: If there was a flood and the water washed up the beach, completely submerging it, how many natural elements would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  72%|███████▏  | 36/50 [00:12<00:05,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 37/50: image17\n",
      "Question: How many objects are visible that have legs?\n",
      "Question: How many objects are visible that are attached to the wall or ceiling?\n",
      "Question: If the blinds are pulled over the window, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  74%|███████▍  | 37/50 [00:12<00:04,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 38/50: image18\n",
      "Question: How many objects made of rubber are visible?\n",
      "Question: How many objects are present that can hold liquids?\n",
      "Question: If the tools hanging on the wall were to be placed on the shelf, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  76%|███████▌  | 38/50 [00:12<00:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 39/50: image19\n",
      "Question: How many different types of gym equipment are present?\n",
      "Question: How many pieces of exercise equipment primarily designed for cardiovascular workouts are visible?\n",
      "Question: If the blinds were pulled over the windows, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  78%|███████▊  | 39/50 [00:12<00:03,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 40/50: image20\n",
      "Question: How many objects are present that have legs?\n",
      "Question: How many objects are visible that act as protection or shade?\n",
      "Question: If the laptop were placed on the shelf next to the TV, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  80%|████████  | 40/50 [00:13<00:02,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 41/50: image01\n",
      "Question: How many objects made of rubber are visible?\n",
      "Question: How many objects are visible that are means of transportation?\n",
      "Question: If the car in the driveway were to leave, how many objects primarily made of metal would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  82%|████████▏ | 41/50 [00:13<00:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 42/50: image02\n",
      "Question: How many objects made of concrete are present?\n",
      "Question: How many objects are visible that can be used for lifting?\n",
      "Question: If the orange paint spilled all over one of the plexiglass sheets, how many objects would remain that are transparent?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  84%|████████▍ | 42/50 [00:13<00:02,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 43/50: image03\n",
      "Question: How many mammals are present in the image?\n",
      "Question: How many objects are visible that are used for both meat and wool production?\n",
      "Question: If the two sheep were replaced by a cow grazing in the same area, how many objects would be present in between the two fences?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  86%|████████▌ | 43/50 [00:14<00:02,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 44/50: image04\n",
      "Question: How many objects are visible that are made of paper?\n",
      "Question: How many objects are present that behave as storage spaces?\n",
      "Question: If the glasses were placed inside the ceramic container, and we use this container as a dividing line between the left and right sides of the bookshelf, how many objects would be on the right side?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  88%|████████▊ | 44/50 [00:14<00:01,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 45/50: image05\n",
      "Question: How many objects are visible that are made of porcelain?\n",
      "Question: How many decoration items are present in the image?\n",
      "Question: If the drinks were split evenly between the two humans, how many drinks would each human consume?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  90%|█████████ | 45/50 [00:14<00:01,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 46/50: image06\n",
      "Question: How many mammals are present in the image?\n",
      "Question: How many objects are visible that are designed to contain liquids?\n",
      "Question: If the trash bags and bottles on the sand are only thrown into the black bin, how many mammals are actively holding some other object?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  92%|█████████▏| 46/50 [00:14<00:01,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 47/50: image07\n",
      "Question: How many mammals are present in the image?\n",
      "Question: How many objects are present that provide shelter?\n",
      "Question: If one of the mammals douses the fire, how many objects are present that can be switched off?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  94%|█████████▍| 47/50 [00:15<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 48/50: image08\n",
      "Question: How many different types of gym equipment are present?\n",
      "Question: How many objects are visible that are positioned between the row of treadmills and the bench press station?\n",
      "Question: If one of the treadmills is faulty and removed from the gym, how many objects are present that convey some kind of information?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  96%|█████████▌| 48/50 [00:15<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 49/50: image09\n",
      "Question: How many objects made of rubber are visible in the image?\n",
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  98%|█████████▊| 49/50 [00:15<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the workers took a wrench off the table, how many objects would remain in physical contact with the table?\n",
      "\n",
      "Processing image 50/50: image10\n",
      "Question: How many objects are visible that are made of metal?\n",
      "Question: How many objects present are breakable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [00:16<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [00:16<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bowls with the tomatoes and the chickpeas were emptied into the steaming pot, how many containers would still have something remaining in them?\n",
      "Initial test successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_blip2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda02fe",
   "metadata": {
    "papermill": {
     "duration": 0.012693,
     "end_time": "2025-06-09T13:10:47.822311",
     "exception": false,
     "start_time": "2025-06-09T13:10:47.809618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.523724,
   "end_time": "2025-06-09T13:10:50.396754",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-fuyu-blip2.ipynb",
   "output_path": "blip2opt6.7b_output.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T13:09:46.873030",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}