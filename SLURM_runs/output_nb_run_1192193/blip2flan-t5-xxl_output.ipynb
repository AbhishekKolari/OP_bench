{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b477c614",
   "metadata": {
    "papermill": {
     "duration": 0.00526,
     "end_time": "2025-06-09T14:41:18.634139",
     "exception": false,
     "start_time": "2025-06-09T14:41:18.628879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4b2bc",
   "metadata": {
    "papermill": {
     "duration": 0.004211,
     "end_time": "2025-06-09T14:41:18.642950",
     "exception": false,
     "start_time": "2025-06-09T14:41:18.638739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d90cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:18.652187Z",
     "iopub.status.busy": "2025-06-09T14:41:18.651934Z",
     "iopub.status.idle": "2025-06-09T14:41:20.221382Z",
     "shell.execute_reply": "2025-06-09T14:41:20.220470Z"
    },
    "papermill": {
     "duration": 1.576235,
     "end_time": "2025-06-09T14:41:20.223301",
     "exception": false,
     "start_time": "2025-06-09T14:41:18.647066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (4.51.1)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: Pillow in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (10.3.0)\r\n",
      "Requirement already satisfied: tqdm in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (4.66.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch) (12.1.105)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch Pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0974afbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:20.235704Z",
     "iopub.status.busy": "2025-06-09T14:41:20.235435Z",
     "iopub.status.idle": "2025-06-09T14:41:23.633571Z",
     "shell.execute_reply": "2025-06-09T14:41:23.632636Z"
    },
    "papermill": {
     "duration": 3.405545,
     "end_time": "2025-06-09T14:41:23.634917",
     "exception": false,
     "start_time": "2025-06-09T14:41:20.229372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd504aa",
   "metadata": {
    "papermill": {
     "duration": 0.004516,
     "end_time": "2025-06-09T14:41:23.644734",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.640218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf93a2b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:23.655177Z",
     "iopub.status.busy": "2025-06-09T14:41:23.654830Z",
     "iopub.status.idle": "2025-06-09T14:41:23.674853Z",
     "shell.execute_reply": "2025-06-09T14:41:23.674130Z"
    },
    "papermill": {
     "duration": 0.026706,
     "end_time": "2025-06-09T14:41:23.675989",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.649283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "    \n",
    "    def format_question(self, question, model_name):\n",
    "        \"\"\"Format a question for the model.\"\"\"\n",
    "\n",
    "        if model_name==\"blip2\":\n",
    "            return f\"Question: {question['question']} Provide only the total number. Answer:\" #Provide just the total count and the list of objects in the given format \\n Format: number [objects] Answer: \"\n",
    "        else:\n",
    "            return f\"Question: {question['question']} Answer(total number):\"\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "        # Remove any text that's not a number\n",
    "        # import re\n",
    "        # numbers = re.findall(r'\\d+', answer)\n",
    "        # if numbers:\n",
    "        #     return numbers[0]  # Return the first number found\n",
    "        # return answer\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    def model_generation(self, model_name, model, inputs, processor):\n",
    "        \"\"\"Generate answer and decode.\"\"\"\n",
    "        outputs = None  # Initialize outputs to None\n",
    "        \n",
    "        if model_name==\"blip2\":\n",
    "            outputs = model.generate(**inputs)\n",
    "            answer = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "            \n",
    "        elif model_name==\"fuyu-8b\":\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=30,  # Increased from 10 to 200\n",
    "                pad_token_id=processor.tokenizer.eos_token_id\n",
    "            )\n",
    "            answer = processor.batch_decode(outputs[:, -30:], skip_special_tokens=True)[0]\n",
    "        else:\n",
    "            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "            answer = \"\"  # Return an empty string\n",
    "\n",
    "        return answer, outputs\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                try:\n",
    "                    print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        print(f\"Warning: Image not found at {image_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question in image_data['questions']:\n",
    "                        try:\n",
    "                            prompt = self.format_question(question, model_name)\n",
    "                            print(f\"Question: {question['question']}\")\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            # Process image and text\n",
    "                            inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "                            \n",
    "                            # Generate answer with better settings\n",
    "                            with torch.no_grad():\n",
    "                                answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n",
    "                                \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data[\"image_type\"],\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing question: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "            if results:\n",
    "                with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a403dcb",
   "metadata": {
    "papermill": {
     "duration": 0.004427,
     "end_time": "2025-06-09T14:41:23.685241",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.680814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Fuyu Model\n",
    "\n",
    "Let's evaluate the Fuyu-8b model on our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80afec6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:23.695145Z",
     "iopub.status.busy": "2025-06-09T14:41:23.694905Z",
     "iopub.status.idle": "2025-06-09T14:41:23.700213Z",
     "shell.execute_reply": "2025-06-09T14:41:23.699587Z"
    },
    "papermill": {
     "duration": 0.011569,
     "end_time": "2025-06-09T14:41:23.701330",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.689761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_fuyu():\n",
    "    #from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    from transformers import FuyuProcessor, FuyuForCausalLM\n",
    "    \n",
    "    print(\"Loading Fuyu-8b model...\")\n",
    "    model = FuyuForCausalLM.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/fuyu-8b\",\n",
    "        # load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "    processor = FuyuProcessor.from_pretrained(\"/var/scratch/ave303/models/fuyu-8b\")\n",
    "\n",
    "    ## fuyu-8b is very slow and average performance\n",
    "\n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "        \n",
    "    tester = BenchmarkTester()\n",
    "    fuyu_results = tester.evaluate_model(\n",
    "        \"fuyu-8b\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"fuyu_8b_results.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "    # tester.save_results(\"fuyu_results.json\")\n",
    "\n",
    "    if fuyu_results is not None:\n",
    "        print(\"Initial test successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5db08c",
   "metadata": {
    "papermill": {
     "duration": 0.004581,
     "end_time": "2025-06-09T14:41:23.710572",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.705991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test BLIP-2 Model\n",
    "\n",
    "Now let's evaluate the blip2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b6bade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:23.720455Z",
     "iopub.status.busy": "2025-06-09T14:41:23.720211Z",
     "iopub.status.idle": "2025-06-09T14:41:23.725790Z",
     "shell.execute_reply": "2025-06-09T14:41:23.725178Z"
    },
    "papermill": {
     "duration": 0.011766,
     "end_time": "2025-06-09T14:41:23.726824",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.715058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_blip2():\n",
    "    from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "    \n",
    "    print(\"Loading BLIP-2 model...\")\n",
    "    model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/blip2flan-t5-xxl\",\n",
    "        # load_in_8bit=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        # temperature=0.8,\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "    processor = Blip2Processor.from_pretrained(\"/var/scratch/ave303/models/blip2flan-t5-xxl\")\n",
    "\n",
    "    ## opt-2.7b average performance, better instruction following \n",
    "        # Format - Answer(total number):\n",
    "    ## opt-6.7b(8bit) better performance with atleast answering, not well-instruction tuned, but provides number for answers\n",
    "        # Format - Answer(total number):\n",
    "    ## flan-t5-xl does fine but needs a lot of post processing, does not follow instructions to clearly\n",
    "        # Format - Answer(provide total number):\n",
    "    ## flan-t5-xxl(8bit) decent performance, better with instruction I think, slight postprocessing needed\n",
    "        # Format - Answer:\n",
    "    \n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "    \n",
    "    tester = BenchmarkTester()\n",
    "    blip2_results = tester.evaluate_model(\n",
    "        \"blip2\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"blip2-flan-t5-xxl_results.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "    # tester.save_results(\"blip2_results.json\")\n",
    "\n",
    "    if blip2_results is not None:\n",
    "        print(\"Initial test successful!\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157c765",
   "metadata": {
    "papermill": {
     "duration": 0.00443,
     "end_time": "2025-06-09T14:41:23.735863",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.731433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the Fuyu model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2ffe92",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:23.746013Z",
     "iopub.status.busy": "2025-06-09T14:41:23.745709Z",
     "iopub.status.idle": "2025-06-09T14:41:23.748868Z",
     "shell.execute_reply": "2025-06-09T14:41:23.748259Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.009355,
     "end_time": "2025-06-09T14:41:23.749969",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.740614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fuyu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ef98e",
   "metadata": {
    "papermill": {
     "duration": 0.004514,
     "end_time": "2025-06-09T14:41:23.759012",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.754498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And then the BLIP-2 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8e6c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T14:41:23.768977Z",
     "iopub.status.busy": "2025-06-09T14:41:23.768677Z",
     "iopub.status.idle": "2025-06-09T14:48:52.150878Z",
     "shell.execute_reply": "2025-06-09T14:48:52.149992Z"
    },
    "papermill": {
     "duration": 448.388668,
     "end_time": "2025-06-09T14:48:52.152172",
     "exception": false,
     "start_time": "2025-06-09T14:41:23.763504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP-2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  10%|█         | 1/10 [00:03<00:34,  3.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  20%|██        | 2/10 [00:06<00:27,  3.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  30%|███       | 3/10 [00:10<00:22,  3.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  40%|████      | 4/10 [00:13<00:19,  3.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  50%|█████     | 5/10 [00:16<00:16,  3.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  60%|██████    | 6/10 [00:19<00:12,  3.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  70%|███████   | 7/10 [00:22<00:09,  3.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  80%|████████  | 8/10 [00:25<00:06,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  90%|█████████ | 9/10 [00:28<00:03,  3.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:30<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:30<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating blip2...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 1/50: image01\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of breakable items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the metal objects were replaced by a wooden object, how many wooden objects would be there in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   2%|▏         | 1/50 [00:07<05:49,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 2/50: image02\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can store other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the zebra were replaced by a tree, how many mammals would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   4%|▍         | 2/50 [00:13<05:25,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 3/50: image03\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects with the primary purpose of illumination can be seen?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the person riding one of the bicycles were replaced by a pedestrian, how many objects that have handles would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   6%|▌         | 3/50 [00:21<05:43,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 4/50: image04\n",
      "Question: How many tools are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cutting tools are present in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the red handle were replaced by a wooden handle, how many colored artifacts would remain in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   8%|▊         | 4/50 [00:30<05:58,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 5/50: image05\n",
      "Question: How many furniture items are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of containers that cannot hold hot liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the room were transformed into an open workspace instead of a meeting room, how many privacy features would need to be removed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  10%|█         | 5/50 [00:36<05:19,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 6/50: image06\n",
      "Question: How many reptiles are visible in this enclosure?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many reptilian couples, at maximum, are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the small pebbles forming the mosaic floor were replaced with sand, how many natural elements would still be visible in the enclosure?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  12%|█▏        | 6/50 [00:45<05:44,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 7/50: image07\n",
      "Question: How many birds are visible in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can comfortably seat a human?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the birds sitting together only on one railing were to fly away, how many birds would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  14%|█▍        | 7/50 [00:52<05:27,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 8/50: image08\n",
      "Question: How many reptiles are visible in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one turtle slid off the log into the water, how many turtles would be in the water?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  16%|█▌        | 8/50 [00:56<04:38,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 9/50: image09\n",
      "Question: How many different types of vegetables are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are used as containers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bag of limes were removed and replaced with two additional avocados, how many fruits would be present in total on the table, considering avocados are fruits?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  18%|█▊        | 9/50 [01:04<04:38,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 10/50: image10\n",
      "Question: How many objects are present that are flexible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that are battery powered?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two phones with three camera lenses were replaced with phones having two camera lenses, how many phones with two camera lenses would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  20%|██        | 10/50 [01:11<04:44,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 11/50: image11\n",
      "Question: How many objects made of glass are present on the table?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present at the table that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tables in the center are removed, how many objects are visible that have legs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  22%|██▏       | 11/50 [01:17<04:22,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 12/50: image12\n",
      "Question: How many pieces of gym equipment are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shade?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two of the stationary bikes were replaced by two treadmills, how many objects would be present that have pedals?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  24%|██▍       | 12/50 [01:24<04:13,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 13/50: image13\n",
      "Question: How many furniture items are present in the room?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many individual storage compartments are present in the furniture items in the room?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two bedside lamps were removed, how many objects are present that need electricity?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  26%|██▌       | 13/50 [01:30<04:05,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 14/50: image14\n",
      "Question: How many objects are present that are transparent?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are positioned for student use to place other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the signages were removed, how many objects would be present that hang from the ceiling?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  28%|██▊       | 14/50 [01:38<04:11,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 15/50: image15\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used to move up?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car on the ground is driven out of the garage, how many objects are present that is used to indicate slowing down to a stop?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  30%|███       | 15/50 [01:45<04:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 16/50: image16\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects can be used as modes of transport if fixed?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the center is fixed and driven out of the garage, how many objects made of rubber would be visible in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  32%|███▏      | 16/50 [01:53<04:04,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 17/50: image17\n",
      "Question: How many yellow colored objects are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are used to protect the head?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one person leaves the cleaning group, how many mammals would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  34%|███▍      | 17/50 [01:59<03:43,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 18/50: image18\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the mammals are to all step inside the shelters, how many natural elements are visible in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  36%|███▌      | 18/50 [02:04<03:27,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 19/50: image19\n",
      "Question: How many gardening tools are present that are made of metal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present in the garden that can hold other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If half the woven baskets are filled, how many containers would remain empty?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  38%|███▊      | 19/50 [02:11<03:21,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 20/50: image20\n",
      "Question: How many objects in the background are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects in the foreground are visible that are foldable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the stack of books on the table in the foreground was moved to the shelf, how many objects in physical contact with the table would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  40%|████      | 20/50 [02:18<03:21,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 21/50: image01\n",
      "Question: How many mammals are present in total?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can store items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bear were to be replaced by a tree, how many different types of mammals would be there at the zoo?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  42%|████▏     | 21/50 [02:27<03:30,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 22/50: image02\n",
      "Question: How many kitchen tools are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that require electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If blinds were installed for the windows above the sink, how many transparent objects would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  44%|████▍     | 22/50 [02:34<03:21,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 23/50: image03\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the worker was not wearing ear protection, how many protective items would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  46%|████▌     | 23/50 [02:42<03:25,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 24/50: image04\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Excluding the drawers, how many items in the workshop serve as containers for storage?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If an electric fan were placed on the workstation to provide ventilation, how many objects in the room would require electricity to operate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  48%|████▊     | 24/50 [02:51<03:29,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 25/50: image05\n",
      "Question: How many birds are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the clouds were to completely cover the sky, blocking the sunlight, how many natural elements would still be visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  50%|█████     | 25/50 [02:59<03:20,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 26/50: image06\n",
      "Question: How many objects are present that have chimneys?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bus were replaced by a pedestrian, how many mammals would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  52%|█████▏    | 26/50 [03:04<02:51,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 27/50: image07\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can be used to carry liquid?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the waste to be disposed was color-coded to match the bins, how many objects are to be thrown in the bin on the right?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  54%|█████▍    | 27/50 [03:14<02:58,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 28/50: image08\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that are openable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bottle was removed from the table, how many objects are present on top of the table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  56%|█████▌    | 28/50 [03:20<02:42,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 29/50: image09\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many kitchen items are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two jars on the top shelf were removed, how many breakable items would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  58%|█████▊    | 29/50 [03:27<02:33,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 30/50: image10\n",
      "Question: How many objects made of plastic are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can record audio?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the microphones were replaced with headsets for every character, how many objects in total would be present that are worn on the head?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  60%|██████    | 30/50 [03:35<02:29,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 31/50: image11\n",
      "Question: How many different food items are present on the kitchen countertop?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the objects on the two shelves above the counter were placed inside the cabinet, how many items that are breakable would be present on the counter?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  62%|██████▏   | 31/50 [03:43<02:25,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 32/50: image12\n",
      "Question: How many different types of plants are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that behave as containers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the visible plants were potted individually and placed on the stand, how many pots would be present on the stand?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  64%|██████▍   | 32/50 [04:12<04:10, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 33/50: image13\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the character standing upright took a seat for themself and the huddled group are seated in pairs, that is two characters per seat. How many objects would remain that can be used for sitting?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  66%|██████▌   | 33/50 [04:20<03:27, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 34/50: image14\n",
      "Question: How many cardboard objects are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bottled objects and the white cups are packed away, how many objects are present that can be used to drink out of?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  68%|██████▊   | 34/50 [04:39<03:48, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 35/50: image15\n",
      "Question: How many objects that are present have wheels?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can be used to hold liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car drives away, how many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  70%|███████   | 35/50 [04:46<02:59, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 36/50: image16\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools designed for gathering or sweeping are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If there was a flood and the water washed up the beach, completely submerging it, how many natural elements would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  72%|███████▏  | 36/50 [04:55<02:36, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 37/50: image17\n",
      "Question: How many objects are visible that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are attached to the wall or ceiling?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the blinds are pulled over the window, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  74%|███████▍  | 37/50 [04:59<01:59,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 38/50: image18\n",
      "Question: How many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can hold liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tools hanging on the wall were to be placed on the shelf, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  76%|███████▌  | 38/50 [05:07<01:43,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 39/50: image19\n",
      "Question: How many different types of gym equipment are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pieces of exercise equipment primarily designed for cardiovascular workouts are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the blinds were pulled over the windows, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  78%|███████▊  | 39/50 [05:24<02:04, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 40/50: image20\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that act as protection or shade?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the laptop were placed on the shelf next to the TV, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  80%|████████  | 40/50 [05:31<01:39,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 41/50: image01\n",
      "Question: How many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the driveway were to leave, how many objects primarily made of metal would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  82%|████████▏ | 41/50 [05:36<01:16,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 42/50: image02\n",
      "Question: How many objects made of concrete are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used for lifting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the orange paint spilled all over one of the plexiglass sheets, how many objects would remain that are transparent?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  84%|████████▍ | 42/50 [05:54<01:30, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 43/50: image03\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are used for both meat and wool production?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two sheep were replaced by a cow grazing in the same area, how many objects would be present in between the two fences?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  86%|████████▌ | 43/50 [06:00<01:07,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 44/50: image04\n",
      "Question: How many objects are visible that are made of paper?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that behave as storage spaces?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the glasses were placed inside the ceramic container, and we use this container as a dividing line between the left and right sides of the bookshelf, how many objects would be on the right side?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  88%|████████▊ | 44/50 [06:06<00:51,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 45/50: image05\n",
      "Question: How many objects are visible that are made of porcelain?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many decoration items are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the drinks were split evenly between the two humans, how many drinks would each human consume?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  90%|█████████ | 45/50 [06:12<00:38,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 46/50: image06\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are designed to contain liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the trash bags and bottles on the sand are only thrown into the black bin, how many mammals are actively holding some other object?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  92%|█████████▏| 46/50 [06:20<00:31,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 47/50: image07\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the mammals douses the fire, how many objects are present that can be switched off?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  94%|█████████▍| 47/50 [06:26<00:21,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 48/50: image08\n",
      "Question: How many different types of gym equipment are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are positioned between the row of treadmills and the bench press station?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the treadmills is faulty and removed from the gym, how many objects are present that convey some kind of information?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  96%|█████████▌| 48/50 [06:35<00:15,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 49/50: image09\n",
      "Question: How many objects made of rubber are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the workers took a wrench off the table, how many objects would remain in physical contact with the table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  98%|█████████▊| 49/50 [06:43<00:07,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 50/50: image10\n",
      "Question: How many objects are visible that are made of metal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects present are breakable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bowls with the tomatoes and the chickpeas were emptied into the steaming pot, how many containers would still have something remaining in them?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [06:50<00:00,  7.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [06:50<00:00,  8.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial test successful!\n"
     ]
    }
   ],
   "source": [
    "test_blip2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ef048",
   "metadata": {
    "papermill": {
     "duration": 0.018461,
     "end_time": "2025-06-09T14:48:52.190632",
     "exception": false,
     "start_time": "2025-06-09T14:48:52.172171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 457.692057,
   "end_time": "2025-06-09T14:48:54.777512",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-fuyu-blip2.ipynb",
   "output_path": "blip2flan-t5-xxl_output.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T14:41:17.085455",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}