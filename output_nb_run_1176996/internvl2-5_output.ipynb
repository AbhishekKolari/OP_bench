{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7e6ae0",
   "metadata": {
    "papermill": {
     "duration": 0.005554,
     "end_time": "2025-05-25T22:57:54.942310",
     "exception": false,
     "start_time": "2025-05-25T22:57:54.936756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fb03e",
   "metadata": {
    "papermill": {
     "duration": 0.004321,
     "end_time": "2025-05-25T22:57:54.951545",
     "exception": false,
     "start_time": "2025-05-25T22:57:54.947224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abb51d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:57:54.961287Z",
     "iopub.status.busy": "2025-05-25T22:57:54.961030Z",
     "iopub.status.idle": "2025-05-25T22:57:54.964648Z",
     "shell.execute_reply": "2025-05-25T22:57:54.964103Z"
    },
    "papermill": {
     "duration": 0.009791,
     "end_time": "2025-05-25T22:57:54.965736",
     "exception": false,
     "start_time": "2025-05-25T22:57:54.955945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install transformers torch Pillow tqdm bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30c5090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:57:54.975576Z",
     "iopub.status.busy": "2025-05-25T22:57:54.975321Z",
     "iopub.status.idle": "2025-05-25T22:57:56.642018Z",
     "shell.execute_reply": "2025-05-25T22:57:56.641033Z"
    },
    "papermill": {
     "duration": 1.673261,
     "end_time": "2025-05-25T22:57:56.643507",
     "exception": false,
     "start_time": "2025-05-25T22:57:54.970246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.7.4.post1)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (2.2.1)\r\n",
      "Requirement already satisfied: einops in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (0.8.1)\r\n",
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.93)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch->flash-attn) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flash-attn #--no-build-isolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22814e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:57:56.655799Z",
     "iopub.status.busy": "2025-05-25T22:57:56.655530Z",
     "iopub.status.idle": "2025-05-25T22:58:00.523503Z",
     "shell.execute_reply": "2025-05-25T22:58:00.522551Z"
    },
    "papermill": {
     "duration": 3.87548,
     "end_time": "2025-05-25T22:58:00.525107",
     "exception": false,
     "start_time": "2025-05-25T22:57:56.649627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea6c724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:00.537013Z",
     "iopub.status.busy": "2025-05-25T22:58:00.536627Z",
     "iopub.status.idle": "2025-05-25T22:58:02.456957Z",
     "shell.execute_reply": "2025-05-25T22:58:02.456025Z"
    },
    "papermill": {
     "duration": 1.92754,
     "end_time": "2025-05-25T22:58:02.458327",
     "exception": false,
     "start_time": "2025-05-25T22:58:00.530787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c566f9f",
   "metadata": {
    "papermill": {
     "duration": 0.004853,
     "end_time": "2025-05-25T22:58:02.468652",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.463799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841d47ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:02.479888Z",
     "iopub.status.busy": "2025-05-25T22:58:02.479473Z",
     "iopub.status.idle": "2025-05-25T22:58:02.505455Z",
     "shell.execute_reply": "2025-05-25T22:58:02.504704Z"
    },
    "papermill": {
     "duration": 0.03299,
     "end_time": "2025-05-25T22:58:02.506622",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.473632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    # IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "    # IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "    IMAGENET_MEAN = (0.5, 0.5, 0.5)\n",
    "    IMAGENET_STD = (0.5, 0.5, 0.5)\n",
    "\n",
    "\n",
    "    def build_transform(self, input_size):\n",
    "        MEAN, STD = self.IMAGENET_MEAN, self.IMAGENET_STD\n",
    "        transform = T.Compose([\n",
    "            T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "            T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=MEAN, std=STD)\n",
    "        ])\n",
    "        return transform\n",
    "\n",
    "    def find_closest_aspect_ratio(self, aspect_ratio, target_ratios, width, height, image_size):\n",
    "        best_ratio_diff = float('inf')\n",
    "        best_ratio = (1, 1)\n",
    "        area = width * height\n",
    "        for ratio in target_ratios:\n",
    "            target_aspect_ratio = ratio[0] / ratio[1]\n",
    "            ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "            if ratio_diff < best_ratio_diff:\n",
    "                best_ratio_diff = ratio_diff\n",
    "                best_ratio = ratio\n",
    "            elif ratio_diff == best_ratio_diff:\n",
    "                if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                    best_ratio = ratio\n",
    "        return best_ratio\n",
    "\n",
    "    def dynamic_preprocess(self, image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "        orig_width, orig_height = image.size\n",
    "        aspect_ratio = orig_width / orig_height\n",
    "    \n",
    "        # calculate the existing image aspect ratio\n",
    "        target_ratios = set(\n",
    "            (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "            i * j <= max_num and i * j >= min_num)\n",
    "        target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "    \n",
    "        # find the closest aspect ratio to the target\n",
    "        target_aspect_ratio = self.find_closest_aspect_ratio(\n",
    "            aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "        # calculate the target width and height\n",
    "        target_width = image_size * target_aspect_ratio[0]\n",
    "        target_height = image_size * target_aspect_ratio[1]\n",
    "        blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "    \n",
    "        # resize the image\n",
    "        resized_img = image.resize((target_width, target_height))\n",
    "        processed_images = []\n",
    "        for i in range(blocks):\n",
    "            box = (\n",
    "                (i % (target_width // image_size)) * image_size,\n",
    "                (i // (target_width // image_size)) * image_size,\n",
    "                ((i % (target_width // image_size)) + 1) * image_size,\n",
    "                ((i // (target_width // image_size)) + 1) * image_size\n",
    "            )\n",
    "            # split the image\n",
    "            split_img = resized_img.crop(box)\n",
    "            processed_images.append(split_img)\n",
    "        assert len(processed_images) == blocks\n",
    "        if use_thumbnail and len(processed_images) != 1:\n",
    "            thumbnail_img = image.resize((image_size, image_size))\n",
    "            processed_images.append(thumbnail_img)\n",
    "        return processed_images\n",
    "\n",
    "    def load_image(self, image_file, input_size=448, max_num=12):     #internvl -> 448, 12 || ristretto -> 384, 10\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "        transform = self.build_transform(input_size=input_size)\n",
    "        images = self.dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "        pixel_values = [transform(image) for image in images]\n",
    "        pixel_values = torch.stack(pixel_values)\n",
    "        return pixel_values\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                try:\n",
    "                    print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        print(f\"Warning: Image not found at {image_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    # image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question in image_data['questions']:\n",
    "                        try:\n",
    "                            print(f\"Question: {question['question']}\")\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "\n",
    "                            # set the max number of tiles in `max_num`\n",
    "                            \n",
    "                            pixel_values = self.load_image(image_path, max_num=12).to(torch.float16).cuda()\n",
    "                            generation_config = dict(max_new_tokens=1024, do_sample=True)\n",
    "                            # prompt = f'<image>\\n {question[\"question\"]} Provide the total count of the objects and then list the objects, separated by commas. \\n Format: <number> [<object1>, <object2>, <object3>, ...]'\n",
    "                            # Answer with the total number(numerical) followed by the objects within square brackets' #Answer format: total number(numerical) objects(within square brackets)'\n",
    "                            prompt = f'<image>\\n {question[\"question\"]} Your response MUST be in the following format and nothing else:\\n <NUMBER> [<OBJECT1>, <OBJECT2>, <OBJECT3>, ...]'\n",
    "                            # prompt = f'<image>\\n {question[\"question\"]} Answer format: total count  [list of objects]'\n",
    "                            answer = model.chat(processor, pixel_values, prompt, generation_config)\n",
    "                            \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data[\"image_type\"],\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            # del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing question: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "            if results:\n",
    "                with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ea837",
   "metadata": {
    "papermill": {
     "duration": 0.004789,
     "end_time": "2025-05-25T22:58:02.516403",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.511614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test InternVL2.5\n",
    "Let's evaluate the InternVL2_5-4B-MPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d899a959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:02.527110Z",
     "iopub.status.busy": "2025-05-25T22:58:02.526819Z",
     "iopub.status.idle": "2025-05-25T22:58:02.530919Z",
     "shell.execute_reply": "2025-05-25T22:58:02.530208Z"
    },
    "papermill": {
     "duration": 0.010699,
     "end_time": "2025-05-25T22:58:02.532046",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.521347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def split_model(model_name):\n",
    "#     import math\n",
    "#     device_map = {}\n",
    "#     world_size = torch.cuda.device_count()\n",
    "#     config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "#     num_layers = config.llm_config.num_hidden_layers\n",
    "#     # num_layers = {\n",
    "#     #     'InternVL2_5-1B': 24, 'InternVL2_5-2B': 24, 'InternVL2_5-4B': 36, 'InternVL2_5-8B': 32,\n",
    "#     #     'InternVL2_5-26B': 48, 'InternVL2_5-38B': 64, 'InternVL2_5-78B': 80}[model_name]\n",
    "#     # Since the first GPU will be used for ViT, treat it as half a GPU.\n",
    "#     num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n",
    "#     num_layers_per_gpu = [num_layers_per_gpu] * world_size\n",
    "#     num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n",
    "#     layer_cnt = 0\n",
    "#     for i, num_layer in enumerate(num_layers_per_gpu):\n",
    "#         for j in range(num_layer):\n",
    "#             device_map[f'language_model.model.layers.{layer_cnt}'] = i\n",
    "#             layer_cnt += 1\n",
    "#     device_map['vision_model'] = 0\n",
    "#     device_map['mlp1'] = 0\n",
    "#     device_map['language_model.model.tok_embeddings'] = 0\n",
    "#     device_map['language_model.model.embed_tokens'] = 0\n",
    "#     device_map['language_model.output'] = 0\n",
    "#     device_map['language_model.model.norm'] = 0\n",
    "#     device_map['language_model.model.rotary_emb'] = 0\n",
    "#     device_map['language_model.lm_head'] = 0\n",
    "#     device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n",
    "\n",
    "#     return device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c9de8cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:02.542537Z",
     "iopub.status.busy": "2025-05-25T22:58:02.542263Z",
     "iopub.status.idle": "2025-05-25T22:58:02.547538Z",
     "shell.execute_reply": "2025-05-25T22:58:02.546813Z"
    },
    "papermill": {
     "duration": 0.011769,
     "end_time": "2025-05-25T22:58:02.548632",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.536863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_InternVL2_5():\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "    # device_map = split_model('InternVL2_5-4B')\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/internvl2.5-8b\",\n",
    "        torch_dtype=torch.float16,\n",
    "        # load_in_8bit=False,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attn=True,\n",
    "        trust_remote_code=True).to('cuda').eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/var/scratch/ave303/models/internvl2.5-8b\", trust_remote_code=True, use_fast=False)\n",
    "\n",
    "    ## InternVL2.5-4B --> performs decently well. slight post processing required\n",
    "    \n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "\n",
    "    tester = BenchmarkTester()\n",
    "    InternVL2_5_results = tester.evaluate_model(\n",
    "        \"InternVL2.5\",\n",
    "        model, \n",
    "        tokenizer, \n",
    "        \"InternVL2.5_results_8bMPO.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "\n",
    "    # Clean up\n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb807fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:02.559328Z",
     "iopub.status.busy": "2025-05-25T22:58:02.559044Z",
     "iopub.status.idle": "2025-05-25T22:58:02.564304Z",
     "shell.execute_reply": "2025-05-25T22:58:02.563583Z"
    },
    "papermill": {
     "duration": 0.011789,
     "end_time": "2025-05-25T22:58:02.565413",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.553624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_InternVL3():\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "    # device_map = split_model('InternVL3-8B')\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/internvl3-8b\",\n",
    "        torch_dtype=torch.float16,\n",
    "        load_in_8bit=False,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attn=True,\n",
    "        # device_map=device_map,\n",
    "        trust_remote_code=True).to('cuda').eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/var/scratch/ave303/models/internvl3-8b\", trust_remote_code=True, use_fast=False)\n",
    "\n",
    "    ## InternVL2.5-4B --> performs decently well. slight post processing required\n",
    "    \n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "\n",
    "    tester = BenchmarkTester()\n",
    "    InternVL3_results = tester.evaluate_model(\n",
    "        \"InternVL3\",\n",
    "        model, \n",
    "        tokenizer, \n",
    "        \"InternVL3_results_8b.json\", \n",
    "        batch_size=50\n",
    "    )\n",
    "\n",
    "    # Clean up\n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c08a341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:02.576208Z",
     "iopub.status.busy": "2025-05-25T22:58:02.575929Z",
     "iopub.status.idle": "2025-05-25T22:58:02.579898Z",
     "shell.execute_reply": "2025-05-25T22:58:02.579184Z"
    },
    "papermill": {
     "duration": 0.010523,
     "end_time": "2025-05-25T22:58:02.581008",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.570485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_Ristretto():\n",
    "#     import torch\n",
    "#     from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "#     # device_map = split_model('InternVL3-8B')\n",
    "    \n",
    "#     model = AutoModel.from_pretrained(\n",
    "#         \"/var/scratch/ave303/models/ristretto-3b\",\n",
    "#         torch_dtype=torch.float16,\n",
    "#         low_cpu_mem_usage=True,\n",
    "#         # device_map=device_map,\n",
    "#         trust_remote_code=True).to('cuda').eval()\n",
    "    \n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"/var/scratch/ave303/models/ristretto-3b\", trust_remote_code=True, use_fast=False)\n",
    "\n",
    "#     ## InternVL2.5-4B --> performs decently well. slight post processing required\n",
    "    \n",
    "#     # Optional: Enable memory efficient attention\n",
    "#     if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "#         model.config.use_memory_efficient_attention = True\n",
    "\n",
    "#     tester = BenchmarkTester()\n",
    "#     Ristretto_results = tester.evaluate_model(\n",
    "#         \"Ristretto-3b\",\n",
    "#         model, \n",
    "#         tokenizer, \n",
    "#         \"Ristretto_3b_results.json\", \n",
    "#         batch_size=25\n",
    "#     )\n",
    "\n",
    "#     # Clean up\n",
    "#     del model, tokenizer\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e835a7",
   "metadata": {
    "papermill": {
     "duration": 0.004844,
     "end_time": "2025-05-25T22:58:02.590944",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.586100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the InternVL2.5 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e69a5db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:58:02.601467Z",
     "iopub.status.busy": "2025-05-25T22:58:02.601180Z",
     "iopub.status.idle": "2025-05-25T23:01:08.401885Z",
     "shell.execute_reply": "2025-05-25T23:01:08.400996Z"
    },
    "papermill": {
     "duration": 185.807382,
     "end_time": "2025-05-25T23:01:08.403158",
     "exception": false,
     "start_time": "2025-05-25T22:58:02.595776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "InternLM2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  14%|█▍        | 1/7 [00:03<00:19,  3.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  29%|██▊       | 2/7 [00:06<00:16,  3.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  43%|████▎     | 3/7 [00:09<00:12,  3.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  57%|█████▋    | 4/7 [00:12<00:09,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  71%|███████▏  | 5/7 [00:15<00:06,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  86%|████████▌ | 6/7 [00:18<00:02,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:20<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:20<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating InternVL2.5...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 1/50: image01\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of breakable items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the metal objects were replaced by a wooden object, how many wooden objects would be there in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   2%|▏         | 1/50 [00:03<03:12,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 2/50: image02\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can store other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the zebra were replaced by a tree, how many mammals would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   4%|▍         | 2/50 [00:06<02:37,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 3/50: image03\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects with the primary purpose of illumination can be seen?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the person riding one of the bicycles were replaced by a pedestrian, how many objects that have handles would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   6%|▌         | 3/50 [00:10<02:37,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 4/50: image04\n",
      "Question: How many tools are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cutting tools are present in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the red handle were replaced by a wooden handle, how many colored artifacts would remain in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:   8%|▊         | 4/50 [00:14<02:47,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 5/50: image05\n",
      "Question: How many furniture items are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of containers that cannot hold hot liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the room were transformed into an open workspace instead of a meeting room, how many privacy features would need to be removed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  10%|█         | 5/50 [00:16<02:25,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 6/50: image06\n",
      "Question: How many reptiles are visible in this enclosure?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many reptilian couples, at maximum, are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the small pebbles forming the mosaic floor were replaced with sand, how many natural elements would still be visible in the enclosure?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  12%|█▏        | 6/50 [00:19<02:16,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 7/50: image07\n",
      "Question: How many birds are visible in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can comfortably seat a human?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the birds sitting together only on one railing were to fly away, how many birds would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  14%|█▍        | 7/50 [00:22<02:06,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 8/50: image08\n",
      "Question: How many reptiles are visible in this image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one turtle slid off the log into the water, how many turtles would be in the water?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  16%|█▌        | 8/50 [00:24<01:55,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 9/50: image09\n",
      "Question: How many different types of vegetables are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are used as containers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bag of limes were removed and replaced with two additional avocados, how many fruits would be present in total on the table, considering avocados are fruits?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  18%|█▊        | 9/50 [00:28<02:05,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 10/50: image10\n",
      "Question: How many objects are present that are flexible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that are battery powered?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two phones with three camera lenses were replaced with phones having two camera lenses, how many phones with two camera lenses would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  20%|██        | 10/50 [00:32<02:16,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 11/50: image11\n",
      "Question: How many objects made of glass are present on the table?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present at the table that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tables in the center are removed, how many objects are visible that have legs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  22%|██▏       | 11/50 [00:35<02:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 12/50: image12\n",
      "Question: How many pieces of gym equipment are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shade?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If two of the stationary bikes were replaced by two treadmills, how many objects would be present that have pedals?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  24%|██▍       | 12/50 [00:38<02:03,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 13/50: image13\n",
      "Question: How many furniture items are present in the room?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many individual storage compartments are present in the furniture items in the room?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two bedside lamps were removed, how many objects are present that need electricity?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  26%|██▌       | 13/50 [00:41<01:54,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 14/50: image14\n",
      "Question: How many objects are present that are transparent?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are positioned for student use to place other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the signages were removed, how many objects would be present that hang from the ceiling?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  28%|██▊       | 14/50 [00:43<01:44,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 15/50: image15\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used to move up?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car on the ground is driven out of the garage, how many objects are present that is used to indicate slowing down to a stop?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  30%|███       | 15/50 [00:47<01:53,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 16/50: image16\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects can be used as modes of transport if fixed?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the center is fixed and driven out of the garage, how many objects made of rubber would be visible in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  32%|███▏      | 16/50 [00:51<01:50,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 17/50: image17\n",
      "Question: How many yellow colored objects are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are used to protect the head?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one person leaves the cleaning group, how many mammals would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  34%|███▍      | 17/50 [00:53<01:39,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 18/50: image18\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the mammals are to all step inside the shelters, how many natural elements are visible in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  36%|███▌      | 18/50 [00:56<01:32,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 19/50: image19\n",
      "Question: How many gardening tools are present that are made of metal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present in the garden that can hold other items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If half the woven baskets are filled, how many containers would remain empty?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  38%|███▊      | 19/50 [00:59<01:29,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 20/50: image20\n",
      "Question: How many objects in the background are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects in the foreground are visible that are foldable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the stack of books on the table in the foreground was moved to the shelf, how many objects in physical contact with the table would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  40%|████      | 20/50 [01:02<01:30,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 21/50: image01\n",
      "Question: How many mammals are present in total?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can store items?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bear were to be replaced by a tree, how many different types of mammals would be there at the zoo?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  42%|████▏     | 21/50 [01:06<01:38,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 22/50: image02\n",
      "Question: How many kitchen tools are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that require electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If blinds were installed for the windows above the sink, how many transparent objects would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  44%|████▍     | 22/50 [01:08<01:21,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 23/50: image03\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the worker was not wearing ear protection, how many protective items would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  46%|████▌     | 23/50 [01:10<01:11,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 24/50: image04\n",
      "Question: How many objects made of rubber are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Excluding the drawers, how many items in the workshop serve as containers for storage?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If an electric fan were placed on the workstation to provide ventilation, how many objects in the room would require electricity to operate?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  48%|████▊     | 24/50 [01:12<01:07,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 25/50: image05\n",
      "Question: How many birds are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that act as support?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the clouds were to completely cover the sky, blocking the sunlight, how many natural elements would still be visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  50%|█████     | 25/50 [01:15<01:02,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 26/50: image06\n",
      "Question: How many objects are present that have chimneys?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bus were replaced by a pedestrian, how many mammals would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  52%|█████▏    | 26/50 [01:17<00:58,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 27/50: image07\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Count the number of items that can be used to carry liquid?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the waste to be disposed was color-coded to match the bins, how many objects are to be thrown in the bin on the right?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  54%|█████▍    | 27/50 [01:19<00:50,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 28/50: image08\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that are openable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bottle was removed from the table, how many objects are present on top of the table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  56%|█████▌    | 28/50 [01:22<00:54,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 29/50: image09\n",
      "Question: How many objects made of wood are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many kitchen items are visible that can be used for cutting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two jars on the top shelf were removed, how many breakable items would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  58%|█████▊    | 29/50 [01:26<01:02,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 30/50: image10\n",
      "Question: How many objects made of plastic are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can record audio?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the microphones were replaced with headsets for every character, how many objects in total would be present that are worn on the head?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  60%|██████    | 30/50 [01:28<00:52,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 31/50: image11\n",
      "Question: How many different food items are present on the kitchen countertop?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the objects on the two shelves above the counter were placed inside the cabinet, how many items that are breakable would be present on the counter?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  62%|██████▏   | 31/50 [01:32<01:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 32/50: image12\n",
      "Question: How many different types of plants are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that behave as containers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If all the visible plants were potted individually and placed on the stand, how many pots would be present on the stand?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  64%|██████▍   | 32/50 [01:36<01:02,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 33/50: image13\n",
      "Question: How many mammals are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the character standing upright took a seat for themself and the huddled group are seated in pairs, that is two characters per seat. How many objects would remain that can be used for sitting?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  66%|██████▌   | 33/50 [01:40<01:01,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 34/50: image14\n",
      "Question: How many cardboard objects are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used for sitting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bottled objects and the white cups are packed away, how many objects are present that can be used to drink out of?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  68%|██████▊   | 34/50 [01:45<01:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 35/50: image15\n",
      "Question: How many objects that are present have wheels?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many items are visible that can be used to hold liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car drives away, how many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  70%|███████   | 35/50 [01:48<00:53,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 36/50: image16\n",
      "Question: How many objects made of glass are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many tools designed for gathering or sweeping are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If there was a flood and the water washed up the beach, completely submerging it, how many natural elements would be present in the image?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  72%|███████▏  | 36/50 [01:51<00:47,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 37/50: image17\n",
      "Question: How many objects are visible that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are attached to the wall or ceiling?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the blinds are pulled over the window, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  74%|███████▍  | 37/50 [01:54<00:44,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 38/50: image18\n",
      "Question: How many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that can hold liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the tools hanging on the wall were to be placed on the shelf, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  76%|███████▌  | 38/50 [01:58<00:42,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 39/50: image19\n",
      "Question: How many different types of gym equipment are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pieces of exercise equipment primarily designed for cardiovascular workouts are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the blinds were pulled over the windows, how many sources of illumination would remain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  78%|███████▊  | 39/50 [02:01<00:36,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 40/50: image20\n",
      "Question: How many objects are present that have legs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that act as protection or shade?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the laptop were placed on the shelf next to the TV, how many objects would be present on the shelf?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  80%|████████  | 40/50 [02:03<00:31,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 41/50: image01\n",
      "Question: How many objects made of rubber are visible?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are means of transportation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the car in the driveway were to leave, how many objects primarily made of metal would be present?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  82%|████████▏ | 41/50 [02:07<00:29,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 42/50: image02\n",
      "Question: How many objects made of concrete are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that can be used for lifting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the orange paint spilled all over one of the plexiglass sheets, how many objects would remain that are transparent?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  84%|████████▍ | 42/50 [02:10<00:26,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 43/50: image03\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are used for both meat and wool production?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the two sheep were replaced by a cow grazing in the same area, how many objects would be present in between the two fences?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  86%|████████▌ | 43/50 [02:14<00:23,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 44/50: image04\n",
      "Question: How many objects are visible that are made of paper?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that behave as storage spaces?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the glasses were placed inside the ceramic container, and we use this container as a dividing line between the left and right sides of the bookshelf, how many objects would be on the right side?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  88%|████████▊ | 44/50 [02:16<00:18,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 45/50: image05\n",
      "Question: How many objects are visible that are made of porcelain?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many decoration items are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the drinks were split evenly between the two humans, how many drinks would each human consume?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  90%|█████████ | 45/50 [02:21<00:17,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 46/50: image06\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are designed to contain liquids?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the trash bags and bottles on the sand are only thrown into the black bin, how many mammals are actively holding some other object?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  92%|█████████▏| 46/50 [02:25<00:15,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 47/50: image07\n",
      "Question: How many mammals are present in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are present that provide shelter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the mammals douses the fire, how many objects are present that can be switched off?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  94%|█████████▍| 47/50 [02:28<00:10,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 48/50: image08\n",
      "Question: How many different types of gym equipment are present?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that are positioned between the row of treadmills and the bench press station?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the treadmills is faulty and removed from the gym, how many objects are present that convey some kind of information?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  96%|█████████▌| 48/50 [02:31<00:06,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 49/50: image09\n",
      "Question: How many objects made of rubber are visible in the image?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects are visible that need electricity to operate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If one of the workers took a wrench off the table, how many objects would remain in physical contact with the table?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  98%|█████████▊| 49/50 [02:34<00:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image 50/50: image10\n",
      "Question: How many objects are visible that are made of metal?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many objects present are breakable?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If the bowls with the tomatoes and the chickpeas were emptied into the steaming pot, how many containers would still have something remaining in them?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [02:38<00:00,  3.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images: 100%|██████████| 50/50 [02:38<00:00,  3.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_InternVL2_5() #8.59 #9.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "249e24ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T23:01:08.443354Z",
     "iopub.status.busy": "2025-05-25T23:01:08.443023Z",
     "iopub.status.idle": "2025-05-25T23:01:08.446179Z",
     "shell.execute_reply": "2025-05-25T23:01:08.445666Z"
    },
    "papermill": {
     "duration": 0.023586,
     "end_time": "2025-05-25T23:01:08.447204",
     "exception": false,
     "start_time": "2025-05-25T23:01:08.423618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_InternVL3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092c44da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T23:01:08.485339Z",
     "iopub.status.busy": "2025-05-25T23:01:08.485195Z",
     "iopub.status.idle": "2025-05-25T23:01:08.487776Z",
     "shell.execute_reply": "2025-05-25T23:01:08.487264Z"
    },
    "papermill": {
     "duration": 0.022617,
     "end_time": "2025-05-25T23:01:08.488792",
     "exception": false,
     "start_time": "2025-05-25T23:01:08.466175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_Ristretto()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 198.639951,
   "end_time": "2025-05-25T23:01:11.958020",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-internvl2-5.ipynb",
   "output_path": "internvl2-5_output.ipynb",
   "parameters": {},
   "start_time": "2025-05-25T22:57:53.318069",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}